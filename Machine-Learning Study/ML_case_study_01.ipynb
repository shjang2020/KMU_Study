{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93b41229599509f643f1c1df3b86b3f79b66666f"
   },
   "source": [
    "<font color=\"#CC3D3D\"><p>\n",
    "# ML Case Study #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93b41229599509f643f1c1df3b86b3f79b66666f"
   },
   "source": [
    "- **`PROBLEM`**: 백화점 고객이 1년 동안 상품을 구매한 속성을 분석하여 `고객의 성별(0:여자, 1:남자)을 예측`하시오.\n",
    "- **`INPUT`**: 학습용(`X_train.csv`, `y_train`)과 평가용(`X_test.csv`) 데이터 \n",
    "- **`OUTPUT`**: 위 데이터를 이용하여 구축한 모형이 생성한 예측결과(`submission.csv`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# EDA\n",
    "import klib\n",
    "\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Modeling\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "from scipy.stats.mstats import gmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd7e3527fd56e5b5855c6846ca226f5f860f725b"
   },
   "source": [
    "### 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "794123064b09797f51add356a676fb6a7aed015d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>총구매액</th>\n",
       "      <th>최대구매액</th>\n",
       "      <th>환불금액</th>\n",
       "      <th>주구매상품</th>\n",
       "      <th>주구매지점</th>\n",
       "      <th>내점일수</th>\n",
       "      <th>내점당구매건수</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>구매주기</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68282840</td>\n",
       "      <td>11264000</td>\n",
       "      <td>6860000.0</td>\n",
       "      <td>기타</td>\n",
       "      <td>강남점</td>\n",
       "      <td>19</td>\n",
       "      <td>3.894737</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2136000</td>\n",
       "      <td>2136000</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>잠실점</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3197000</td>\n",
       "      <td>1639000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>남성 캐주얼</td>\n",
       "      <td>관악점</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16077620</td>\n",
       "      <td>4935000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기타</td>\n",
       "      <td>광주점</td>\n",
       "      <td>18</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29050000</td>\n",
       "      <td>24000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>보석</td>\n",
       "      <td>본  점</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>82581500</td>\n",
       "      <td>23976000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>골프</td>\n",
       "      <td>부산본점</td>\n",
       "      <td>8</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>480000</td>\n",
       "      <td>480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>섬유잡화</td>\n",
       "      <td>광주점</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>260003790</td>\n",
       "      <td>25750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>남성 캐주얼</td>\n",
       "      <td>본  점</td>\n",
       "      <td>19</td>\n",
       "      <td>3.736842</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>88991520</td>\n",
       "      <td>18120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>육류</td>\n",
       "      <td>본  점</td>\n",
       "      <td>5</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>623700</td>\n",
       "      <td>209000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>2</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           총구매액     최대구매액       환불금액   주구매상품 주구매지점  내점일수   내점당구매건수    주말방문비율  \\\n",
       "0      68282840  11264000  6860000.0      기타   강남점    19  3.894737  0.527027   \n",
       "1       2136000   2136000   300000.0     스포츠   잠실점     2  1.500000  0.000000   \n",
       "2       3197000   1639000        NaN  남성 캐주얼   관악점     2  2.000000  0.000000   \n",
       "3      16077620   4935000        NaN      기타   광주점    18  2.444444  0.318182   \n",
       "4      29050000  24000000        NaN      보석  본  점     2  1.500000  0.000000   \n",
       "...         ...       ...        ...     ...   ...   ...       ...       ...   \n",
       "5977   82581500  23976000        NaN      골프  부산본점     8  1.750000  0.642857   \n",
       "5978     480000    480000        NaN    섬유잡화   광주점     1  1.000000  0.000000   \n",
       "5979  260003790  25750000        NaN  남성 캐주얼  본  점    19  3.736842  0.915493   \n",
       "5980   88991520  18120000        NaN      육류  본  점     5  3.600000  0.444444   \n",
       "5981     623700    209000        NaN    가공식품  영등포점     2  5.000000  0.000000   \n",
       "\n",
       "      구매주기  \n",
       "0       17  \n",
       "1        1  \n",
       "2        1  \n",
       "3       16  \n",
       "4       85  \n",
       "...    ...  \n",
       "5977    40  \n",
       "5978     0  \n",
       "5979    18  \n",
       "5980    60  \n",
       "5981    31  \n",
       "\n",
       "[5982 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습용과 평가용(제출용) 데이터를 읽어들인다.\n",
    "train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "\n",
    "# 분석에 필요없는 ID 필드를 데이터에서 제거하고, 전처리 후 학습용과 제출용 데이터를 분리하기 위해 ID는 보관한다.\n",
    "train_id = train['cust_id']\n",
    "test_id = test['cust_id']\n",
    "del train['cust_id'], test['cust_id']\n",
    "\n",
    "# 학습용 정답 데이터를 읽는다.\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "# 전처리를 동일하게 적용하기 위해 두 데이터를 합한다.\n",
    "features = pd.concat([train, test]).reset_index(drop=True)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd7e3527fd56e5b5855c6846ca226f5f860f725b"
   },
   "source": [
    "### 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib 한글깨짐 지원\n",
    "\n",
    "path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print('Unknown system...')\n",
    "rc('axes', unicode_minus=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleansing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수와 수치형 변수를 분리\n",
    "\n",
    "cat_features = features.select_dtypes(include=['object']).columns.to_list()\n",
    "num_features = features.select_dtypes(exclude='object').columns.to_list()\n",
    "#num_features = [c for c in features.columns.tolist() if c not in cat_features]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Impute Missing Values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#구매상품을 분류 별로 나눈 것\n",
    "#features['주구매상품1']=features['주구매상품'].apply(lambda x: '음식' if (x == '가공식품' or x == '건강식품' or \n",
    "#                                                                                               x == '농산물' or x == '수산품' or x == '육류' or \n",
    "#                                                                                               x == '젓갈/반찬' or x == '축산가공') \n",
    "#                                          else '물품' if (x == '가구' or x == '대형가전'  or x == '생활잡화' or \n",
    "#                                                                                        x == '소형가전' or x == '식기' or x == '일용잡화' or x == '주방가전' or\n",
    "#                                                                                          x == '주방용품' or x=='침구/수예')\n",
    "#                                           else '남성성' if (x == '골프' or x == '구두'  or x == '남성 캐주얼' or \n",
    "#                                                                                         x == '남성 트랜디' or x == '남성정장' or x == '셔츠' or x == '스포츠' or\n",
    "#                                                                                         x == '시티웨어' or x=='통신/컴퓨터' or x== '주류' or x=='트래디셔널')\n",
    "#                                           else '여성성' if (x == '디자이너' or x == '란제리/내의'  or x == '섬유잡화' or \n",
    "#                                                                                         x == '캐주얼' or x == '명품' or x == '모피/피혁' or x == '보석' or\n",
    "#                                                                                          x == '액세서리' or x=='피혁잡화' or x== '화장품')\n",
    "#                                           else '기타')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#지역별로 주매지점을 나눈 것\n",
    "#features['주구매지점1']=features['주구매지점'].apply(lambda x: '서울' if (x == '잠실점' or x == '영등포점' or \n",
    "#                                                                                               x == '강남점' or x == '청량리점' or x == '노원점' or \n",
    "#                                                                                               x == '미아점' or x == '관악점') \n",
    "#                                          else '경기도' if (x == '분당점' or x == '일산점'  or x == '인천점' )\n",
    "#                                         else '타지역' if (x == '부산본점' or x == '광주점'  or x == '대전점' or \n",
    "#                                                                                         x == '동래점' or x == '울산점' or x == '센텀시티점' or x == '창원점'\n",
    "#                                                                                          or x=='포항점' or x== '대구점' or x=='전주점'or x=='상인점')\n",
    "#                                         else '본점' if (x == '본  점')\n",
    "#                                          else '매각점')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##서울을 따로 만든것\n",
    "#features['서울지점']=features['주구매지점'].apply(lambda x: '서울' if (x == '잠실점' or x == '영등포점' or \n",
    "#                                                                                               x == '강남점' or x == '청량리점' or x == '노원점' or \n",
    "#                                                                                               x == '미아점' or x == '관악점') else '나머지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##경기도을 따로 만든것\n",
    "#features['경기도지점']=features['주구매지점'].apply(lambda x: '경기도' if (x == '분당점' or x == '일산점'  or x == '인천점' ) else '나머지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##지방을 따로 만든것\n",
    "#features['지방지점']=features['주구매지점'].apply(lambda x: '타지역' if (x == '부산본점' or x == '광주점'  or x == '대전점' or \n",
    " #                                                                                         x == '동래점' or x == '울산점' or x == '센텀시티점' or x == '창원점'\n",
    "  #                                                                                        or x=='포항점' or x== '대구점' or x=='전주점'or x=='상인점') else '나머지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##본지점을 따로 만든것\n",
    "#features['본지점']=features['주구매지점'].apply(lambda x:'본점' if (x == '본  점') else '나머지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##매각을 한 지점을 따로 만든것\n",
    "#features['매각지점']=features['주구매지점'].apply(lambda x:'매각지점' if (x == '안양점' or x == '부평점') else '나머지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##롯데백화점 데이터로 지점 별 등급이 높은 에비뉴엘을 나눈 것\n",
    "#features['에비뉴엘']=features['주구매지점'].apply(lambda x: '에비뉴엘' if (x=='본  점' or x=='잠실점' or x=='부산본점')\n",
    "#                                         else '노 에비뉴엘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#남자제품을 따로 뽑은 것\n",
    "features['남자제품']=features['주구매상품'].apply(lambda x: '남성' if (x == '골프'  or x == '남성 캐주얼' or \n",
    "                                                                                          x == '남성 트랜디' or x == '남성정장' or x == '셔츠' or x == '스포츠' or\n",
    "                                                                                          x == '시티웨어' or x=='통신/컴퓨터' or x== '주류' or x=='트래디셔널')\n",
    "                                         else '나머지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#여자제품을 따로 뽑은 것\n",
    "features['여자제품']=features['주구매상품'].apply(lambda x: '여자' if (x == '명품' or x == '화장품'  or x == '액세서리' or \n",
    "                                                                                         x == '피혁잡화' or x == '모피/피혁' or x == '란제리/내의') \n",
    "                                           else '나머지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#총구매액으로 고객 등급을 나눈 것, 롯데백화점 사이트의 등급을 실제로 이용\n",
    "features['고객등급']=features['총구매액'].apply(lambda x:'AVENUEL' if (x>200000000) else 'LENITH' if (x>100000000)else 'MVG-Prestige' if (x >60000000)\n",
    "                                                                   else 'MVG-Crown' if (x >40000000)\n",
    "                                        else 'VIP+' if (x >8000000)\n",
    "                                                                   else 'VIP' if (x >4000000) else '일반')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meanencoding 을 이용하여 주구매상품과 주구매지점에 대한 열을 따로 새로 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1=train.copy()\n",
    "train_1['성별']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=train_1['성별'].mean()\n",
    "agg=train_1.groupby('주구매상품')['성별'].agg(['count','mean'])\n",
    "counts=agg['count']\n",
    "means=agg['mean']\n",
    "weight=80\n",
    "smooth=(counts*means+weight*mean)/(counts+weight)\n",
    "features['상품_mean']=features['주구매상품'].map(smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=train_1['성별'].mean()\n",
    "agg=train_1.groupby('주구매지점')['성별'].agg(['count','mean'])\n",
    "counts=agg['count']\n",
    "means=agg['mean']\n",
    "weight=80\n",
    "smooth=(counts*means+weight*mean)/(counts+weight)\n",
    "features['지점_mean']=features['주구매지점'].map(smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "총구매액       0\n",
       "최대구매액      0\n",
       "환불금액       0\n",
       "주구매상품      0\n",
       "주구매지점      0\n",
       "내점일수       0\n",
       "내점당구매건수    0\n",
       "주말방문비율     0\n",
       "구매주기       0\n",
       "남자제품       0\n",
       "여자제품       0\n",
       "고객등급       0\n",
       "상품_mean    0\n",
       "지점_mean    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측값 처리: 범주형이냐 수치형이냐에 따라 다르게 처리\n",
    "# 현재 결측값은 환불금액만 있기 때문에 일단 미뤄두고 진행하겠다.\n",
    "\n",
    "if len(num_features) > 0: \n",
    "    features[num_features] = SimpleImputer(strategy='constant', fill_value=0).fit_transform(features[num_features])\n",
    "if len(cat_features) > 0:  \n",
    "    features[cat_features] = SimpleImputer(strategy=\"most_frequent\").fit_transform(features[cat_features])\n",
    "\n",
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- 내점당구매건수* 내점일수 = 총구매건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['총구매건수']=features['내점일수']*features['내점당구매건수']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총구매액과 총구매건수를 곱하여 건평균구매액을 만든것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['건평균구매액']=features['총구매액']*features['총구매건수']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구매주기와 내점일수를 이용하여 생활기간을 만든 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['생활기간']=features['구매주기']*features['내점일수']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총구매액과 환불금액을 이용하여 비환불금액을 만든 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['비환불금액']=features['총구매액']-features['환불금액']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비환불금액과 총구매건수를 이용하여 구매상품평균금액을 만들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['구매상품평균금액']=features['비환불금액']*features['총구매건수']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구매주기를 이용하여 구매왕과 아닌 것을 나눈 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features[features['구매주기']>100]\n",
    "features['구매주기_1']=features['구매주기'].apply(lambda x: '구매왕' if x>100 else '나머지')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음의 수를 log1p를 하기 위해 0으로 바꿔준 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['총구매액']=features['총구매액'].apply(lambda x: 0 if x<0 else x)\n",
    "features['최대구매액']=features['최대구매액'].apply(lambda x: 0 if x<0 else x)\n",
    "features['환불금액']=features['환불금액'].apply(lambda x: 0 if x<0 else x)\n",
    "features['건평균구매액']=features['건평균구매액'].apply(lambda x: 0 if x<0 else x)\n",
    "features['구매상품평균금액']=features['구매상품평균금액'].apply(lambda x: 0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로그변환을 사용해줌 log1p를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['총구매액']=np.log1p(features['총구매액']) \n",
    "features['최대구매액']=np.log1p(features['최대구매액']) \n",
    "features['환불금액']=np.log1p(features['환불금액']) \n",
    "features['건평균구매액']=np.log1p(features['건평균구매액']) \n",
    "features['구매상품평균금액']=np.log1p(features['구매상품평균금액'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['최대구매액']=np.log1p(features['최대구매액']) \n",
    "features['환불금액']=np.log1p(features['환불금액']) \n",
    "features['건평균구매액']=np.log1p(features['건평균구매액'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Deal with Outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수와 수치형 변수를 분리\n",
    "\n",
    "cat_features = features.select_dtypes(include=['object']).columns.to_list()\n",
    "num_features = features.select_dtypes(exclude='object').columns.to_list()\n",
    "#num_features = [c for c in features.columns.tolist() if c not in cat_features]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meanencoding 을 이용한 열제외하고 이상치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features.remove('상품_mean')\n",
    "num_features.remove('지점_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수에 대해 이상치(outlier)를 처리\n",
    "features[num_features] = features[num_features].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in ['총구매액', '최대구매액', '환불금액', '건평균구매액', '구매상품평균금액']:\n",
    "#    features[col] = np.log2(1 + features[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in ['최대구매액', '환불금액', '건평균구매액']:\n",
    "#    features[col] = np.log2(1 + features[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "standardscaler 를 이용하여 스케일링을 해준 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_features-['주말방문비율','구매주기','생활기간']\n",
    "num_features.remove('주말방문비율')\n",
    "num_features.remove('구매주기')\n",
    "num_features.remove('생활기간')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features[num_features] = scaler.fit_transform(features[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features.append('주말방문비율')\n",
    "num_features.append('구매주기')\n",
    "num_features.append('생활기간')\n",
    "num_features.append('상품_mean')\n",
    "num_features.append('지점_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polynomial 을 이용하려 하였으나 효능이 좋지 않아 제외시켰음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_features=features.loc[:3499,num_features]\n",
    "#test_features=features.loc[3500:,num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#poly = PolynomialFeatures(2, include_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features = poly.fit_transform(train_features)\n",
    "#test_features = poly.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features=pd.DataFrame(data=train_features, columns=poly.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_features=pd.DataFrame(data=test_features, columns=poly.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_num=pd.concat([train_features, test_features], axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_num[features_num.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#features_num[features_num.columns] = scaler.fit_transform(features_num[features_num.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#features = pd.concat([features_num,features[['지점_mean','상품_mean']], pd.get_dummies(features[cat_features])], axis=1)\n",
    "#features#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결합시킨거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>총구매액</th>\n",
       "      <th>최대구매액</th>\n",
       "      <th>환불금액</th>\n",
       "      <th>내점일수</th>\n",
       "      <th>내점당구매건수</th>\n",
       "      <th>총구매건수</th>\n",
       "      <th>건평균구매액</th>\n",
       "      <th>비환불금액</th>\n",
       "      <th>구매상품평균금액</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>...</th>\n",
       "      <th>여자제품_여자</th>\n",
       "      <th>고객등급_AVENUEL</th>\n",
       "      <th>고객등급_LENITH</th>\n",
       "      <th>고객등급_MVG-Crown</th>\n",
       "      <th>고객등급_MVG-Prestige</th>\n",
       "      <th>고객등급_VIP</th>\n",
       "      <th>고객등급_VIP+</th>\n",
       "      <th>고객등급_일반</th>\n",
       "      <th>구매주기_1_구매왕</th>\n",
       "      <th>구매주기_1_나머지</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566538</td>\n",
       "      <td>0.293396</td>\n",
       "      <td>1.378200</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>0.872291</td>\n",
       "      <td>0.249115</td>\n",
       "      <td>0.737943</td>\n",
       "      <td>-0.146959</td>\n",
       "      <td>0.722768</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.111230</td>\n",
       "      <td>-0.739928</td>\n",
       "      <td>1.223488</td>\n",
       "      <td>-0.753769</td>\n",
       "      <td>-0.872757</td>\n",
       "      <td>-0.701238</td>\n",
       "      <td>-1.164787</td>\n",
       "      <td>-0.702866</td>\n",
       "      <td>-1.125666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.915946</td>\n",
       "      <td>-0.914654</td>\n",
       "      <td>-0.728331</td>\n",
       "      <td>-0.753769</td>\n",
       "      <td>-0.508406</td>\n",
       "      <td>-0.687853</td>\n",
       "      <td>-0.935191</td>\n",
       "      <td>-0.690168</td>\n",
       "      <td>-0.893827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.133789</td>\n",
       "      <td>-0.206395</td>\n",
       "      <td>-0.728331</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>-0.184539</td>\n",
       "      <td>-0.152443</td>\n",
       "      <td>0.240450</td>\n",
       "      <td>-0.570001</td>\n",
       "      <td>0.210753</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.152685</td>\n",
       "      <td>0.730923</td>\n",
       "      <td>-0.728331</td>\n",
       "      <td>-0.753769</td>\n",
       "      <td>-0.872757</td>\n",
       "      <td>-0.701238</td>\n",
       "      <td>-0.342449</td>\n",
       "      <td>-0.448977</td>\n",
       "      <td>-0.365602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>0.658606</td>\n",
       "      <td>0.730357</td>\n",
       "      <td>-0.728331</td>\n",
       "      <td>-0.467680</td>\n",
       "      <td>-0.690582</td>\n",
       "      <td>-0.554000</td>\n",
       "      <td>0.368909</td>\n",
       "      <td>0.050437</td>\n",
       "      <td>0.345959</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>-1.834158</td>\n",
       "      <td>-1.766454</td>\n",
       "      <td>-0.728331</td>\n",
       "      <td>-0.801451</td>\n",
       "      <td>-1.237108</td>\n",
       "      <td>-0.728009</td>\n",
       "      <td>-1.955121</td>\n",
       "      <td>-0.715516</td>\n",
       "      <td>-1.797305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>1.213989</td>\n",
       "      <td>0.770692</td>\n",
       "      <td>-0.728331</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>0.757233</td>\n",
       "      <td>0.208960</td>\n",
       "      <td>1.043379</td>\n",
       "      <td>1.705672</td>\n",
       "      <td>1.108529</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>0.694806</td>\n",
       "      <td>0.570557</td>\n",
       "      <td>-0.728331</td>\n",
       "      <td>-0.610725</td>\n",
       "      <td>0.657516</td>\n",
       "      <td>-0.500459</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>0.110239</td>\n",
       "      <td>0.435708</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>-1.707343</td>\n",
       "      <td>-2.325137</td>\n",
       "      <td>-0.728331</td>\n",
       "      <td>-0.753769</td>\n",
       "      <td>1.677698</td>\n",
       "      <td>-0.607541</td>\n",
       "      <td>-1.173967</td>\n",
       "      <td>-0.714176</td>\n",
       "      <td>-1.091454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          총구매액     최대구매액      환불금액      내점일수   내점당구매건수     총구매건수    건평균구매액  \\\n",
       "0     0.566538  0.293396  1.378200  0.056816  0.872291  0.249115  0.737943   \n",
       "1    -1.111230 -0.739928  1.223488 -0.753769 -0.872757 -0.701238 -1.164787   \n",
       "2    -0.915946 -0.914654 -0.728331 -0.753769 -0.508406 -0.687853 -0.935191   \n",
       "3    -0.133789 -0.206395 -0.728331  0.009135 -0.184539 -0.152443  0.240450   \n",
       "4     0.152685  0.730923 -0.728331 -0.753769 -0.872757 -0.701238 -0.342449   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5977  0.658606  0.730357 -0.728331 -0.467680 -0.690582 -0.554000  0.368909   \n",
       "5978 -1.834158 -1.766454 -0.728331 -0.801451 -1.237108 -0.728009 -1.955121   \n",
       "5979  1.213989  0.770692 -0.728331  0.056816  0.757233  0.208960  1.043379   \n",
       "5980  0.694806  0.570557 -0.728331 -0.610725  0.657516 -0.500459  0.452595   \n",
       "5981 -1.707343 -2.325137 -0.728331 -0.753769  1.677698 -0.607541 -1.173967   \n",
       "\n",
       "         비환불금액  구매상품평균금액    주말방문비율  ...  여자제품_여자  고객등급_AVENUEL  고객등급_LENITH  \\\n",
       "0    -0.146959  0.722768  0.527027  ...        0             0            0   \n",
       "1    -0.702866 -1.125666  0.000000  ...        0             0            0   \n",
       "2    -0.690168 -0.893827  0.000000  ...        0             0            0   \n",
       "3    -0.570001  0.210753  0.318182  ...        0             0            0   \n",
       "4    -0.448977 -0.365602  0.000000  ...        0             0            0   \n",
       "...        ...       ...       ...  ...      ...           ...          ...   \n",
       "5977  0.050437  0.345959  0.642857  ...        0             0            0   \n",
       "5978 -0.715516 -1.797305  0.000000  ...        0             0            0   \n",
       "5979  1.705672  1.108529  0.915493  ...        0             1            0   \n",
       "5980  0.110239  0.435708  0.444444  ...        0             0            0   \n",
       "5981 -0.714176 -1.091454  0.000000  ...        0             0            0   \n",
       "\n",
       "      고객등급_MVG-Crown  고객등급_MVG-Prestige  고객등급_VIP  고객등급_VIP+  고객등급_일반  \\\n",
       "0                  0                  1         0          0        0   \n",
       "1                  0                  0         0          0        1   \n",
       "2                  0                  0         0          0        1   \n",
       "3                  0                  0         0          1        0   \n",
       "4                  0                  0         0          1        0   \n",
       "...              ...                ...       ...        ...      ...   \n",
       "5977               0                  1         0          0        0   \n",
       "5978               0                  0         0          0        1   \n",
       "5979               0                  0         0          0        0   \n",
       "5980               0                  1         0          0        0   \n",
       "5981               0                  0         0          0        1   \n",
       "\n",
       "      구매주기_1_구매왕  구매주기_1_나머지  \n",
       "0              0           1  \n",
       "1              0           1  \n",
       "2              0           1  \n",
       "3              0           1  \n",
       "4              0           1  \n",
       "...          ...         ...  \n",
       "5977           0           1  \n",
       "5978           0           1  \n",
       "5979           0           1  \n",
       "5980           0           1  \n",
       "5981           0           1  \n",
       "\n",
       "[5982 rows x 93 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 범주형 변수에 One-Hot-Encoding 후 수치형 변수와 병합\n",
    "\n",
    "features = pd.concat([features[num_features], pd.get_dummies(features[cat_features])], axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Select Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [00:55<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 0.6884363141969262)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습용과 제출용 데이터로 분리\n",
    "features = pd.concat([pd.concat([train_id, test_id]).reset_index(drop=True), features], axis=1)\n",
    "X_train = features.query('cust_id in @train_id').drop('cust_id', axis=1)\n",
    "X_test = features.query('cust_id in @test_id').drop('cust_id', axis=1)\n",
    "\n",
    "# 사용할 모델 설정 (속도가 빠른 모델 사용 권장)\n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "# 각 특성과 타깃(class) 사이에 유의한 통계적 관계가 있는지 계산하여 특성을 선택하는 방법 \n",
    "cv_scores = []\n",
    "for p in tqdm(range(5,100,1)):\n",
    "    X_new = SelectPercentile(percentile=p).fit_transform(X_train, y_train)    #SelectPercentile: 지정된 비율만큼 특성을 선택한다.\n",
    "    cv_score = cross_val_score(model, X_new, y_train, scoring='roc_auc', cv=5).mean()\n",
    "    cv_scores.append((p,cv_score))\n",
    "\n",
    "# Print the best percentile\n",
    "best_score = cv_scores[np.argmax([score for _, score in cv_scores])]\n",
    "print(best_score)\n",
    "\n",
    "# Plot the performance change with p\n",
    "plt.plot([k for k, _ in cv_scores], [score for _, score in cv_scores])\n",
    "plt.xlabel('Percent of features')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 27)\n",
      "['총구매액', '최대구매액', '환불금액', '내점일수', '내점당구매건수', '총구매건수', '건평균구매액', '비환불금액', '구매상품평균금액', '주말방문비율', '생활기간', '상품_mean', '지점_mean', '주구매상품_남성 캐주얼', '주구매상품_남성정장', '주구매상품_농산물', '주구매상품_디자이너', '주구매상품_시티웨어', '주구매상품_주방가전', '주구매상품_화장품', '남자제품_나머지', '남자제품_남성', '여자제품_여자', '고객등급_AVENUEL', '고객등급_LENITH', '고객등급_VIP', '고객등급_일반']\n"
     ]
    }
   ],
   "source": [
    "# 과적합을 피하기 위해 최적의 p값 주변의 값을 선택하는게 더 나은 결과를 얻을 수 있다. \n",
    "fs = SelectPercentile(percentile=best_score[0]).fit(X_train, y_train)\n",
    "X_train = fs.transform(X_train)\n",
    "X_test = fs.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(features.iloc[:,1:].columns[fs.get_support()].tolist()) #get_support: 선택한 특성을 불린값으로 보여줘서 어떤 특성을 선택했는지 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Tuning (bayesianOptimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베이지안 옵티마이져를 다뤄본 것\n",
    "사용하지는 않았음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터 70%, 평가데이터 30%로 데이터 분할\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skfold = StratifiedKFold(n_splits=5) # 교차검증 시 남녀비율을 맞추기 위해 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_evaluate(min_samples_leaf, maxDepth, max_features, colSam,nestimator,learningrate, output = 'score'):\n",
    "    cla=RandomForestClassifier(max_depth= 2)\n",
    "    scores = cross_val_score(cla, X_train, y_train, cv=5, scoring='roc_auc')\n",
    " \n",
    "    if output == 'score' :\n",
    "      return np.mean(scores)\n",
    "    if output == 'model' :\n",
    "      return cla\n",
    " \n",
    "def bayesOpt(train_x, train_y):\n",
    "    randBO = BayesianOptimization(rand_evaluate, { 'learningrate':(0.01,0.2), 'nestimator':(100,500),'min_samples_leaf':  (1,10),  'maxDepth': (2, 90),   'max_features': (17,34),   'colSam': (0.4, 1) })\n",
    "    randBO.maximize(init_points=5, n_iter=30)\n",
    "    print(randBO.res)\n",
    "    return randBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  colSam   | learni... | maxDepth  | max_fe... | min_sa... | nestim... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6672  \u001b[0m | \u001b[0m 0.5927  \u001b[0m | \u001b[0m 0.1459  \u001b[0m | \u001b[0m 37.05   \u001b[0m | \u001b[0m 22.18   \u001b[0m | \u001b[0m 9.814   \u001b[0m | \u001b[0m 223.3   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.667   \u001b[0m | \u001b[0m 0.8909  \u001b[0m | \u001b[0m 0.1193  \u001b[0m | \u001b[0m 59.32   \u001b[0m | \u001b[0m 20.94   \u001b[0m | \u001b[0m 9.103   \u001b[0m | \u001b[0m 357.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.667   \u001b[0m | \u001b[0m 0.5129  \u001b[0m | \u001b[0m 0.1659  \u001b[0m | \u001b[0m 51.46   \u001b[0m | \u001b[0m 19.68   \u001b[0m | \u001b[0m 5.15    \u001b[0m | \u001b[0m 184.3   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.6688  \u001b[0m | \u001b[95m 0.973   \u001b[0m | \u001b[95m 0.06578 \u001b[0m | \u001b[95m 24.08   \u001b[0m | \u001b[95m 30.81   \u001b[0m | \u001b[95m 1.819   \u001b[0m | \u001b[95m 177.4   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.6699  \u001b[0m | \u001b[95m 0.7019  \u001b[0m | \u001b[95m 0.1965  \u001b[0m | \u001b[95m 27.63   \u001b[0m | \u001b[95m 22.42   \u001b[0m | \u001b[95m 9.391   \u001b[0m | \u001b[95m 392.8   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6663  \u001b[0m | \u001b[0m 0.9336  \u001b[0m | \u001b[0m 0.1346  \u001b[0m | \u001b[0m 25.11   \u001b[0m | \u001b[0m 28.73   \u001b[0m | \u001b[0m 2.474   \u001b[0m | \u001b[0m 177.4   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6681  \u001b[0m | \u001b[0m 0.8204  \u001b[0m | \u001b[0m 0.1229  \u001b[0m | \u001b[0m 65.32   \u001b[0m | \u001b[0m 31.6    \u001b[0m | \u001b[0m 2.66    \u001b[0m | \u001b[0m 312.5   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6684  \u001b[0m | \u001b[0m 0.6605  \u001b[0m | \u001b[0m 0.1138  \u001b[0m | \u001b[0m 45.29   \u001b[0m | \u001b[0m 23.42   \u001b[0m | \u001b[0m 9.305   \u001b[0m | \u001b[0m 223.5   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6695  \u001b[0m | \u001b[0m 0.658   \u001b[0m | \u001b[0m 0.02467 \u001b[0m | \u001b[0m 31.5    \u001b[0m | \u001b[0m 26.73   \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m 192.9   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6685  \u001b[0m | \u001b[0m 0.4226  \u001b[0m | \u001b[0m 0.1878  \u001b[0m | \u001b[0m 73.29   \u001b[0m | \u001b[0m 29.14   \u001b[0m | \u001b[0m 6.635   \u001b[0m | \u001b[0m 251.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6686  \u001b[0m | \u001b[0m 0.4537  \u001b[0m | \u001b[0m 0.1291  \u001b[0m | \u001b[0m 10.54   \u001b[0m | \u001b[0m 26.19   \u001b[0m | \u001b[0m 9.251   \u001b[0m | \u001b[0m 325.0   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.6702  \u001b[0m | \u001b[95m 0.5724  \u001b[0m | \u001b[95m 0.06725 \u001b[0m | \u001b[95m 50.01   \u001b[0m | \u001b[95m 28.67   \u001b[0m | \u001b[95m 4.637   \u001b[0m | \u001b[95m 477.6   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.6709  \u001b[0m | \u001b[95m 0.9544  \u001b[0m | \u001b[95m 0.1495  \u001b[0m | \u001b[95m 79.48   \u001b[0m | \u001b[95m 26.33   \u001b[0m | \u001b[95m 5.778   \u001b[0m | \u001b[95m 383.5   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6692  \u001b[0m | \u001b[0m 0.567   \u001b[0m | \u001b[0m 0.06154 \u001b[0m | \u001b[0m 24.28   \u001b[0m | \u001b[0m 30.69   \u001b[0m | \u001b[0m 7.047   \u001b[0m | \u001b[0m 458.9   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6677  \u001b[0m | \u001b[0m 0.469   \u001b[0m | \u001b[0m 0.0247  \u001b[0m | \u001b[0m 45.38   \u001b[0m | \u001b[0m 22.84   \u001b[0m | \u001b[0m 8.471   \u001b[0m | \u001b[0m 163.7   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6698  \u001b[0m | \u001b[0m 0.5677  \u001b[0m | \u001b[0m 0.07786 \u001b[0m | \u001b[0m 50.61   \u001b[0m | \u001b[0m 29.07   \u001b[0m | \u001b[0m 4.507   \u001b[0m | \u001b[0m 115.2   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6683  \u001b[0m | \u001b[0m 0.7183  \u001b[0m | \u001b[0m 0.09085 \u001b[0m | \u001b[0m 59.0    \u001b[0m | \u001b[0m 33.1    \u001b[0m | \u001b[0m 5.186   \u001b[0m | \u001b[0m 334.7   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6691  \u001b[0m | \u001b[0m 0.6511  \u001b[0m | \u001b[0m 0.06171 \u001b[0m | \u001b[0m 48.34   \u001b[0m | \u001b[0m 17.15   \u001b[0m | \u001b[0m 5.596   \u001b[0m | \u001b[0m 273.1   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6692  \u001b[0m | \u001b[0m 0.6943  \u001b[0m | \u001b[0m 0.109   \u001b[0m | \u001b[0m 81.08   \u001b[0m | \u001b[0m 29.53   \u001b[0m | \u001b[0m 8.616   \u001b[0m | \u001b[0m 184.1   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.67    \u001b[0m | \u001b[0m 0.4226  \u001b[0m | \u001b[0m 0.195   \u001b[0m | \u001b[0m 18.35   \u001b[0m | \u001b[0m 22.72   \u001b[0m | \u001b[0m 6.881   \u001b[0m | \u001b[0m 282.9   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6684  \u001b[0m | \u001b[0m 0.9735  \u001b[0m | \u001b[0m 0.1574  \u001b[0m | \u001b[0m 19.41   \u001b[0m | \u001b[0m 28.47   \u001b[0m | \u001b[0m 3.772   \u001b[0m | \u001b[0m 452.8   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.669   \u001b[0m | \u001b[0m 0.7795  \u001b[0m | \u001b[0m 0.164   \u001b[0m | \u001b[0m 17.13   \u001b[0m | \u001b[0m 24.61   \u001b[0m | \u001b[0m 4.671   \u001b[0m | \u001b[0m 216.6   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6686  \u001b[0m | \u001b[0m 0.5753  \u001b[0m | \u001b[0m 0.1915  \u001b[0m | \u001b[0m 65.66   \u001b[0m | \u001b[0m 27.44   \u001b[0m | \u001b[0m 2.984   \u001b[0m | \u001b[0m 422.9   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6676  \u001b[0m | \u001b[0m 0.7277  \u001b[0m | \u001b[0m 0.05802 \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 20.82   \u001b[0m | \u001b[0m 9.58    \u001b[0m | \u001b[0m 485.8   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6698  \u001b[0m | \u001b[0m 0.5506  \u001b[0m | \u001b[0m 0.02619 \u001b[0m | \u001b[0m 21.01   \u001b[0m | \u001b[0m 21.4    \u001b[0m | \u001b[0m 1.121   \u001b[0m | \u001b[0m 284.5   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6669  \u001b[0m | \u001b[0m 0.5725  \u001b[0m | \u001b[0m 0.1582  \u001b[0m | \u001b[0m 49.99   \u001b[0m | \u001b[0m 26.45   \u001b[0m | \u001b[0m 9.439   \u001b[0m | \u001b[0m 120.4   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.667   \u001b[0m | \u001b[0m 0.5319  \u001b[0m | \u001b[0m 0.1524  \u001b[0m | \u001b[0m 23.8    \u001b[0m | \u001b[0m 19.87   \u001b[0m | \u001b[0m 9.356   \u001b[0m | \u001b[0m 389.1   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6676  \u001b[0m | \u001b[0m 0.9861  \u001b[0m | \u001b[0m 0.05973 \u001b[0m | \u001b[0m 65.49   \u001b[0m | \u001b[0m 32.98   \u001b[0m | \u001b[0m 5.045   \u001b[0m | \u001b[0m 391.8   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6683  \u001b[0m | \u001b[0m 0.6632  \u001b[0m | \u001b[0m 0.01339 \u001b[0m | \u001b[0m 71.43   \u001b[0m | \u001b[0m 30.23   \u001b[0m | \u001b[0m 4.815   \u001b[0m | \u001b[0m 165.8   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6679  \u001b[0m | \u001b[0m 0.5705  \u001b[0m | \u001b[0m 0.04891 \u001b[0m | \u001b[0m 57.98   \u001b[0m | \u001b[0m 32.78   \u001b[0m | \u001b[0m 3.816   \u001b[0m | \u001b[0m 233.4   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6708  \u001b[0m | \u001b[0m 0.8194  \u001b[0m | \u001b[0m 0.09097 \u001b[0m | \u001b[0m 56.46   \u001b[0m | \u001b[0m 27.94   \u001b[0m | \u001b[0m 3.682   \u001b[0m | \u001b[0m 277.1   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6682  \u001b[0m | \u001b[0m 0.7883  \u001b[0m | \u001b[0m 0.1905  \u001b[0m | \u001b[0m 56.48   \u001b[0m | \u001b[0m 31.34   \u001b[0m | \u001b[0m 5.084   \u001b[0m | \u001b[0m 215.1   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6686  \u001b[0m | \u001b[0m 0.8166  \u001b[0m | \u001b[0m 0.1042  \u001b[0m | \u001b[0m 78.14   \u001b[0m | \u001b[0m 27.51   \u001b[0m | \u001b[0m 8.762   \u001b[0m | \u001b[0m 284.7   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6694  \u001b[0m | \u001b[0m 0.729   \u001b[0m | \u001b[0m 0.1015  \u001b[0m | \u001b[0m 18.81   \u001b[0m | \u001b[0m 23.48   \u001b[0m | \u001b[0m 7.692   \u001b[0m | \u001b[0m 350.0   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.669   \u001b[0m | \u001b[0m 0.4648  \u001b[0m | \u001b[0m 0.02804 \u001b[0m | \u001b[0m 57.57   \u001b[0m | \u001b[0m 25.32   \u001b[0m | \u001b[0m 1.514   \u001b[0m | \u001b[0m 270.0   \u001b[0m |\n",
      "=================================================================================================\n",
      "[{'target': 0.6672141025959681, 'params': {'colSam': 0.59267666590183, 'learningrate': 0.14588959321663314, 'maxDepth': 37.04888869049979, 'max_features': 22.17556212430636, 'min_samples_leaf': 9.813819548503425, 'nestimator': 223.2786417085556}}, {'target': 0.6670174410642403, 'params': {'colSam': 0.890880117999952, 'learningrate': 0.11932166985996165, 'maxDepth': 59.32061972147847, 'max_features': 20.944069706474263, 'min_samples_leaf': 9.103486066544615, 'nestimator': 357.2952465828072}}, {'target': 0.666980476104886, 'params': {'colSam': 0.5129293229560133, 'learningrate': 0.16591957369471846, 'maxDepth': 51.46432266290416, 'max_features': 19.6775382845748, 'min_samples_leaf': 5.1495299518234114, 'nestimator': 184.33610319080654}}, {'target': 0.6688180666101664, 'params': {'colSam': 0.9729697594347626, 'learningrate': 0.06578107958211654, 'maxDepth': 24.078164579635853, 'max_features': 30.81444838121275, 'min_samples_leaf': 1.8186551929413723, 'nestimator': 177.35878508617233}}, {'target': 0.669927713834002, 'params': {'colSam': 0.7018632396991739, 'learningrate': 0.19651845959604694, 'maxDepth': 27.63134528936695, 'max_features': 22.41780678242507, 'min_samples_leaf': 9.390500632151904, 'nestimator': 392.76051107230506}}, {'target': 0.666337176199893, 'params': {'colSam': 0.933616578494682, 'learningrate': 0.13463261855408415, 'maxDepth': 25.105523475587475, 'max_features': 28.733696784702698, 'min_samples_leaf': 2.4737192245983874, 'nestimator': 177.44154212215574}}, {'target': 0.668113486764386, 'params': {'colSam': 0.8203945119742313, 'learningrate': 0.1229408844610707, 'maxDepth': 65.31520981182744, 'max_features': 31.597871660644437, 'min_samples_leaf': 2.6597605251789043, 'nestimator': 312.5160407549753}}, {'target': 0.6683591241564484, 'params': {'colSam': 0.660454979082665, 'learningrate': 0.11384620708328595, 'maxDepth': 45.29241574599845, 'max_features': 23.424734900895302, 'min_samples_leaf': 9.304937003812627, 'nestimator': 223.52104570650158}}, {'target': 0.6695133718342872, 'params': {'colSam': 0.6580353310188196, 'learningrate': 0.02466911240701146, 'maxDepth': 31.496045985378423, 'max_features': 26.731924147060333, 'min_samples_leaf': 1.0110749097816838, 'nestimator': 192.89575383995668}}, {'target': 0.668531954813378, 'params': {'colSam': 0.4226017027293181, 'learningrate': 0.18781818772122746, 'maxDepth': 73.28976423909799, 'max_features': 29.13912436149722, 'min_samples_leaf': 6.63503863511582, 'nestimator': 251.35866356533018}}, {'target': 0.6686147754393936, 'params': {'colSam': 0.4537180970777953, 'learningrate': 0.1290900870646947, 'maxDepth': 10.541565306624848, 'max_features': 26.19469541837673, 'min_samples_leaf': 9.251246538917673, 'nestimator': 324.9818189908432}}, {'target': 0.6702143869884841, 'params': {'colSam': 0.5723514245854364, 'learningrate': 0.06724865107717234, 'maxDepth': 50.00552854334891, 'max_features': 28.66552772636843, 'min_samples_leaf': 4.636510748649421, 'nestimator': 477.6392553023162}}, {'target': 0.670903941081964, 'params': {'colSam': 0.9543719547617695, 'learningrate': 0.149509361347902, 'maxDepth': 79.4823613455046, 'max_features': 26.327949408885424, 'min_samples_leaf': 5.778115355848725, 'nestimator': 383.5384930865464}}, {'target': 0.669170547460219, 'params': {'colSam': 0.5670363166844562, 'learningrate': 0.06153696477332278, 'maxDepth': 24.28061895750155, 'max_features': 30.68859624163274, 'min_samples_leaf': 7.047078583150639, 'nestimator': 458.91642442305056}}, {'target': 0.6677137907226756, 'params': {'colSam': 0.46896698706058965, 'learningrate': 0.0246972069053127, 'maxDepth': 45.37623426186177, 'max_features': 22.837836433015333, 'min_samples_leaf': 8.470855316412248, 'nestimator': 163.68694367171722}}, {'target': 0.6698466909571712, 'params': {'colSam': 0.5677164680366542, 'learningrate': 0.077862106754028, 'maxDepth': 50.60512106669093, 'max_features': 29.068700940144126, 'min_samples_leaf': 4.507374415433711, 'nestimator': 115.22869300362788}}, {'target': 0.6683493648663279, 'params': {'colSam': 0.7183213861150518, 'learningrate': 0.0908477411395034, 'maxDepth': 58.998410501848895, 'max_features': 33.10256571567618, 'min_samples_leaf': 5.185513511376493, 'nestimator': 334.66638377809886}}, {'target': 0.6690889883205837, 'params': {'colSam': 0.6511193497838381, 'learningrate': 0.06170888236099927, 'maxDepth': 48.33761873783072, 'max_features': 17.147747323826856, 'min_samples_leaf': 5.596125904020135, 'nestimator': 273.1458814890745}}, {'target': 0.6692351558448065, 'params': {'colSam': 0.6943240351436499, 'learningrate': 0.10896390958818906, 'maxDepth': 81.07514741116007, 'max_features': 29.53073438908538, 'min_samples_leaf': 8.616407642329957, 'nestimator': 184.11685222933514}}, {'target': 0.6699819128959236, 'params': {'colSam': 0.42256120094349897, 'learningrate': 0.1949701937551093, 'maxDepth': 18.345092102480827, 'max_features': 22.715842927365763, 'min_samples_leaf': 6.88068155756442, 'nestimator': 282.91641931310255}}, {'target': 0.6684271255948125, 'params': {'colSam': 0.9735058695743783, 'learningrate': 0.1573521167240387, 'maxDepth': 19.407601617930332, 'max_features': 28.466147198538614, 'min_samples_leaf': 3.7724494243276445, 'nestimator': 452.81395348617775}}, {'target': 0.6689698282346961, 'params': {'colSam': 0.7795034015818405, 'learningrate': 0.16399273416088975, 'maxDepth': 17.125535229833346, 'max_features': 24.61342810922142, 'min_samples_leaf': 4.671453448297698, 'nestimator': 216.5732270774488}}, {'target': 0.6686156163991013, 'params': {'colSam': 0.5752592473755658, 'learningrate': 0.19154421979261127, 'maxDepth': 65.6580418405525, 'max_features': 27.437478964318018, 'min_samples_leaf': 2.9843190838269558, 'nestimator': 422.8789627309669}}, {'target': 0.6675929763404783, 'params': {'colSam': 0.7277367257342936, 'learningrate': 0.05802044559951026, 'maxDepth': 10.717203514013182, 'max_features': 20.815279113660768, 'min_samples_leaf': 9.580181738559551, 'nestimator': 485.83179798592676}}, {'target': 0.6698054053695093, 'params': {'colSam': 0.550616242106104, 'learningrate': 0.0261890627871067, 'maxDepth': 21.00915706423089, 'max_features': 21.40242571987011, 'min_samples_leaf': 1.1206293112203676, 'nestimator': 284.4897075412696}}, {'target': 0.6668733242981244, 'params': {'colSam': 0.5725446125321456, 'learningrate': 0.15821944839594126, 'maxDepth': 49.990103525005786, 'max_features': 26.45475191566473, 'min_samples_leaf': 9.43873556142722, 'nestimator': 120.44638333186538}}, {'target': 0.6670135168977299, 'params': {'colSam': 0.5319331723091003, 'learningrate': 0.1524087068411512, 'maxDepth': 23.799841220821403, 'max_features': 19.866301748489576, 'min_samples_leaf': 9.355880353375923, 'nestimator': 389.0921286868109}}, {'target': 0.6676457193369891, 'params': {'colSam': 0.9860529187413056, 'learningrate': 0.05973130616986246, 'maxDepth': 65.49382905248598, 'max_features': 32.98195919387818, 'min_samples_leaf': 5.045495014778159, 'nestimator': 391.8016149472566}}, {'target': 0.6682529573240956, 'params': {'colSam': 0.6632072478521486, 'learningrate': 0.013389751182193835, 'maxDepth': 71.42966099923817, 'max_features': 30.225710000264748, 'min_samples_leaf': 4.815106198710767, 'nestimator': 165.75610893756686}}, {'target': 0.6678705631786089, 'params': {'colSam': 0.5705411822130664, 'learningrate': 0.048909492908350886, 'maxDepth': 57.97813926336202, 'max_features': 32.779658385468146, 'min_samples_leaf': 3.8162764401570346, 'nestimator': 233.3841200494613}}, {'target': 0.6708368792037499, 'params': {'colSam': 0.8194084306784504, 'learningrate': 0.09096966799944063, 'maxDepth': 56.46203785793356, 'max_features': 27.94042594612214, 'min_samples_leaf': 3.682141349534054, 'nestimator': 277.1444719369913}}, {'target': 0.6681847065286775, 'params': {'colSam': 0.7883493068506675, 'learningrate': 0.19052655196730306, 'maxDepth': 56.48034613498605, 'max_features': 31.3416651255836, 'min_samples_leaf': 5.0836761892987745, 'nestimator': 215.1284494567504}}, {'target': 0.6686395943786428, 'params': {'colSam': 0.8165627164740057, 'learningrate': 0.10416933105811103, 'maxDepth': 78.14012390377641, 'max_features': 27.505129696403593, 'min_samples_leaf': 8.762467316467603, 'nestimator': 284.6643179260641}}, {'target': 0.6694207204726265, 'params': {'colSam': 0.728964815729679, 'learningrate': 0.10153954560332488, 'maxDepth': 18.813024401549903, 'max_features': 23.48263838661857, 'min_samples_leaf': 7.691688750396134, 'nestimator': 349.9960488229133}}, {'target': 0.6689949748120722, 'params': {'colSam': 0.4647668087196929, 'learningrate': 0.028036059102584367, 'maxDepth': 57.56770271205868, 'max_features': 25.319495845077032, 'min_samples_leaf': 1.5144572036252604, 'nestimator': 269.961040766424}}]\n"
     ]
    }
   ],
   "source": [
    "randBO = bayesOpt(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rand = randBO.max['params']\n",
    " \n",
    "# 모델에 적용\n",
    "model = rand_evaluate(\n",
    "    learningrate=params_rand['learningrate'],\n",
    "    nestimator=params_rand['nestimator'],\n",
    "     maxDepth = params_rand['maxDepth'],\n",
    "     colSam = params_rand['colSam'],\n",
    "    min_samples_leaf=params_rand['min_samples_leaf'],\n",
    "    max_features=params_rand['max_features'],\n",
    "     output = 'model'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colSam': 0.9543719547617695,\n",
       " 'learningrate': 0.149509361347902,\n",
       " 'maxDepth': 79.4823613455046,\n",
       " 'max_features': 26.327949408885424,\n",
       " 'min_samples_leaf': 5.778115355848725,\n",
       " 'nestimator': 383.5384930865464}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_evaluate(numLeaves, maxDepth, scaleWeight, minChildWeight, subsample, colSam,nestimator,learningrate, output = 'score'):\n",
    "    cla=lgb.LGBMClassifier(num_leaves=31, max_depth= 2,scale_pos_weight= scaleWeight, min_child_weight= minChildWeight, subsample= 0.4, colsample_bytree= 0.4)\n",
    "    scores = cross_val_score(cla, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    # scores = cross_val_score(reg, train_x, train_y, cv=5, scoring='neg_mean_squared_error')\n",
    " \n",
    "    if output == 'score' :\n",
    "      return np.mean(scores)\n",
    "    if output == 'model' :\n",
    "      return cla\n",
    " \n",
    "def bayesOpt(train_x, train_y):\n",
    "    lgbBO = BayesianOptimization(lgb_evaluate, { 'learningrate':(0.01,0.2), 'nestimator':(100,500),'numLeaves':  (5, 90),  'maxDepth': (2, 90),   'scaleWeight': (1, 10000),  'minChildWeight': (0.01, 70), 'subsample': (0.4, 1), 'colSam': (0.4, 1) })\n",
    "    lgbBO.maximize(init_points=5, n_iter=30)\n",
    "    print(lgbBO.res)\n",
    "    return lgbBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  colSam   | learni... | maxDepth  | minChi... | nestim... | numLeaves | scaleW... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.693   \u001b[0m | \u001b[0m 0.7456  \u001b[0m | \u001b[0m 0.03626 \u001b[0m | \u001b[0m 24.4    \u001b[0m | \u001b[0m 31.4    \u001b[0m | \u001b[0m 110.2   \u001b[0m | \u001b[0m 12.32   \u001b[0m | \u001b[0m 1.08e+03\u001b[0m | \u001b[0m 0.6265  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6959  \u001b[0m | \u001b[95m 0.5899  \u001b[0m | \u001b[95m 0.02393 \u001b[0m | \u001b[95m 67.38   \u001b[0m | \u001b[95m 2.259   \u001b[0m | \u001b[95m 381.5   \u001b[0m | \u001b[95m 58.57   \u001b[0m | \u001b[95m 1.145e+0\u001b[0m | \u001b[95m 0.5061  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6934  \u001b[0m | \u001b[0m 0.4135  \u001b[0m | \u001b[0m 0.02135 \u001b[0m | \u001b[0m 85.32   \u001b[0m | \u001b[0m 2.506   \u001b[0m | \u001b[0m 375.2   \u001b[0m | \u001b[0m 28.92   \u001b[0m | \u001b[0m 766.3   \u001b[0m | \u001b[0m 0.9209  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6913  \u001b[0m | \u001b[0m 0.8375  \u001b[0m | \u001b[0m 0.03399 \u001b[0m | \u001b[0m 21.89   \u001b[0m | \u001b[0m 54.03   \u001b[0m | \u001b[0m 112.8   \u001b[0m | \u001b[0m 62.87   \u001b[0m | \u001b[0m 264.5   \u001b[0m | \u001b[0m 0.6149  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6906  \u001b[0m | \u001b[0m 0.7103  \u001b[0m | \u001b[0m 0.07591 \u001b[0m | \u001b[0m 37.66   \u001b[0m | \u001b[0m 11.62   \u001b[0m | \u001b[0m 365.8   \u001b[0m | \u001b[0m 89.95   \u001b[0m | \u001b[0m 9.144e+0\u001b[0m | \u001b[0m 0.5486  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.69    \u001b[0m | \u001b[0m 0.9692  \u001b[0m | \u001b[0m 0.1662  \u001b[0m | \u001b[0m 40.13   \u001b[0m | \u001b[0m 21.99   \u001b[0m | \u001b[0m 251.4   \u001b[0m | \u001b[0m 41.98   \u001b[0m | \u001b[0m 5.625e+0\u001b[0m | \u001b[0m 0.4926  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6905  \u001b[0m | \u001b[0m 0.8442  \u001b[0m | \u001b[0m 0.0578  \u001b[0m | \u001b[0m 26.23   \u001b[0m | \u001b[0m 45.31   \u001b[0m | \u001b[0m 481.9   \u001b[0m | \u001b[0m 33.81   \u001b[0m | \u001b[0m 1.319e+0\u001b[0m | \u001b[0m 0.4031  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.693   \u001b[0m | \u001b[0m 0.5273  \u001b[0m | \u001b[0m 0.1963  \u001b[0m | \u001b[0m 58.19   \u001b[0m | \u001b[0m 8.106   \u001b[0m | \u001b[0m 373.4   \u001b[0m | \u001b[0m 65.36   \u001b[0m | \u001b[0m 1.142e+0\u001b[0m | \u001b[0m 0.4101  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6914  \u001b[0m | \u001b[0m 0.7307  \u001b[0m | \u001b[0m 0.02557 \u001b[0m | \u001b[0m 46.89   \u001b[0m | \u001b[0m 10.42   \u001b[0m | \u001b[0m 434.8   \u001b[0m | \u001b[0m 29.56   \u001b[0m | \u001b[0m 5.42e+03\u001b[0m | \u001b[0m 0.4471  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6924  \u001b[0m | \u001b[0m 0.8838  \u001b[0m | \u001b[0m 0.02437 \u001b[0m | \u001b[0m 63.99   \u001b[0m | \u001b[0m 18.39   \u001b[0m | \u001b[0m 397.5   \u001b[0m | \u001b[0m 62.22   \u001b[0m | \u001b[0m 1.155e+0\u001b[0m | \u001b[0m 0.4178  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6923  \u001b[0m | \u001b[0m 0.5792  \u001b[0m | \u001b[0m 0.03469 \u001b[0m | \u001b[0m 25.52   \u001b[0m | \u001b[0m 43.16   \u001b[0m | \u001b[0m 102.4   \u001b[0m | \u001b[0m 9.441   \u001b[0m | \u001b[0m 1.086e+0\u001b[0m | \u001b[0m 0.9829  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6933  \u001b[0m | \u001b[0m 0.9602  \u001b[0m | \u001b[0m 0.1332  \u001b[0m | \u001b[0m 68.02   \u001b[0m | \u001b[0m 17.73   \u001b[0m | \u001b[0m 377.6   \u001b[0m | \u001b[0m 35.79   \u001b[0m | \u001b[0m 1.134e+0\u001b[0m | \u001b[0m 0.6167  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6927  \u001b[0m | \u001b[0m 0.9315  \u001b[0m | \u001b[0m 0.1641  \u001b[0m | \u001b[0m 37.13   \u001b[0m | \u001b[0m 11.42   \u001b[0m | \u001b[0m 182.5   \u001b[0m | \u001b[0m 27.29   \u001b[0m | \u001b[0m 886.0   \u001b[0m | \u001b[0m 0.6557  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6918  \u001b[0m | \u001b[0m 0.8256  \u001b[0m | \u001b[0m 0.09357 \u001b[0m | \u001b[0m 77.1    \u001b[0m | \u001b[0m 15.69   \u001b[0m | \u001b[0m 387.5   \u001b[0m | \u001b[0m 37.15   \u001b[0m | \u001b[0m 749.3   \u001b[0m | \u001b[0m 0.4347  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6913  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.1128  \u001b[0m | \u001b[0m 25.13   \u001b[0m | \u001b[0m 28.33   \u001b[0m | \u001b[0m 109.4   \u001b[0m | \u001b[0m 10.64   \u001b[0m | \u001b[0m 1.066e+0\u001b[0m | \u001b[0m 0.4817  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6934  \u001b[0m | \u001b[0m 0.8629  \u001b[0m | \u001b[0m 0.1554  \u001b[0m | \u001b[0m 58.22   \u001b[0m | \u001b[0m 18.19   \u001b[0m | \u001b[0m 367.3   \u001b[0m | \u001b[0m 17.77   \u001b[0m | \u001b[0m 1.148e+0\u001b[0m | \u001b[0m 0.6433  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6933  \u001b[0m | \u001b[0m 0.8189  \u001b[0m | \u001b[0m 0.1601  \u001b[0m | \u001b[0m 56.75   \u001b[0m | \u001b[0m 21.98   \u001b[0m | \u001b[0m 391.9   \u001b[0m | \u001b[0m 33.3    \u001b[0m | \u001b[0m 1.12e+03\u001b[0m | \u001b[0m 0.6156  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6892  \u001b[0m | \u001b[0m 0.5397  \u001b[0m | \u001b[0m 0.1248  \u001b[0m | \u001b[0m 38.88   \u001b[0m | \u001b[0m 22.81   \u001b[0m | \u001b[0m 185.9   \u001b[0m | \u001b[0m 30.54   \u001b[0m | \u001b[0m 8.361e+0\u001b[0m | \u001b[0m 0.646   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6904  \u001b[0m | \u001b[0m 0.7987  \u001b[0m | \u001b[0m 0.03211 \u001b[0m | \u001b[0m 45.0    \u001b[0m | \u001b[0m 21.44   \u001b[0m | \u001b[0m 214.3   \u001b[0m | \u001b[0m 50.54   \u001b[0m | \u001b[0m 4.546e+0\u001b[0m | \u001b[0m 0.407   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6916  \u001b[0m | \u001b[0m 0.4028  \u001b[0m | \u001b[0m 0.1771  \u001b[0m | \u001b[0m 58.34   \u001b[0m | \u001b[0m 62.39   \u001b[0m | \u001b[0m 138.8   \u001b[0m | \u001b[0m 86.85   \u001b[0m | \u001b[0m 62.58   \u001b[0m | \u001b[0m 0.8109  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6957  \u001b[0m | \u001b[0m 0.4809  \u001b[0m | \u001b[0m 0.01806 \u001b[0m | \u001b[0m 52.51   \u001b[0m | \u001b[0m 4.058   \u001b[0m | \u001b[0m 392.9   \u001b[0m | \u001b[0m 17.57   \u001b[0m | \u001b[0m 1.124e+0\u001b[0m | \u001b[0m 0.4756  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6937  \u001b[0m | \u001b[0m 0.4068  \u001b[0m | \u001b[0m 0.1726  \u001b[0m | \u001b[0m 89.12   \u001b[0m | \u001b[0m 6.384   \u001b[0m | \u001b[0m 361.5   \u001b[0m | \u001b[0m 81.07   \u001b[0m | \u001b[0m 1.149e+0\u001b[0m | \u001b[0m 0.6844  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6913  \u001b[0m | \u001b[0m 0.7145  \u001b[0m | \u001b[0m 0.07681 \u001b[0m | \u001b[0m 70.03   \u001b[0m | \u001b[0m 23.92   \u001b[0m | \u001b[0m 256.7   \u001b[0m | \u001b[0m 61.48   \u001b[0m | \u001b[0m 2.379e+0\u001b[0m | \u001b[0m 0.4144  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6928  \u001b[0m | \u001b[0m 0.4724  \u001b[0m | \u001b[0m 0.1672  \u001b[0m | \u001b[0m 67.53   \u001b[0m | \u001b[0m 14.75   \u001b[0m | \u001b[0m 207.0   \u001b[0m | \u001b[0m 56.66   \u001b[0m | \u001b[0m 1.148e+0\u001b[0m | \u001b[0m 0.8991  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6927  \u001b[0m | \u001b[0m 0.7682  \u001b[0m | \u001b[0m 0.1375  \u001b[0m | \u001b[0m 36.97   \u001b[0m | \u001b[0m 18.39   \u001b[0m | \u001b[0m 373.4   \u001b[0m | \u001b[0m 40.34   \u001b[0m | \u001b[0m 1.133e+0\u001b[0m | \u001b[0m 0.5914  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6953  \u001b[0m | \u001b[0m 0.9381  \u001b[0m | \u001b[0m 0.08633 \u001b[0m | \u001b[0m 77.86   \u001b[0m | \u001b[0m 4.125   \u001b[0m | \u001b[0m 362.6   \u001b[0m | \u001b[0m 82.53   \u001b[0m | \u001b[0m 1.131e+0\u001b[0m | \u001b[0m 0.9377  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6915  \u001b[0m | \u001b[0m 0.4579  \u001b[0m | \u001b[0m 0.0987  \u001b[0m | \u001b[0m 64.52   \u001b[0m | \u001b[0m 67.75   \u001b[0m | \u001b[0m 229.2   \u001b[0m | \u001b[0m 84.54   \u001b[0m | \u001b[0m 5.86e+03\u001b[0m | \u001b[0m 0.7866  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6943  \u001b[0m | \u001b[0m 0.7141  \u001b[0m | \u001b[0m 0.1048  \u001b[0m | \u001b[0m 32.59   \u001b[0m | \u001b[0m 9.122   \u001b[0m | \u001b[0m 376.6   \u001b[0m | \u001b[0m 28.6    \u001b[0m | \u001b[0m 2.318e+0\u001b[0m | \u001b[0m 0.5817  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6873  \u001b[0m | \u001b[0m 0.8209  \u001b[0m | \u001b[0m 0.1714  \u001b[0m | \u001b[0m 36.29   \u001b[0m | \u001b[0m 25.48   \u001b[0m | \u001b[0m 105.3   \u001b[0m | \u001b[0m 80.39   \u001b[0m | \u001b[0m 8.867e+0\u001b[0m | \u001b[0m 0.7336  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6931  \u001b[0m | \u001b[0m 0.7179  \u001b[0m | \u001b[0m 0.1147  \u001b[0m | \u001b[0m 8.481   \u001b[0m | \u001b[0m 12.07   \u001b[0m | \u001b[0m 225.9   \u001b[0m | \u001b[0m 52.81   \u001b[0m | \u001b[0m 2.329e+0\u001b[0m | \u001b[0m 0.5507  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6918  \u001b[0m | \u001b[0m 0.5925  \u001b[0m | \u001b[0m 0.1665  \u001b[0m | \u001b[0m 35.99   \u001b[0m | \u001b[0m 64.72   \u001b[0m | \u001b[0m 306.8   \u001b[0m | \u001b[0m 35.87   \u001b[0m | \u001b[0m 1.144e+0\u001b[0m | \u001b[0m 0.9795  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.687   \u001b[0m | \u001b[0m 0.4084  \u001b[0m | \u001b[0m 0.04159 \u001b[0m | \u001b[0m 69.36   \u001b[0m | \u001b[0m 47.86   \u001b[0m | \u001b[0m 201.6   \u001b[0m | \u001b[0m 82.67   \u001b[0m | \u001b[0m 7.722e+0\u001b[0m | \u001b[0m 0.9448  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6928  \u001b[0m | \u001b[0m 0.56    \u001b[0m | \u001b[0m 0.1309  \u001b[0m | \u001b[0m 61.37   \u001b[0m | \u001b[0m 3.217   \u001b[0m | \u001b[0m 179.8   \u001b[0m | \u001b[0m 40.84   \u001b[0m | \u001b[0m 6.476e+0\u001b[0m | \u001b[0m 0.4167  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6941  \u001b[0m | \u001b[0m 0.4568  \u001b[0m | \u001b[0m 0.1457  \u001b[0m | \u001b[0m 69.59   \u001b[0m | \u001b[0m 7.355   \u001b[0m | \u001b[0m 387.4   \u001b[0m | \u001b[0m 61.3    \u001b[0m | \u001b[0m 1.113e+0\u001b[0m | \u001b[0m 0.4834  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6895  \u001b[0m | \u001b[0m 0.6939  \u001b[0m | \u001b[0m 0.1635  \u001b[0m | \u001b[0m 2.691   \u001b[0m | \u001b[0m 19.78   \u001b[0m | \u001b[0m 255.5   \u001b[0m | \u001b[0m 52.04   \u001b[0m | \u001b[0m 7.526e+0\u001b[0m | \u001b[0m 0.8912  \u001b[0m |\n",
      "=========================================================================================================================\n",
      "[{'target': 0.6929933503187531, 'params': {'colSam': 0.745578785609456, 'learningrate': 0.03626176235443038, 'maxDepth': 24.39669164158878, 'minChildWeight': 31.402101232618012, 'nestimator': 110.23365717535647, 'numLeaves': 12.324745238824892, 'scaleWeight': 1079.7873022457316, 'subsample': 0.6265021300328173}}, {'target': 0.6959467743126555, 'params': {'colSam': 0.5899345427049327, 'learningrate': 0.023930536433008, 'maxDepth': 67.3847264821173, 'minChildWeight': 2.2592437085969928, 'nestimator': 381.48036249258377, 'numLeaves': 58.57403739538251, 'scaleWeight': 1145.211831114847, 'subsample': 0.506106176585304}}, {'target': 0.6934368569809144, 'params': {'colSam': 0.41354741932879835, 'learningrate': 0.021352173937245852, 'maxDepth': 85.31735064117407, 'minChildWeight': 2.5062808741008524, 'nestimator': 375.1634263844673, 'numLeaves': 28.919388947772795, 'scaleWeight': 766.2561275171417, 'subsample': 0.9209286090716017}}, {'target': 0.6913491529231323, 'params': {'colSam': 0.8374682502176076, 'learningrate': 0.03399145942489988, 'maxDepth': 21.889697044904985, 'minChildWeight': 54.03494712750411, 'nestimator': 112.76447020542886, 'numLeaves': 62.866402462233275, 'scaleWeight': 264.47729858962293, 'subsample': 0.6149068288772022}}, {'target': 0.6906327238885878, 'params': {'colSam': 0.7103344632643163, 'learningrate': 0.07590858400892059, 'maxDepth': 37.658470052826814, 'minChildWeight': 11.619458495439892, 'nestimator': 365.8316771381872, 'numLeaves': 89.9536761351162, 'scaleWeight': 9143.85010895127, 'subsample': 0.5485845453643377}}, {'target': 0.6900324348449026, 'params': {'colSam': 0.9692433499280864, 'learningrate': 0.16620213054304256, 'maxDepth': 40.12744526823999, 'minChildWeight': 21.990576126949403, 'nestimator': 251.40982127646865, 'numLeaves': 41.984352188600305, 'scaleWeight': 5625.363553959799, 'subsample': 0.49255473988480875}}, {'target': 0.6904606528202506, 'params': {'colSam': 0.8441522497213312, 'learningrate': 0.05780498883593288, 'maxDepth': 26.227004813456617, 'minChildWeight': 45.310267327860686, 'nestimator': 481.9066922262328, 'numLeaves': 33.81308809692917, 'scaleWeight': 1319.3237667329754, 'subsample': 0.403055727106408}}, {'target': 0.6930146556925741, 'params': {'colSam': 0.527297074089704, 'learningrate': 0.19631360678754733, 'maxDepth': 58.18960093849873, 'minChildWeight': 8.105598234904685, 'nestimator': 373.4273621894373, 'numLeaves': 65.3627250630465, 'scaleWeight': 1142.330620341482, 'subsample': 0.4101322707748473}}, {'target': 0.691371532976228, 'params': {'colSam': 0.7307452943576992, 'learningrate': 0.025567906709929637, 'maxDepth': 46.89465276930008, 'minChildWeight': 10.423360009145378, 'nestimator': 434.84505423055396, 'numLeaves': 29.557753402284742, 'scaleWeight': 5419.522936596113, 'subsample': 0.4470899882912047}}, {'target': 0.6923703614494078, 'params': {'colSam': 0.8838326052911015, 'learningrate': 0.024374852129415356, 'maxDepth': 63.993513332483104, 'minChildWeight': 18.386205527887107, 'nestimator': 397.52257237711655, 'numLeaves': 62.217410913151596, 'scaleWeight': 1154.9311980238638, 'subsample': 0.4178027300527519}}, {'target': 0.6922874448448041, 'params': {'colSam': 0.5791720431043672, 'learningrate': 0.034691724087786875, 'maxDepth': 25.51634131740726, 'minChildWeight': 43.15835137696629, 'nestimator': 102.38210247405233, 'numLeaves': 9.44146003459639, 'scaleWeight': 1086.0113392305352, 'subsample': 0.9829243392589121}}, {'target': 0.6933316114493702, 'params': {'colSam': 0.96016187140831, 'learningrate': 0.13315777096847714, 'maxDepth': 68.01629739038123, 'minChildWeight': 17.732601563899674, 'nestimator': 377.5857032615466, 'numLeaves': 35.78902052618007, 'scaleWeight': 1134.293552633023, 'subsample': 0.6166600770872951}}, {'target': 0.6927102367057838, 'params': {'colSam': 0.9315210578397406, 'learningrate': 0.1640941357078629, 'maxDepth': 37.13129981976171, 'minChildWeight': 11.421573290290333, 'nestimator': 182.5327397937655, 'numLeaves': 27.28812225725698, 'scaleWeight': 886.0096154264805, 'subsample': 0.6557352654486168}}, {'target': 0.691813093192621, 'params': {'colSam': 0.8255919417556385, 'learningrate': 0.09357314472731888, 'maxDepth': 77.10053792084766, 'minChildWeight': 15.692158469068657, 'nestimator': 387.50167298096596, 'numLeaves': 37.1539822612547, 'scaleWeight': 749.310094563194, 'subsample': 0.4347301881958}}, {'target': 0.6913225894208817, 'params': {'colSam': 0.6604343598859039, 'learningrate': 0.1127742010678827, 'maxDepth': 25.12972382522088, 'minChildWeight': 28.32689313087524, 'nestimator': 109.38213083695243, 'numLeaves': 10.641031224679224, 'scaleWeight': 1066.0521529843543, 'subsample': 0.48172432485470373}}, {'target': 0.6933781750166427, 'params': {'colSam': 0.8628827230226963, 'learningrate': 0.155371527179621, 'maxDepth': 58.21979549100704, 'minChildWeight': 18.188059664614826, 'nestimator': 367.2648572398884, 'numLeaves': 17.774034853840742, 'scaleWeight': 1148.028074776784, 'subsample': 0.6432728811973303}}, {'target': 0.6933105799656666, 'params': {'colSam': 0.818875383643374, 'learningrate': 0.1601207557312573, 'maxDepth': 56.7540889745763, 'minChildWeight': 21.982191234221762, 'nestimator': 391.85953808103847, 'numLeaves': 33.30169761087458, 'scaleWeight': 1120.3073688977101, 'subsample': 0.6155625938424053}}, {'target': 0.6892206291249818, 'params': {'colSam': 0.5397476364280269, 'learningrate': 0.12482529023884027, 'maxDepth': 38.87929948294298, 'minChildWeight': 22.805590915084313, 'nestimator': 185.9081109785457, 'numLeaves': 30.539366164442075, 'scaleWeight': 8361.297210496565, 'subsample': 0.6459793900057529}}, {'target': 0.690431095347875, 'params': {'colSam': 0.7987177822901135, 'learningrate': 0.03210774543156815, 'maxDepth': 45.0011726084506, 'minChildWeight': 21.4430581402462, 'nestimator': 214.33063438601266, 'numLeaves': 50.544077324556845, 'scaleWeight': 4545.63572025992, 'subsample': 0.40696002257077646}}, {'target': 0.6915725772180235, 'params': {'colSam': 0.40275334135753516, 'learningrate': 0.17713574495340612, 'maxDepth': 58.341507742067805, 'minChildWeight': 62.39035892605594, 'nestimator': 138.7513053542227, 'numLeaves': 86.84588447013928, 'scaleWeight': 62.57864561056368, 'subsample': 0.8109226150681794}}, {'target': 0.6956673933772085, 'params': {'colSam': 0.4808713304797323, 'learningrate': 0.018059621379815528, 'maxDepth': 52.51265295148172, 'minChildWeight': 4.058394200169116, 'nestimator': 392.8590272929394, 'numLeaves': 17.572647658700852, 'scaleWeight': 1124.3292816323958, 'subsample': 0.47556443766580814}}, {'target': 0.6936550951547267, 'params': {'colSam': 0.4068365462710062, 'learningrate': 0.17255144548784887, 'maxDepth': 89.11934895898077, 'minChildWeight': 6.383934108922281, 'nestimator': 361.47974410814555, 'numLeaves': 81.07362906164083, 'scaleWeight': 1149.2325152805613, 'subsample': 0.684433191933956}}, {'target': 0.6913439714839356, 'params': {'colSam': 0.7144728311413545, 'learningrate': 0.07681441088855975, 'maxDepth': 70.03034040529116, 'minChildWeight': 23.918089209761778, 'nestimator': 256.68541304564724, 'numLeaves': 61.48286903871613, 'scaleWeight': 2378.5132193927134, 'subsample': 0.4143588469210321}}, {'target': 0.6927628737981159, 'params': {'colSam': 0.47240968286290685, 'learningrate': 0.16719184724906036, 'maxDepth': 67.5344585356436, 'minChildWeight': 14.754748598757226, 'nestimator': 206.950431478096, 'numLeaves': 56.65774768805876, 'scaleWeight': 1147.5551448918873, 'subsample': 0.8990627451553197}}, {'target': 0.6926833883578112, 'params': {'colSam': 0.7682102556267822, 'learningrate': 0.1375428663440219, 'maxDepth': 36.9716921248402, 'minChildWeight': 18.391210329109168, 'nestimator': 373.40899378976513, 'numLeaves': 40.343302153380776, 'scaleWeight': 1133.4948479813122, 'subsample': 0.5914477173452164}}, {'target': 0.6952952369165809, 'params': {'colSam': 0.9380783812824722, 'learningrate': 0.08633162148033383, 'maxDepth': 77.85600060985294, 'minChildWeight': 4.124698422670775, 'nestimator': 362.56445725119335, 'numLeaves': 82.53143112243303, 'scaleWeight': 1130.9714313170016, 'subsample': 0.9376935439503759}}, {'target': 0.6914902230011276, 'params': {'colSam': 0.4578533147467034, 'learningrate': 0.09870175252494665, 'maxDepth': 64.51892896793181, 'minChildWeight': 67.74828023932284, 'nestimator': 229.1661950035576, 'numLeaves': 84.54032308429662, 'scaleWeight': 5860.0941590932125, 'subsample': 0.7866119166818952}}, {'target': 0.6942540934970857, 'params': {'colSam': 0.7141075889732087, 'learningrate': 0.10476500305137415, 'maxDepth': 32.59468648849415, 'minChildWeight': 9.12233205636362, 'nestimator': 376.57612377051896, 'numLeaves': 28.602942726305642, 'scaleWeight': 2318.3910215976625, 'subsample': 0.5816547970455838}}, {'target': 0.6872559900302424, 'params': {'colSam': 0.8208783575677516, 'learningrate': 0.1714365489891238, 'maxDepth': 36.29146958900745, 'minChildWeight': 25.483858086870384, 'nestimator': 105.33307225115882, 'numLeaves': 80.39162210199466, 'scaleWeight': 8867.116393482187, 'subsample': 0.7336118353780953}}, {'target': 0.69311820151355, 'params': {'colSam': 0.7178857618653458, 'learningrate': 0.11468279742055534, 'maxDepth': 8.480952557969104, 'minChildWeight': 12.07104812218261, 'nestimator': 225.91662685335604, 'numLeaves': 52.81383285532782, 'scaleWeight': 2328.895114356316, 'subsample': 0.550651546274321}}, {'target': 0.6917667643749296, 'params': {'colSam': 0.5925357581579493, 'learningrate': 0.16654876106922623, 'maxDepth': 35.99048944366847, 'minChildWeight': 64.72034542351072, 'nestimator': 306.803865751078, 'numLeaves': 35.86783486310348, 'scaleWeight': 1144.0606799381308, 'subsample': 0.9794713147507711}}, {'target': 0.6869935640635371, 'params': {'colSam': 0.4084325144280983, 'learningrate': 0.041587669809323026, 'maxDepth': 69.36188913555131, 'minChildWeight': 47.85896576691665, 'nestimator': 201.62209080228362, 'numLeaves': 82.6670448188473, 'scaleWeight': 7721.978527692479, 'subsample': 0.9447794749126364}}, {'target': 0.692832209198399, 'params': {'colSam': 0.5599988234543409, 'learningrate': 0.13085079847237874, 'maxDepth': 61.37389994298853, 'minChildWeight': 3.217367779172668, 'nestimator': 179.84782846736977, 'numLeaves': 40.83766353640129, 'scaleWeight': 6475.8355610268545, 'subsample': 0.41674062065276724}}, {'target': 0.6941206917805532, 'params': {'colSam': 0.4567743477520832, 'learningrate': 0.1457438325264073, 'maxDepth': 69.58637648267029, 'minChildWeight': 7.35495561630699, 'nestimator': 387.3889488584436, 'numLeaves': 61.303325180284176, 'scaleWeight': 1112.5284797858235, 'subsample': 0.4834194372773199}}, {'target': 0.6894775121175355, 'params': {'colSam': 0.6938682477931468, 'learningrate': 0.16353718792189179, 'maxDepth': 2.690529386476042, 'minChildWeight': 19.784286130483196, 'nestimator': 255.52228236201847, 'numLeaves': 52.041275604420846, 'scaleWeight': 7525.513233187871, 'subsample': 0.891181271170991}}]\n"
     ]
    }
   ],
   "source": [
    "lgbBO = bayesOpt(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = lgbBO.max['params']\n",
    " \n",
    "# 모델에 적용\n",
    "model = lgb_evaluate(\n",
    "    learningrate=params_lgb['learningrate'],\n",
    "    nestimator=params_lgb['nestimator'],\n",
    "    numLeaves = params_lgb['numLeaves'],\n",
    "     maxDepth = params_lgb['maxDepth'],\n",
    "     scaleWeight = params_lgb['maxDepth'],\n",
    "     minChildWeight = params_lgb['minChildWeight'],\n",
    "     subsample = params_lgb['subsample'],\n",
    "     colSam = params_lgb['colSam'],\n",
    "     output = 'model'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colSam': 0.5899345427049327,\n",
       " 'learningrate': 0.023930536433008,\n",
       " 'maxDepth': 67.3847264821173,\n",
       " 'minChildWeight': 2.2592437085969928,\n",
       " 'nestimator': 381.48036249258377,\n",
       " 'numLeaves': 58.57403739538251,\n",
       " 'scaleWeight': 1145.211831114847,\n",
       " 'subsample': 0.506106176585304}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(numLeaves, maxDepth, scaleWeight, minChildWeight, subsample, colSam,nestimator,learningrate, output = 'score'):\n",
    "    cla=xgb.XGBClassifier(num_leaves=31, max_depth= 2,scale_pos_weight= scaleWeight, min_child_weight= minChildWeight, subsample= 0.4, colsample_bytree= 0.4)\n",
    "    scores = cross_val_score(cla, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    # scores = cross_val_score(reg, train_x, train_y, cv=5, scoring='neg_mean_squared_error')\n",
    " \n",
    "    if output == 'score' :\n",
    "      return np.mean(scores)\n",
    "    if output == 'model' :\n",
    "      return cla\n",
    " \n",
    "def bayesOpt(train_x, train_y):\n",
    "    xgbBO = BayesianOptimization(xgb_evaluate, { 'learningrate':(0.01,0.2), 'nestimator':(100,500),'numLeaves':  (5, 90),  'maxDepth': (2, 90),   'scaleWeight': (1, 10000),  'minChildWeight': (0.01, 70), 'subsample': (0.4, 1), 'colSam': (0.4, 1) })\n",
    "    xgbBO.maximize(init_points=5, n_iter=30)\n",
    "    print(xgbBO.res)\n",
    "    return xgbBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  colSam   | learni... | maxDepth  | minChi... | nestim... | numLeaves | scaleW... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6742  \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.138   \u001b[0m | \u001b[0m 87.27   \u001b[0m | \u001b[0m 55.65   \u001b[0m | \u001b[0m 181.4   \u001b[0m | \u001b[0m 43.32   \u001b[0m | \u001b[0m 1.789e+0\u001b[0m | \u001b[0m 0.8313  \u001b[0m |\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6788  \u001b[0m | \u001b[95m 0.5248  \u001b[0m | \u001b[95m 0.07901 \u001b[0m | \u001b[95m 2.456   \u001b[0m | \u001b[95m 28.81   \u001b[0m | \u001b[95m 104.2   \u001b[0m | \u001b[95m 76.58   \u001b[0m | \u001b[95m 9.938e+0\u001b[0m | \u001b[95m 0.7313  \u001b[0m |\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6707  \u001b[0m | \u001b[0m 0.5666  \u001b[0m | \u001b[0m 0.06373 \u001b[0m | \u001b[0m 60.45   \u001b[0m | \u001b[0m 39.16   \u001b[0m | \u001b[0m 214.3   \u001b[0m | \u001b[0m 14.73   \u001b[0m | \u001b[0m 2.969e+0\u001b[0m | \u001b[0m 0.7947  \u001b[0m |\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.6789  \u001b[0m | \u001b[95m 0.9984  \u001b[0m | \u001b[95m 0.01163 \u001b[0m | \u001b[95m 82.72   \u001b[0m | \u001b[95m 31.36   \u001b[0m | \u001b[95m 459.8   \u001b[0m | \u001b[95m 72.73   \u001b[0m | \u001b[95m 2.12e+03\u001b[0m | \u001b[95m 0.8877  \u001b[0m |\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6693  \u001b[0m | \u001b[0m 0.9125  \u001b[0m | \u001b[0m 0.1747  \u001b[0m | \u001b[0m 2.216   \u001b[0m | \u001b[0m 11.4    \u001b[0m | \u001b[0m 354.4   \u001b[0m | \u001b[0m 14.43   \u001b[0m | \u001b[0m 6.344e+0\u001b[0m | \u001b[0m 0.6267  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.6794  \u001b[0m | \u001b[95m 0.9776  \u001b[0m | \u001b[95m 0.1127  \u001b[0m | \u001b[95m 44.77   \u001b[0m | \u001b[95m 57.94   \u001b[0m | \u001b[95m 408.2   \u001b[0m | \u001b[95m 70.73   \u001b[0m | \u001b[95m 6.634e+0\u001b[0m | \u001b[95m 0.9783  \u001b[0m |\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6663  \u001b[0m | \u001b[0m 0.4197  \u001b[0m | \u001b[0m 0.1551  \u001b[0m | \u001b[0m 87.44   \u001b[0m | \u001b[0m 31.71   \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 62.62   \u001b[0m | \u001b[0m 2.877e+0\u001b[0m | \u001b[0m 0.8339  \u001b[0m |\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6752  \u001b[0m | \u001b[0m 0.6581  \u001b[0m | \u001b[0m 0.1682  \u001b[0m | \u001b[0m 8.854   \u001b[0m | \u001b[0m 23.38   \u001b[0m | \u001b[0m 109.2   \u001b[0m | \u001b[0m 76.42   \u001b[0m | \u001b[0m 9.917e+0\u001b[0m | \u001b[0m 0.935   \u001b[0m |\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.6808  \u001b[0m | \u001b[95m 0.4707  \u001b[0m | \u001b[95m 0.07714 \u001b[0m | \u001b[95m 39.36   \u001b[0m | \u001b[95m 59.81   \u001b[0m | \u001b[95m 168.4   \u001b[0m | \u001b[95m 60.18   \u001b[0m | \u001b[95m 9.507e+0\u001b[0m | \u001b[95m 0.5572  \u001b[0m |\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6803  \u001b[0m | \u001b[0m 0.8051  \u001b[0m | \u001b[0m 0.09245 \u001b[0m | \u001b[0m 36.91   \u001b[0m | \u001b[0m 51.74   \u001b[0m | \u001b[0m 182.7   \u001b[0m | \u001b[0m 89.29   \u001b[0m | \u001b[0m 9.483e+0\u001b[0m | \u001b[0m 0.4582  \u001b[0m |\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6728  \u001b[0m | \u001b[0m 0.7862  \u001b[0m | \u001b[0m 0.04331 \u001b[0m | \u001b[0m 44.37   \u001b[0m | \u001b[0m 32.98   \u001b[0m | \u001b[0m 218.4   \u001b[0m | \u001b[0m 17.77   \u001b[0m | \u001b[0m 7.025e+0\u001b[0m | \u001b[0m 0.5671  \u001b[0m |\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.6812  \u001b[0m | \u001b[95m 0.7321  \u001b[0m | \u001b[95m 0.06753 \u001b[0m | \u001b[95m 43.38   \u001b[0m | \u001b[95m 62.08   \u001b[0m | \u001b[95m 164.7   \u001b[0m | \u001b[95m 56.57   \u001b[0m | \u001b[95m 9.493e+0\u001b[0m | \u001b[95m 0.805   \u001b[0m |\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.6843  \u001b[0m | \u001b[95m 0.7735  \u001b[0m | \u001b[95m 0.144   \u001b[0m | \u001b[95m 42.04   \u001b[0m | \u001b[95m 52.73   \u001b[0m | \u001b[95m 149.8   \u001b[0m | \u001b[95m 65.15   \u001b[0m | \u001b[95m 9.999e+0\u001b[0m | \u001b[95m 0.6814  \u001b[0m |\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6632  \u001b[0m | \u001b[0m 0.7762  \u001b[0m | \u001b[0m 0.05902 \u001b[0m | \u001b[0m 62.23   \u001b[0m | \u001b[0m 15.33   \u001b[0m | \u001b[0m 403.7   \u001b[0m | \u001b[0m 30.32   \u001b[0m | \u001b[0m 4.506e+0\u001b[0m | \u001b[0m 0.5974  \u001b[0m |\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.678   \u001b[0m | \u001b[0m 0.5962  \u001b[0m | \u001b[0m 0.1136  \u001b[0m | \u001b[0m 7.214   \u001b[0m | \u001b[0m 48.14   \u001b[0m | \u001b[0m 273.5   \u001b[0m | \u001b[0m 88.06   \u001b[0m | \u001b[0m 9.991e+0\u001b[0m | \u001b[0m 0.5647  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6748  \u001b[0m | \u001b[0m 0.779   \u001b[0m | \u001b[0m 0.05695 \u001b[0m | \u001b[0m 65.18   \u001b[0m | \u001b[0m 44.87   \u001b[0m | \u001b[0m 289.0   \u001b[0m | \u001b[0m 10.38   \u001b[0m | \u001b[0m 9.481e+0\u001b[0m | \u001b[0m 0.9528  \u001b[0m |\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6791  \u001b[0m | \u001b[0m 0.6158  \u001b[0m | \u001b[0m 0.06774 \u001b[0m | \u001b[0m 18.17   \u001b[0m | \u001b[0m 55.26   \u001b[0m | \u001b[0m 115.4   \u001b[0m | \u001b[0m 27.0    \u001b[0m | \u001b[0m 9.358e+0\u001b[0m | \u001b[0m 0.8557  \u001b[0m |\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6544  \u001b[0m | \u001b[0m 0.4947  \u001b[0m | \u001b[0m 0.1108  \u001b[0m | \u001b[0m 17.62   \u001b[0m | \u001b[0m 12.86   \u001b[0m | \u001b[0m 267.4   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 7.041e+0\u001b[0m | \u001b[0m 0.6857  \u001b[0m |\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6448  \u001b[0m | \u001b[0m 0.6722  \u001b[0m | \u001b[0m 0.0938  \u001b[0m | \u001b[0m 20.99   \u001b[0m | \u001b[0m 2.323   \u001b[0m | \u001b[0m 172.2   \u001b[0m | \u001b[0m 35.88   \u001b[0m | \u001b[0m 9.998e+0\u001b[0m | \u001b[0m 0.6685  \u001b[0m |\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.668   \u001b[0m | \u001b[0m 0.5235  \u001b[0m | \u001b[0m 0.1115  \u001b[0m | \u001b[0m 10.48   \u001b[0m | \u001b[0m 9.498   \u001b[0m | \u001b[0m 108.2   \u001b[0m | \u001b[0m 32.78   \u001b[0m | \u001b[0m 8.714e+0\u001b[0m | \u001b[0m 0.8735  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 0.6846  \u001b[0m | \u001b[95m 0.6873  \u001b[0m | \u001b[95m 0.1656  \u001b[0m | \u001b[95m 52.7    \u001b[0m | \u001b[95m 58.68   \u001b[0m | \u001b[95m 164.0   \u001b[0m | \u001b[95m 50.26   \u001b[0m | \u001b[95m 9.494e+0\u001b[0m | \u001b[95m 0.8174  \u001b[0m |\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6831  \u001b[0m | \u001b[0m 0.7274  \u001b[0m | \u001b[0m 0.07066 \u001b[0m | \u001b[0m 60.7    \u001b[0m | \u001b[0m 50.63   \u001b[0m | \u001b[0m 285.2   \u001b[0m | \u001b[0m 15.04   \u001b[0m | \u001b[0m 9.472e+0\u001b[0m | \u001b[0m 0.9138  \u001b[0m |\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6717  \u001b[0m | \u001b[0m 0.9381  \u001b[0m | \u001b[0m 0.1759  \u001b[0m | \u001b[0m 82.22   \u001b[0m | \u001b[0m 32.91   \u001b[0m | \u001b[0m 294.2   \u001b[0m | \u001b[0m 21.72   \u001b[0m | \u001b[0m 7.383e+0\u001b[0m | \u001b[0m 0.5182  \u001b[0m |\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6781  \u001b[0m | \u001b[0m 0.7152  \u001b[0m | \u001b[0m 0.1141  \u001b[0m | \u001b[0m 52.24   \u001b[0m | \u001b[0m 40.43   \u001b[0m | \u001b[0m 293.0   \u001b[0m | \u001b[0m 34.13   \u001b[0m | \u001b[0m 9.446e+0\u001b[0m | \u001b[0m 0.7925  \u001b[0m |\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6668  \u001b[0m | \u001b[0m 0.6044  \u001b[0m | \u001b[0m 0.1036  \u001b[0m | \u001b[0m 48.73   \u001b[0m | \u001b[0m 18.42   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 18.13   \u001b[0m | \u001b[0m 2.265e+0\u001b[0m | \u001b[0m 0.7219  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6742  \u001b[0m | \u001b[0m 0.7954  \u001b[0m | \u001b[0m 0.1025  \u001b[0m | \u001b[0m 56.61   \u001b[0m | \u001b[0m 49.1    \u001b[0m | \u001b[0m 287.3   \u001b[0m | \u001b[0m 14.11   \u001b[0m | \u001b[0m 9.486e+0\u001b[0m | \u001b[0m 0.7252  \u001b[0m |\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.678   \u001b[0m | \u001b[0m 0.9945  \u001b[0m | \u001b[0m 0.01561 \u001b[0m | \u001b[0m 23.36   \u001b[0m | \u001b[0m 43.26   \u001b[0m | \u001b[0m 369.5   \u001b[0m | \u001b[0m 33.77   \u001b[0m | \u001b[0m 1.104e+0\u001b[0m | \u001b[0m 0.4999  \u001b[0m |\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 28      \u001b[0m | \u001b[95m 0.6851  \u001b[0m | \u001b[95m 0.8846  \u001b[0m | \u001b[95m 0.1354  \u001b[0m | \u001b[95m 67.74   \u001b[0m | \u001b[95m 31.5    \u001b[0m | \u001b[95m 167.8   \u001b[0m | \u001b[95m 64.69   \u001b[0m | \u001b[95m 9.484e+0\u001b[0m | \u001b[95m 0.4242  \u001b[0m |\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.678   \u001b[0m | \u001b[0m 0.8635  \u001b[0m | \u001b[0m 0.07921 \u001b[0m | \u001b[0m 58.54   \u001b[0m | \u001b[0m 53.65   \u001b[0m | \u001b[0m 195.1   \u001b[0m | \u001b[0m 58.16   \u001b[0m | \u001b[0m 9.502e+0\u001b[0m | \u001b[0m 0.4885  \u001b[0m |\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6807  \u001b[0m | \u001b[0m 0.6255  \u001b[0m | \u001b[0m 0.07673 \u001b[0m | \u001b[0m 53.81   \u001b[0m | \u001b[0m 49.73   \u001b[0m | \u001b[0m 120.8   \u001b[0m | \u001b[0m 80.96   \u001b[0m | \u001b[0m 9.977e+0\u001b[0m | \u001b[0m 0.8044  \u001b[0m |\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 31      \u001b[0m | \u001b[95m 0.6856  \u001b[0m | \u001b[95m 0.4931  \u001b[0m | \u001b[95m 0.1789  \u001b[0m | \u001b[95m 53.06   \u001b[0m | \u001b[95m 44.4    \u001b[0m | \u001b[95m 123.2   \u001b[0m | \u001b[95m 64.08   \u001b[0m | \u001b[95m 9.499e+0\u001b[0m | \u001b[95m 0.8477  \u001b[0m |\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.676   \u001b[0m | \u001b[0m 0.7335  \u001b[0m | \u001b[0m 0.1825  \u001b[0m | \u001b[0m 55.21   \u001b[0m | \u001b[0m 29.34   \u001b[0m | \u001b[0m 138.9   \u001b[0m | \u001b[0m 38.18   \u001b[0m | \u001b[0m 9.484e+0\u001b[0m | \u001b[0m 0.9629  \u001b[0m |\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6781  \u001b[0m | \u001b[0m 0.4222  \u001b[0m | \u001b[0m 0.0205  \u001b[0m | \u001b[0m 51.47   \u001b[0m | \u001b[0m 43.96   \u001b[0m | \u001b[0m 221.3   \u001b[0m | \u001b[0m 46.59   \u001b[0m | \u001b[0m 7.832e+0\u001b[0m | \u001b[0m 0.5758  \u001b[0m |\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6609  \u001b[0m | \u001b[0m 0.4452  \u001b[0m | \u001b[0m 0.1538  \u001b[0m | \u001b[0m 44.89   \u001b[0m | \u001b[0m 13.13   \u001b[0m | \u001b[0m 409.3   \u001b[0m | \u001b[0m 25.81   \u001b[0m | \u001b[0m 2.513e+0\u001b[0m | \u001b[0m 0.4824  \u001b[0m |\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6854  \u001b[0m | \u001b[0m 0.8046  \u001b[0m | \u001b[0m 0.08232 \u001b[0m | \u001b[0m 25.9    \u001b[0m | \u001b[0m 57.9    \u001b[0m | \u001b[0m 115.2   \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 9.344e+0\u001b[0m | \u001b[0m 0.7264  \u001b[0m |\n",
      "=========================================================================================================================\n",
      "[{'target': 0.6742361667193884, 'params': {'colSam': 0.7929234735724131, 'learningrate': 0.13796561768070942, 'maxDepth': 87.27435671115802, 'minChildWeight': 55.65231796031927, 'nestimator': 181.44248747704063, 'numLeaves': 43.31560118221748, 'scaleWeight': 1788.8923882047466, 'subsample': 0.8312749851058361}}, {'target': 0.6788052661752741, 'params': {'colSam': 0.5248323485981408, 'learningrate': 0.07901022873971988, 'maxDepth': 2.4564787785708297, 'minChildWeight': 28.805712753746263, 'nestimator': 104.22152673314619, 'numLeaves': 76.57704572461034, 'scaleWeight': 9937.993821685077, 'subsample': 0.7312942846195177}}, {'target': 0.6707257394632402, 'params': {'colSam': 0.566629193892706, 'learningrate': 0.06373012335611214, 'maxDepth': 60.44682750900269, 'minChildWeight': 39.157274555161514, 'nestimator': 214.32466940114028, 'numLeaves': 14.725644169525186, 'scaleWeight': 2968.8731018780036, 'subsample': 0.7947450800516063}}, {'target': 0.6788531313994778, 'params': {'colSam': 0.9984023787912247, 'learningrate': 0.0116306060401084, 'maxDepth': 82.71614650653547, 'minChildWeight': 31.358651216471152, 'nestimator': 459.8470228517954, 'numLeaves': 72.72936035081679, 'scaleWeight': 2119.6900719726573, 'subsample': 0.8876775010270189}}, {'target': 0.6693310823704463, 'params': {'colSam': 0.9124975046733583, 'learningrate': 0.17474235003533337, 'maxDepth': 2.216053489642526, 'minChildWeight': 11.395669824359986, 'nestimator': 354.4311726977703, 'numLeaves': 14.432817942510683, 'scaleWeight': 6343.73490424453, 'subsample': 0.6266879144137195}}, {'target': 0.6794429391131462, 'params': {'colSam': 0.9775809239931555, 'learningrate': 0.11272789833020133, 'maxDepth': 44.77159377201463, 'minChildWeight': 57.944536169063895, 'nestimator': 408.2361016530146, 'numLeaves': 70.72579631285454, 'scaleWeight': 6634.146399740515, 'subsample': 0.9782762499900751}}, {'target': 0.6663427931477857, 'params': {'colSam': 0.4196877316434471, 'learningrate': 0.1551349787955279, 'maxDepth': 87.43783930811195, 'minChildWeight': 31.714744732174076, 'nestimator': 160.0368875475241, 'numLeaves': 62.6223769536421, 'scaleWeight': 2877.077868934252, 'subsample': 0.8338848998717883}}, {'target': 0.6752053553190633, 'params': {'colSam': 0.6580519736722115, 'learningrate': 0.16823697566730555, 'maxDepth': 8.85399738101357, 'minChildWeight': 23.38309569567298, 'nestimator': 109.19926587816971, 'numLeaves': 76.41515009931575, 'scaleWeight': 9917.458159403383, 'subsample': 0.9350412623557143}}, {'target': 0.6808093608035026, 'params': {'colSam': 0.47074842852582305, 'learningrate': 0.07713899494013364, 'maxDepth': 39.35972769455834, 'minChildWeight': 59.80508333399324, 'nestimator': 168.43517469382908, 'numLeaves': 60.1787421264815, 'scaleWeight': 9507.342216502533, 'subsample': 0.5572104385679416}}, {'target': 0.6802829887565308, 'params': {'colSam': 0.8051333503751017, 'learningrate': 0.09244717945454432, 'maxDepth': 36.9145202521687, 'minChildWeight': 51.74415205272248, 'nestimator': 182.74436729946058, 'numLeaves': 89.28659182400817, 'scaleWeight': 9482.850721670597, 'subsample': 0.4581930404297759}}, {'target': 0.6727505504844902, 'params': {'colSam': 0.7862429025626706, 'learningrate': 0.04330664664236035, 'maxDepth': 44.365471701645376, 'minChildWeight': 32.98236031282378, 'nestimator': 218.44912715694738, 'numLeaves': 17.76876486092888, 'scaleWeight': 7025.206887677601, 'subsample': 0.5671238471115769}}, {'target': 0.6811937248978068, 'params': {'colSam': 0.7320887196349165, 'learningrate': 0.06753077825552091, 'maxDepth': 43.38234912494286, 'minChildWeight': 62.084240829997555, 'nestimator': 164.73884922313604, 'numLeaves': 56.57140475986235, 'scaleWeight': 9492.694353340868, 'subsample': 0.8049910435791514}}, {'target': 0.6843467469936846, 'params': {'colSam': 0.7734621269665485, 'learningrate': 0.14400834750394242, 'maxDepth': 42.035093388828784, 'minChildWeight': 52.72736038335796, 'nestimator': 149.82998413120768, 'numLeaves': 65.15417564656931, 'scaleWeight': 9998.638732327896, 'subsample': 0.6814159334164362}}, {'target': 0.663213742289539, 'params': {'colSam': 0.7761701909620637, 'learningrate': 0.05901795827598426, 'maxDepth': 62.234139493723546, 'minChildWeight': 15.331525556451084, 'nestimator': 403.6939664118707, 'numLeaves': 30.322340619574373, 'scaleWeight': 4505.801882141301, 'subsample': 0.5974345638373317}}, {'target': 0.678035858364624, 'params': {'colSam': 0.5962160323244876, 'learningrate': 0.11363155562747862, 'maxDepth': 7.213570684864591, 'minChildWeight': 48.14087780011353, 'nestimator': 273.4902314192359, 'numLeaves': 88.06211665300614, 'scaleWeight': 9990.970678047432, 'subsample': 0.5647148204973466}}, {'target': 0.674828405547286, 'params': {'colSam': 0.779043864177875, 'learningrate': 0.05694645685040926, 'maxDepth': 65.17847117327895, 'minChildWeight': 44.87469595176055, 'nestimator': 289.01907002060767, 'numLeaves': 10.378421907764274, 'scaleWeight': 9480.778711390092, 'subsample': 0.9528086833565278}}, {'target': 0.679112827828773, 'params': {'colSam': 0.6157998919782997, 'learningrate': 0.06774115482864808, 'maxDepth': 18.166276471537977, 'minChildWeight': 55.26297729493489, 'nestimator': 115.43405234174759, 'numLeaves': 27.004041009601583, 'scaleWeight': 9357.826921497954, 'subsample': 0.8556748259133984}}, {'target': 0.6544210926073633, 'params': {'colSam': 0.49474906778096095, 'learningrate': 0.11082503060653208, 'maxDepth': 17.61808810737466, 'minChildWeight': 12.860504425779384, 'nestimator': 267.3681069421141, 'numLeaves': 13.96897304459256, 'scaleWeight': 7040.977015866297, 'subsample': 0.6857300561336261}}, {'target': 0.6447636029956737, 'params': {'colSam': 0.6722430521870991, 'learningrate': 0.0938044814752068, 'maxDepth': 20.992553009896657, 'minChildWeight': 2.3226412489466948, 'nestimator': 172.23680305582872, 'numLeaves': 35.87763695590704, 'scaleWeight': 9998.10527914477, 'subsample': 0.6685496156364902}}, {'target': 0.6679761753951785, 'params': {'colSam': 0.5234936422654461, 'learningrate': 0.11149093401672942, 'maxDepth': 10.483827168519607, 'minChildWeight': 9.497827676608258, 'nestimator': 108.201962202439, 'numLeaves': 32.77704347824765, 'scaleWeight': 8713.77673416451, 'subsample': 0.8735332694391529}}, {'target': 0.6845509406440995, 'params': {'colSam': 0.6872789700112305, 'learningrate': 0.16557256090076286, 'maxDepth': 52.69896434373138, 'minChildWeight': 58.68003051554712, 'nestimator': 164.0343235305332, 'numLeaves': 50.26064344371309, 'scaleWeight': 9493.544310423304, 'subsample': 0.8174026728341739}}, {'target': 0.6831420423888489, 'params': {'colSam': 0.7273803748689127, 'learningrate': 0.0706635089070409, 'maxDepth': 60.699869759325956, 'minChildWeight': 50.62594191852603, 'nestimator': 285.19772447298516, 'numLeaves': 15.035261513090555, 'scaleWeight': 9471.944127310397, 'subsample': 0.9137745556953861}}, {'target': 0.6716806744466517, 'params': {'colSam': 0.9381229985042828, 'learningrate': 0.17589265944044402, 'maxDepth': 82.22277831573076, 'minChildWeight': 32.90984112837617, 'nestimator': 294.2307346876827, 'numLeaves': 21.718961684063668, 'scaleWeight': 7382.97700396824, 'subsample': 0.5181863416286814}}, {'target': 0.6781473657265357, 'params': {'colSam': 0.715235504362552, 'learningrate': 0.11414706129188858, 'maxDepth': 52.23707079492251, 'minChildWeight': 40.431214160262805, 'nestimator': 293.0179701435819, 'numLeaves': 34.13474846446492, 'scaleWeight': 9445.608340390334, 'subsample': 0.7924896741911001}}, {'target': 0.6667731542079605, 'params': {'colSam': 0.6044361224553022, 'learningrate': 0.10361512302034494, 'maxDepth': 48.72525353199138, 'minChildWeight': 18.424779520354047, 'nestimator': 290.0178044718689, 'numLeaves': 18.134863293952584, 'scaleWeight': 2264.93647886028, 'subsample': 0.7218733321542588}}, {'target': 0.6742415114626413, 'params': {'colSam': 0.7953680736354667, 'learningrate': 0.10253154954314113, 'maxDepth': 56.60961937510812, 'minChildWeight': 49.09695640054866, 'nestimator': 287.28505968793064, 'numLeaves': 14.111622547731807, 'scaleWeight': 9485.990396164892, 'subsample': 0.725206513753994}}, {'target': 0.6780437369426047, 'params': {'colSam': 0.994538681927914, 'learningrate': 0.01561395209183684, 'maxDepth': 23.359189237035178, 'minChildWeight': 43.25700913472397, 'nestimator': 369.4792474771517, 'numLeaves': 33.77083824921404, 'scaleWeight': 1103.502210634302, 'subsample': 0.4999398078831744}}, {'target': 0.6851438905562882, 'params': {'colSam': 0.8845699670633772, 'learningrate': 0.13543137752434067, 'maxDepth': 67.73708814497581, 'minChildWeight': 31.497498695760843, 'nestimator': 167.81294975638053, 'numLeaves': 64.68878002717337, 'scaleWeight': 9484.249457293303, 'subsample': 0.424193997140381}}, {'target': 0.6780471612713554, 'params': {'colSam': 0.8634899960850992, 'learningrate': 0.07920527827927186, 'maxDepth': 58.543437334462496, 'minChildWeight': 53.648422754675416, 'nestimator': 195.11529266288838, 'numLeaves': 58.161407299896254, 'scaleWeight': 9501.560540848022, 'subsample': 0.4884967467019626}}, {'target': 0.6807307972258326, 'params': {'colSam': 0.6255190000326211, 'learningrate': 0.07672733470754858, 'maxDepth': 53.80658678235268, 'minChildWeight': 49.72862009727668, 'nestimator': 120.81180957719124, 'numLeaves': 80.95882549538642, 'scaleWeight': 9977.102985775808, 'subsample': 0.804421498868575}}, {'target': 0.6856201996098441, 'params': {'colSam': 0.4931254473997531, 'learningrate': 0.17893514486196332, 'maxDepth': 53.05752055007547, 'minChildWeight': 44.395112884210775, 'nestimator': 123.24003590362733, 'numLeaves': 64.08393719402008, 'scaleWeight': 9498.601445016538, 'subsample': 0.8477242762196162}}, {'target': 0.6759522720223685, 'params': {'colSam': 0.7335465228434163, 'learningrate': 0.18248866163344996, 'maxDepth': 55.20635072004666, 'minChildWeight': 29.33520332601344, 'nestimator': 138.93223072312435, 'numLeaves': 38.18188276826628, 'scaleWeight': 9483.602746876806, 'subsample': 0.9628940528210949}}, {'target': 0.6780743059824808, 'params': {'colSam': 0.42223711749769055, 'learningrate': 0.020495434607079574, 'maxDepth': 51.473302169769845, 'minChildWeight': 43.958464035018686, 'nestimator': 221.3268604162845, 'numLeaves': 46.59079153749294, 'scaleWeight': 7832.0060212522985, 'subsample': 0.5758497342768041}}, {'target': 0.6608563388671834, 'params': {'colSam': 0.4452200473322943, 'learningrate': 0.15382830067581554, 'maxDepth': 44.888342389967654, 'minChildWeight': 13.125826769580334, 'nestimator': 409.2998850454053, 'numLeaves': 25.809878419221356, 'scaleWeight': 2512.9450924087864, 'subsample': 0.48241494881209085}}, {'target': 0.6854399807552911, 'params': {'colSam': 0.804614031542907, 'learningrate': 0.08231894927338465, 'maxDepth': 25.899615339294357, 'minChildWeight': 57.90122477623596, 'nestimator': 115.22700948738631, 'numLeaves': 29.827146999598874, 'scaleWeight': 9344.056414702456, 'subsample': 0.7263790574146038}}]\n"
     ]
    }
   ],
   "source": [
    "xgbBO = bayesOpt(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "params_xgb = xgbBO.max['params']\n",
    " \n",
    "# 모델에 적용\n",
    "model = xgb_evaluate(\n",
    "    learningrate=params_xgb['learningrate'],\n",
    "    nestimator=params_xgb['nestimator'],\n",
    "    numLeaves = params_xgb['numLeaves'],\n",
    "     maxDepth = params_xgb['maxDepth'],\n",
    "     scaleWeight = params_xgb['maxDepth'],\n",
    "     minChildWeight = params_xgb['minChildWeight'],\n",
    "     subsample = params_xgb['subsample'],\n",
    "     colSam = params_xgb['colSam'],\n",
    "     output = 'model'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colSam': 0.4931254473997531,\n",
       " 'learningrate': 0.17893514486196332,\n",
       " 'maxDepth': 53.05752055007547,\n",
       " 'minChildWeight': 44.395112884210775,\n",
       " 'nestimator': 123.24003590362733,\n",
       " 'numLeaves': 64.08393719402008,\n",
       " 'scaleWeight': 9498.601445016538,\n",
       " 'subsample': 0.8477242762196162}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_evaluate(min_samples_leaf, maxDepth, max_features, colSam,nestimator,learningrate, output = 'score'):\n",
    "    cla=ExtraTreesClassifier(max_depth= 2)\n",
    "    scores = cross_val_score(cla, X_train, y_train, cv=5, scoring='roc_auc')\n",
    " \n",
    "    if output == 'score' :\n",
    "      return np.mean(scores)\n",
    "    if output == 'model' :\n",
    "      return cla\n",
    " \n",
    "def bayesOpt(train_x, train_y):\n",
    "    extBO = BayesianOptimization(ext_evaluate, { 'learningrate':(0.01,0.2), 'nestimator':(100,500),'min_samples_leaf':  (1,10),  'maxDepth': (2, 90),   'max_features': (17,34),   'colSam': (0.4, 1) })\n",
    "    extBO.maximize(init_points=5, n_iter=30)\n",
    "    print(extBO.res)\n",
    "    return extBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  colSam   | learni... | maxDepth  | max_fe... | min_sa... | nestim... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6696  \u001b[0m | \u001b[0m 0.5926  \u001b[0m | \u001b[0m 0.1215  \u001b[0m | \u001b[0m 27.89   \u001b[0m | \u001b[0m 32.1    \u001b[0m | \u001b[0m 8.371   \u001b[0m | \u001b[0m 472.5   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6706  \u001b[0m | \u001b[95m 0.9703  \u001b[0m | \u001b[95m 0.1946  \u001b[0m | \u001b[95m 9.492   \u001b[0m | \u001b[95m 32.23   \u001b[0m | \u001b[95m 1.21    \u001b[0m | \u001b[95m 409.0   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.67    \u001b[0m | \u001b[0m 0.4531  \u001b[0m | \u001b[0m 0.1585  \u001b[0m | \u001b[0m 44.58   \u001b[0m | \u001b[0m 23.17   \u001b[0m | \u001b[0m 1.306   \u001b[0m | \u001b[0m 354.7   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.6717  \u001b[0m | \u001b[95m 0.8047  \u001b[0m | \u001b[95m 0.09073 \u001b[0m | \u001b[95m 28.28   \u001b[0m | \u001b[95m 21.6    \u001b[0m | \u001b[95m 1.173   \u001b[0m | \u001b[95m 114.8   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.672   \u001b[0m | \u001b[95m 0.8115  \u001b[0m | \u001b[95m 0.1933  \u001b[0m | \u001b[95m 81.65   \u001b[0m | \u001b[95m 20.92   \u001b[0m | \u001b[95m 4.973   \u001b[0m | \u001b[95m 285.9   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6711  \u001b[0m | \u001b[0m 0.7781  \u001b[0m | \u001b[0m 0.1282  \u001b[0m | \u001b[0m 88.97   \u001b[0m | \u001b[0m 22.91   \u001b[0m | \u001b[0m 7.98    \u001b[0m | \u001b[0m 268.6   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6695  \u001b[0m | \u001b[0m 0.6559  \u001b[0m | \u001b[0m 0.0892  \u001b[0m | \u001b[0m 84.68   \u001b[0m | \u001b[0m 21.51   \u001b[0m | \u001b[0m 1.137   \u001b[0m | \u001b[0m 301.3   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6695  \u001b[0m | \u001b[0m 0.6637  \u001b[0m | \u001b[0m 0.05062 \u001b[0m | \u001b[0m 30.5    \u001b[0m | \u001b[0m 29.69   \u001b[0m | \u001b[0m 4.254   \u001b[0m | \u001b[0m 265.7   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6702  \u001b[0m | \u001b[0m 0.6163  \u001b[0m | \u001b[0m 0.1286  \u001b[0m | \u001b[0m 89.93   \u001b[0m | \u001b[0m 21.95   \u001b[0m | \u001b[0m 6.62    \u001b[0m | \u001b[0m 267.2   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6704  \u001b[0m | \u001b[0m 0.5664  \u001b[0m | \u001b[0m 0.0708  \u001b[0m | \u001b[0m 81.34   \u001b[0m | \u001b[0m 24.97   \u001b[0m | \u001b[0m 1.927   \u001b[0m | \u001b[0m 215.7   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6701  \u001b[0m | \u001b[0m 0.5353  \u001b[0m | \u001b[0m 0.03026 \u001b[0m | \u001b[0m 26.3    \u001b[0m | \u001b[0m 19.92   \u001b[0m | \u001b[0m 7.792   \u001b[0m | \u001b[0m 249.2   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6713  \u001b[0m | \u001b[0m 0.4541  \u001b[0m | \u001b[0m 0.05711 \u001b[0m | \u001b[0m 84.86   \u001b[0m | \u001b[0m 29.82   \u001b[0m | \u001b[0m 5.043   \u001b[0m | \u001b[0m 311.7   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6698  \u001b[0m | \u001b[0m 0.6104  \u001b[0m | \u001b[0m 0.1905  \u001b[0m | \u001b[0m 37.2    \u001b[0m | \u001b[0m 22.46   \u001b[0m | \u001b[0m 2.967   \u001b[0m | \u001b[0m 365.4   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6702  \u001b[0m | \u001b[0m 0.9493  \u001b[0m | \u001b[0m 0.08799 \u001b[0m | \u001b[0m 49.46   \u001b[0m | \u001b[0m 26.68   \u001b[0m | \u001b[0m 2.1     \u001b[0m | \u001b[0m 252.9   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6696  \u001b[0m | \u001b[0m 0.7432  \u001b[0m | \u001b[0m 0.1576  \u001b[0m | \u001b[0m 37.71   \u001b[0m | \u001b[0m 29.53   \u001b[0m | \u001b[0m 2.136   \u001b[0m | \u001b[0m 475.2   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6691  \u001b[0m | \u001b[0m 0.4582  \u001b[0m | \u001b[0m 0.07597 \u001b[0m | \u001b[0m 54.84   \u001b[0m | \u001b[0m 25.79   \u001b[0m | \u001b[0m 8.34    \u001b[0m | \u001b[0m 213.4   \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.6728  \u001b[0m | \u001b[95m 0.5296  \u001b[0m | \u001b[95m 0.181   \u001b[0m | \u001b[95m 69.29   \u001b[0m | \u001b[95m 20.04   \u001b[0m | \u001b[95m 7.932   \u001b[0m | \u001b[95m 194.9   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6703  \u001b[0m | \u001b[0m 0.4707  \u001b[0m | \u001b[0m 0.09199 \u001b[0m | \u001b[0m 87.64   \u001b[0m | \u001b[0m 30.75   \u001b[0m | \u001b[0m 8.124   \u001b[0m | \u001b[0m 282.3   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6702  \u001b[0m | \u001b[0m 0.6637  \u001b[0m | \u001b[0m 0.1238  \u001b[0m | \u001b[0m 28.64   \u001b[0m | \u001b[0m 31.67   \u001b[0m | \u001b[0m 8.13    \u001b[0m | \u001b[0m 275.6   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6702  \u001b[0m | \u001b[0m 0.8797  \u001b[0m | \u001b[0m 0.1061  \u001b[0m | \u001b[0m 40.35   \u001b[0m | \u001b[0m 17.71   \u001b[0m | \u001b[0m 2.823   \u001b[0m | \u001b[0m 153.6   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6695  \u001b[0m | \u001b[0m 0.6921  \u001b[0m | \u001b[0m 0.1704  \u001b[0m | \u001b[0m 88.39   \u001b[0m | \u001b[0m 23.99   \u001b[0m | \u001b[0m 8.095   \u001b[0m | \u001b[0m 274.3   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6705  \u001b[0m | \u001b[0m 0.445   \u001b[0m | \u001b[0m 0.08227 \u001b[0m | \u001b[0m 79.73   \u001b[0m | \u001b[0m 29.5    \u001b[0m | \u001b[0m 4.898   \u001b[0m | \u001b[0m 336.0   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6721  \u001b[0m | \u001b[0m 0.5621  \u001b[0m | \u001b[0m 0.07807 \u001b[0m | \u001b[0m 24.38   \u001b[0m | \u001b[0m 26.31   \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 249.9   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6661  \u001b[0m | \u001b[0m 0.7116  \u001b[0m | \u001b[0m 0.1185  \u001b[0m | \u001b[0m 82.36   \u001b[0m | \u001b[0m 32.62   \u001b[0m | \u001b[0m 3.525   \u001b[0m | \u001b[0m 258.5   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6715  \u001b[0m | \u001b[0m 0.4551  \u001b[0m | \u001b[0m 0.02279 \u001b[0m | \u001b[0m 65.66   \u001b[0m | \u001b[0m 19.65   \u001b[0m | \u001b[0m 6.352   \u001b[0m | \u001b[0m 194.8   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6697  \u001b[0m | \u001b[0m 0.9269  \u001b[0m | \u001b[0m 0.03203 \u001b[0m | \u001b[0m 71.82   \u001b[0m | \u001b[0m 20.22   \u001b[0m | \u001b[0m 8.719   \u001b[0m | \u001b[0m 191.5   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6726  \u001b[0m | \u001b[0m 0.4572  \u001b[0m | \u001b[0m 0.09585 \u001b[0m | \u001b[0m 80.61   \u001b[0m | \u001b[0m 20.42   \u001b[0m | \u001b[0m 2.353   \u001b[0m | \u001b[0m 286.7   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6701  \u001b[0m | \u001b[0m 0.9068  \u001b[0m | \u001b[0m 0.09116 \u001b[0m | \u001b[0m 68.48   \u001b[0m | \u001b[0m 22.34   \u001b[0m | \u001b[0m 7.657   \u001b[0m | \u001b[0m 195.8   \u001b[0m |\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m 0.6734  \u001b[0m | \u001b[95m 0.5821  \u001b[0m | \u001b[95m 0.02158 \u001b[0m | \u001b[95m 81.92   \u001b[0m | \u001b[95m 19.18   \u001b[0m | \u001b[95m 2.255   \u001b[0m | \u001b[95m 288.3   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6703  \u001b[0m | \u001b[0m 0.5712  \u001b[0m | \u001b[0m 0.08684 \u001b[0m | \u001b[0m 81.86   \u001b[0m | \u001b[0m 19.48   \u001b[0m | \u001b[0m 1.617   \u001b[0m | \u001b[0m 287.6   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6688  \u001b[0m | \u001b[0m 0.9896  \u001b[0m | \u001b[0m 0.08825 \u001b[0m | \u001b[0m 59.29   \u001b[0m | \u001b[0m 21.52   \u001b[0m | \u001b[0m 7.593   \u001b[0m | \u001b[0m 323.9   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.672   \u001b[0m | \u001b[0m 0.5363  \u001b[0m | \u001b[0m 0.1049  \u001b[0m | \u001b[0m 26.85   \u001b[0m | \u001b[0m 18.65   \u001b[0m | \u001b[0m 8.174   \u001b[0m | \u001b[0m 357.8   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6695  \u001b[0m | \u001b[0m 0.6948  \u001b[0m | \u001b[0m 0.1791  \u001b[0m | \u001b[0m 89.27   \u001b[0m | \u001b[0m 21.81   \u001b[0m | \u001b[0m 9.973   \u001b[0m | \u001b[0m 239.6   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6702  \u001b[0m | \u001b[0m 0.6891  \u001b[0m | \u001b[0m 0.08655 \u001b[0m | \u001b[0m 25.23   \u001b[0m | \u001b[0m 27.24   \u001b[0m | \u001b[0m 3.532   \u001b[0m | \u001b[0m 161.4   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6706  \u001b[0m | \u001b[0m 0.5647  \u001b[0m | \u001b[0m 0.03373 \u001b[0m | \u001b[0m 55.73   \u001b[0m | \u001b[0m 18.87   \u001b[0m | \u001b[0m 2.44    \u001b[0m | \u001b[0m 368.1   \u001b[0m |\n",
      "=================================================================================================\n",
      "[{'target': 0.6695958580802652, 'params': {'colSam': 0.5926036223471054, 'learningrate': 0.12152922417743074, 'maxDepth': 27.887173677384173, 'max_features': 32.09902528786336, 'min_samples_leaf': 8.371217376773721, 'nestimator': 472.5481063159531}}, {'target': 0.6705981605101486, 'params': {'colSam': 0.9702948284653563, 'learningrate': 0.19462796765840873, 'maxDepth': 9.492140388737349, 'max_features': 32.22667729462887, 'min_samples_leaf': 1.209706709239271, 'nestimator': 408.9538881445864}}, {'target': 0.6699615638433913, 'params': {'colSam': 0.4531295961830528, 'learningrate': 0.15852027373703634, 'maxDepth': 44.58367979782351, 'max_features': 23.17063325595268, 'min_samples_leaf': 1.3057462082975015, 'nestimator': 354.71241381637867}}, {'target': 0.6716591824530002, 'params': {'colSam': 0.8046676079934545, 'learningrate': 0.09072689547314, 'maxDepth': 28.27567148828608, 'max_features': 21.596358162968272, 'min_samples_leaf': 1.1734442574077355, 'nestimator': 114.8368964877494}}, {'target': 0.6720426815227214, 'params': {'colSam': 0.811527712993917, 'learningrate': 0.19328481816572424, 'maxDepth': 81.64717131067226, 'max_features': 20.924460316265346, 'min_samples_leaf': 4.973059963680232, 'nestimator': 285.92424854622266}}, {'target': 0.6710618962750164, 'params': {'colSam': 0.7781269036711396, 'learningrate': 0.12822956009429406, 'maxDepth': 88.97402671592856, 'max_features': 22.914861130710094, 'min_samples_leaf': 7.979791766017117, 'nestimator': 268.6168828597191}}, {'target': 0.6695005643578439, 'params': {'colSam': 0.6558699316531312, 'learningrate': 0.0892041413652429, 'maxDepth': 84.67898212339819, 'max_features': 21.51149033995508, 'min_samples_leaf': 1.137247734315328, 'nestimator': 301.34415492739225}}, {'target': 0.6694751209491269, 'params': {'colSam': 0.6637096700390841, 'learningrate': 0.050619304213600724, 'maxDepth': 30.501115755417874, 'max_features': 29.68817991900924, 'min_samples_leaf': 4.253660414696556, 'nestimator': 265.6635256421273}}, {'target': 0.6702424221936325, 'params': {'colSam': 0.6162847179559788, 'learningrate': 0.128580233660412, 'maxDepth': 89.93257770049871, 'max_features': 21.94952393251646, 'min_samples_leaf': 6.619623492397249, 'nestimator': 267.2013631369273}}, {'target': 0.670370260616644, 'params': {'colSam': 0.5664380202335377, 'learningrate': 0.07079691113821243, 'maxDepth': 81.34022296184774, 'max_features': 24.972745092849152, 'min_samples_leaf': 1.9269509281860435, 'nestimator': 215.69854978429504}}, {'target': 0.6701071434168285, 'params': {'colSam': 0.5352806291900134, 'learningrate': 0.03026225283191971, 'maxDepth': 26.29713112808326, 'max_features': 19.918611307718674, 'min_samples_leaf': 7.791839909337783, 'nestimator': 249.15527375545636}}, {'target': 0.6712644158715781, 'params': {'colSam': 0.4541317537667738, 'learningrate': 0.05710530156647657, 'maxDepth': 84.86344489467, 'max_features': 29.820819082815724, 'min_samples_leaf': 5.043168892498364, 'nestimator': 311.74819241585374}}, {'target': 0.6697607470474403, 'params': {'colSam': 0.6103838801046293, 'learningrate': 0.19052602021872686, 'maxDepth': 37.19716830233662, 'max_features': 22.45652472499702, 'min_samples_leaf': 2.966632644905056, 'nestimator': 365.35703790359594}}, {'target': 0.6702392748450416, 'params': {'colSam': 0.9492775486569707, 'learningrate': 0.08798799999661683, 'maxDepth': 49.4579981112517, 'max_features': 26.681039787409887, 'min_samples_leaf': 2.0998551892277297, 'nestimator': 252.85408758151036}}, {'target': 0.6696311046015218, 'params': {'colSam': 0.7431888607102133, 'learningrate': 0.15758366703093107, 'maxDepth': 37.70678512640911, 'max_features': 29.52526073182115, 'min_samples_leaf': 2.135661764432131, 'nestimator': 475.161242423206}}, {'target': 0.6690521584803542, 'params': {'colSam': 0.45817109699802344, 'learningrate': 0.07597486036843379, 'maxDepth': 54.835863344474575, 'max_features': 25.788324755823275, 'min_samples_leaf': 8.339911252698007, 'nestimator': 213.3876001573595}}, {'target': 0.6727590657048329, 'params': {'colSam': 0.5295820961851824, 'learningrate': 0.1809938950477369, 'maxDepth': 69.28726985054645, 'max_features': 20.03539089973963, 'min_samples_leaf': 7.931884358960992, 'nestimator': 194.93122233354353}}, {'target': 0.6703162201768963, 'params': {'colSam': 0.4707184506806551, 'learningrate': 0.09198986166450508, 'maxDepth': 87.6448027249053, 'max_features': 30.74605599755928, 'min_samples_leaf': 8.123809566159284, 'nestimator': 282.30157158445394}}, {'target': 0.6701986606393089, 'params': {'colSam': 0.6637328956485686, 'learningrate': 0.12381880036849008, 'maxDepth': 28.639693970425636, 'max_features': 31.669381314714858, 'min_samples_leaf': 8.13027865338334, 'nestimator': 275.6029201844722}}, {'target': 0.6702306705752968, 'params': {'colSam': 0.8796647521012888, 'learningrate': 0.10609074881442103, 'maxDepth': 40.34716989647568, 'max_features': 17.71346670959048, 'min_samples_leaf': 2.8234606467230448, 'nestimator': 153.60604228155034}}, {'target': 0.6695404226268525, 'params': {'colSam': 0.6921483270164093, 'learningrate': 0.1703910194347034, 'maxDepth': 88.38763363287678, 'max_features': 23.987431424553684, 'min_samples_leaf': 8.094705072396318, 'nestimator': 274.3312336460351}}, {'target': 0.6704741064526407, 'params': {'colSam': 0.44501685656125345, 'learningrate': 0.08226622856562943, 'maxDepth': 79.72677763097991, 'max_features': 29.502080746095935, 'min_samples_leaf': 4.898446797689428, 'nestimator': 335.9937117771159}}, {'target': 0.6720987440674557, 'params': {'colSam': 0.5621387920427201, 'learningrate': 0.0780713933595267, 'maxDepth': 24.379023828892535, 'max_features': 26.313694852876843, 'min_samples_leaf': 1.499884808066932, 'nestimator': 249.94728732622912}}, {'target': 0.6660962799628111, 'params': {'colSam': 0.7116012974149757, 'learningrate': 0.11851827020947497, 'maxDepth': 82.35501001387169, 'max_features': 32.618725459965184, 'min_samples_leaf': 3.5250239671410637, 'nestimator': 258.5329981872079}}, {'target': 0.6715310675180172, 'params': {'colSam': 0.45505541767649305, 'learningrate': 0.022786917956366684, 'maxDepth': 65.66251826691874, 'max_features': 19.654227488622688, 'min_samples_leaf': 6.351916891571816, 'nestimator': 194.8326646893504}}, {'target': 0.669719551164644, 'params': {'colSam': 0.9269241913693593, 'learningrate': 0.03203462368494708, 'maxDepth': 71.82403370277017, 'max_features': 20.224139434165984, 'min_samples_leaf': 8.718813741026972, 'nestimator': 191.47365615886974}}, {'target': 0.6725977576285542, 'params': {'colSam': 0.4572451715678126, 'learningrate': 0.09585445390460007, 'maxDepth': 80.60963553209153, 'max_features': 20.421356307887272, 'min_samples_leaf': 2.3526030369605824, 'nestimator': 286.6562494711624}}, {'target': 0.6700897575276353, 'params': {'colSam': 0.9068229705509718, 'learningrate': 0.09115721695102193, 'maxDepth': 68.4819013598978, 'max_features': 22.34342311623311, 'min_samples_leaf': 7.656734540857156, 'nestimator': 195.75767860262624}}, {'target': 0.673412213574798, 'params': {'colSam': 0.5820686358392038, 'learningrate': 0.02158341687861813, 'maxDepth': 81.91914189104035, 'max_features': 19.17525369098223, 'min_samples_leaf': 2.2552233430313215, 'nestimator': 288.318161028525}}, {'target': 0.6703254911466878, 'params': {'colSam': 0.5711973781271552, 'learningrate': 0.08684275490361795, 'maxDepth': 81.85782550486917, 'max_features': 19.48225841034383, 'min_samples_leaf': 1.617343455557351, 'nestimator': 287.562579750401}}, {'target': 0.6688147784305546, 'params': {'colSam': 0.9896479995809322, 'learningrate': 0.08824706000350774, 'maxDepth': 59.288257610610756, 'max_features': 21.520613831135833, 'min_samples_leaf': 7.593316862924946, 'nestimator': 323.87662509976946}}, {'target': 0.6720452252830396, 'params': {'colSam': 0.5362664313538594, 'learningrate': 0.10492898599327341, 'maxDepth': 26.845277581581968, 'max_features': 18.65086441950946, 'min_samples_leaf': 8.17352921577384, 'nestimator': 357.757108690986}}, {'target': 0.6695057723901323, 'params': {'colSam': 0.6948101708012315, 'learningrate': 0.1790632059716857, 'maxDepth': 89.27064955213604, 'max_features': 21.80705069968224, 'min_samples_leaf': 9.97329202391144, 'nestimator': 239.55133594277166}}, {'target': 0.67020124925206, 'params': {'colSam': 0.6890776845134976, 'learningrate': 0.08654563033299796, 'maxDepth': 25.229025419500072, 'max_features': 27.236131568698784, 'min_samples_leaf': 3.5323554053129924, 'nestimator': 161.41456876237464}}, {'target': 0.6706147591876435, 'params': {'colSam': 0.5647003976130377, 'learningrate': 0.033734837002208, 'maxDepth': 55.729652055631384, 'max_features': 18.869139792801068, 'min_samples_leaf': 2.439569840745527, 'nestimator': 368.1121142397783}}]\n"
     ]
    }
   ],
   "source": [
    "extBO = bayesOpt(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ext = extBO.max['params']\n",
    " \n",
    "# 모델에 적용\n",
    "model = ext_evaluate(\n",
    "    learningrate=params_ext['learningrate'],\n",
    "    nestimator=params_ext['nestimator'],\n",
    "     maxDepth = params_ext['maxDepth'],\n",
    "     colSam = params_ext['colSam'],\n",
    "    min_samples_leaf=params_ext['min_samples_leaf'],\n",
    "    max_features=params_ext['max_features'],\n",
    "     output = 'model'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colSam': 0.5820686358392038,\n",
       " 'learningrate': 0.02158341687861813,\n",
       " 'maxDepth': 81.91914189104035,\n",
       " 'max_features': 19.17525369098223,\n",
       " 'min_samples_leaf': 2.2552233430313215,\n",
       " 'nestimator': 288.318161028525}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gra_evaluate( maxDepth, subsample, colSam,nestimator,learningrate, output = 'score'):\n",
    "    cla=GradientBoostingClassifier( max_depth= 2, subsample= 0.4)\n",
    "    scores = cross_val_score(cla, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    # scores = cross_val_score(reg, train_x, train_y, cv=5, scoring='neg_mean_squared_error')\n",
    " \n",
    "    if output == 'score' :\n",
    "      return np.mean(scores)\n",
    "    if output == 'model' :\n",
    "      return cla\n",
    " \n",
    "def bayesOpt(train_x, train_y):\n",
    "    graBO = BayesianOptimization(gra_evaluate, { 'learningrate':(0.01,0.2), 'nestimator':(100,500),'maxDepth': (2, 90),  'subsample': (0.4, 1), 'colSam': (0.4, 1) })\n",
    "    graBO.maximize(init_points=5, n_iter=30)\n",
    "    print(graBO.res)\n",
    "    return graBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  colSam   | learni... | maxDepth  | nestim... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6855  \u001b[0m | \u001b[0m 0.9334  \u001b[0m | \u001b[0m 0.1246  \u001b[0m | \u001b[0m 15.25   \u001b[0m | \u001b[0m 492.1   \u001b[0m | \u001b[0m 0.5574  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6845  \u001b[0m | \u001b[0m 0.7117  \u001b[0m | \u001b[0m 0.1528  \u001b[0m | \u001b[0m 50.67   \u001b[0m | \u001b[0m 359.7   \u001b[0m | \u001b[0m 0.7829  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.685   \u001b[0m | \u001b[0m 0.4108  \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 35.22   \u001b[0m | \u001b[0m 431.1   \u001b[0m | \u001b[0m 0.6708  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6811  \u001b[0m | \u001b[0m 0.8088  \u001b[0m | \u001b[0m 0.1554  \u001b[0m | \u001b[0m 78.17   \u001b[0m | \u001b[0m 397.4   \u001b[0m | \u001b[0m 0.5197  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.686   \u001b[0m | \u001b[95m 0.788   \u001b[0m | \u001b[95m 0.1117  \u001b[0m | \u001b[95m 67.23   \u001b[0m | \u001b[95m 152.6   \u001b[0m | \u001b[95m 0.5721  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.685   \u001b[0m | \u001b[0m 0.6044  \u001b[0m | \u001b[0m 0.178   \u001b[0m | \u001b[0m 68.16   \u001b[0m | \u001b[0m 151.8   \u001b[0m | \u001b[0m 0.8739  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.6927  \u001b[0m | \u001b[95m 0.4104  \u001b[0m | \u001b[95m 0.1837  \u001b[0m | \u001b[95m 65.09   \u001b[0m | \u001b[95m 154.6   \u001b[0m | \u001b[95m 0.9224  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6861  \u001b[0m | \u001b[0m 0.8093  \u001b[0m | \u001b[0m 0.1528  \u001b[0m | \u001b[0m 63.69   \u001b[0m | \u001b[0m 155.3   \u001b[0m | \u001b[0m 0.6313  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6811  \u001b[0m | \u001b[0m 0.6377  \u001b[0m | \u001b[0m 0.0803  \u001b[0m | \u001b[0m 65.61   \u001b[0m | \u001b[0m 154.8   \u001b[0m | \u001b[0m 0.6102  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6827  \u001b[0m | \u001b[0m 0.6009  \u001b[0m | \u001b[0m 0.04735 \u001b[0m | \u001b[0m 46.32   \u001b[0m | \u001b[0m 423.5   \u001b[0m | \u001b[0m 0.5594  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6849  \u001b[0m | \u001b[0m 0.6161  \u001b[0m | \u001b[0m 0.05529 \u001b[0m | \u001b[0m 14.48   \u001b[0m | \u001b[0m 343.2   \u001b[0m | \u001b[0m 0.632   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6805  \u001b[0m | \u001b[0m 0.444   \u001b[0m | \u001b[0m 0.1792  \u001b[0m | \u001b[0m 60.44   \u001b[0m | \u001b[0m 185.6   \u001b[0m | \u001b[0m 0.5619  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6849  \u001b[0m | \u001b[0m 0.8802  \u001b[0m | \u001b[0m 0.1441  \u001b[0m | \u001b[0m 15.93   \u001b[0m | \u001b[0m 477.5   \u001b[0m | \u001b[0m 0.9175  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6884  \u001b[0m | \u001b[0m 0.4442  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 14.27   \u001b[0m | \u001b[0m 116.4   \u001b[0m | \u001b[0m 0.5901  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6834  \u001b[0m | \u001b[0m 0.5927  \u001b[0m | \u001b[0m 0.04465 \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 221.6   \u001b[0m | \u001b[0m 0.8817  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6816  \u001b[0m | \u001b[0m 0.5959  \u001b[0m | \u001b[0m 0.1355  \u001b[0m | \u001b[0m 83.05   \u001b[0m | \u001b[0m 424.7   \u001b[0m | \u001b[0m 0.5361  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6904  \u001b[0m | \u001b[0m 0.448   \u001b[0m | \u001b[0m 0.1538  \u001b[0m | \u001b[0m 82.75   \u001b[0m | \u001b[0m 123.3   \u001b[0m | \u001b[0m 0.4068  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6829  \u001b[0m | \u001b[0m 0.9732  \u001b[0m | \u001b[0m 0.1545  \u001b[0m | \u001b[0m 31.38   \u001b[0m | \u001b[0m 334.8   \u001b[0m | \u001b[0m 0.8084  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6855  \u001b[0m | \u001b[0m 0.4778  \u001b[0m | \u001b[0m 0.1491  \u001b[0m | \u001b[0m 39.85   \u001b[0m | \u001b[0m 132.8   \u001b[0m | \u001b[0m 0.5167  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6905  \u001b[0m | \u001b[0m 0.6428  \u001b[0m | \u001b[0m 0.1296  \u001b[0m | \u001b[0m 74.69   \u001b[0m | \u001b[0m 127.4   \u001b[0m | \u001b[0m 0.429   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6922  \u001b[0m | \u001b[0m 0.5709  \u001b[0m | \u001b[0m 0.047   \u001b[0m | \u001b[0m 55.21   \u001b[0m | \u001b[0m 357.5   \u001b[0m | \u001b[0m 0.7163  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6802  \u001b[0m | \u001b[0m 0.5261  \u001b[0m | \u001b[0m 0.07867 \u001b[0m | \u001b[0m 73.5    \u001b[0m | \u001b[0m 274.5   \u001b[0m | \u001b[0m 0.6357  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.688   \u001b[0m | \u001b[0m 0.5192  \u001b[0m | \u001b[0m 0.1159  \u001b[0m | \u001b[0m 40.12   \u001b[0m | \u001b[0m 134.1   \u001b[0m | \u001b[0m 0.5361  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6822  \u001b[0m | \u001b[0m 0.6717  \u001b[0m | \u001b[0m 0.1685  \u001b[0m | \u001b[0m 14.55   \u001b[0m | \u001b[0m 482.9   \u001b[0m | \u001b[0m 0.8808  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.677   \u001b[0m | \u001b[0m 0.691   \u001b[0m | \u001b[0m 0.1799  \u001b[0m | \u001b[0m 7.817   \u001b[0m | \u001b[0m 382.7   \u001b[0m | \u001b[0m 0.634   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6828  \u001b[0m | \u001b[0m 0.4414  \u001b[0m | \u001b[0m 0.06879 \u001b[0m | \u001b[0m 62.05   \u001b[0m | \u001b[0m 317.1   \u001b[0m | \u001b[0m 0.7956  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6857  \u001b[0m | \u001b[0m 0.4273  \u001b[0m | \u001b[0m 0.146   \u001b[0m | \u001b[0m 5.359   \u001b[0m | \u001b[0m 458.4   \u001b[0m | \u001b[0m 0.9835  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6859  \u001b[0m | \u001b[0m 0.9761  \u001b[0m | \u001b[0m 0.1693  \u001b[0m | \u001b[0m 48.8    \u001b[0m | \u001b[0m 175.4   \u001b[0m | \u001b[0m 0.568   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6832  \u001b[0m | \u001b[0m 0.9613  \u001b[0m | \u001b[0m 0.1197  \u001b[0m | \u001b[0m 20.01   \u001b[0m | \u001b[0m 492.8   \u001b[0m | \u001b[0m 0.7715  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6927  \u001b[0m | \u001b[0m 0.807   \u001b[0m | \u001b[0m 0.1838  \u001b[0m | \u001b[0m 46.15   \u001b[0m | \u001b[0m 303.9   \u001b[0m | \u001b[0m 0.6646  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6827  \u001b[0m | \u001b[0m 0.5008  \u001b[0m | \u001b[0m 0.1747  \u001b[0m | \u001b[0m 53.32   \u001b[0m | \u001b[0m 238.7   \u001b[0m | \u001b[0m 0.577   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6878  \u001b[0m | \u001b[0m 0.7965  \u001b[0m | \u001b[0m 0.06658 \u001b[0m | \u001b[0m 78.02   \u001b[0m | \u001b[0m 360.7   \u001b[0m | \u001b[0m 0.9994  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6849  \u001b[0m | \u001b[0m 0.4282  \u001b[0m | \u001b[0m 0.1274  \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 236.4   \u001b[0m | \u001b[0m 0.9172  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6844  \u001b[0m | \u001b[0m 0.5995  \u001b[0m | \u001b[0m 0.09535 \u001b[0m | \u001b[0m 66.52   \u001b[0m | \u001b[0m 350.9   \u001b[0m | \u001b[0m 0.7353  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6854  \u001b[0m | \u001b[0m 0.9346  \u001b[0m | \u001b[0m 0.1006  \u001b[0m | \u001b[0m 54.04   \u001b[0m | \u001b[0m 152.6   \u001b[0m | \u001b[0m 0.8649  \u001b[0m |\n",
      "=====================================================================================\n",
      "[{'target': 0.6854898999212813, 'params': {'colSam': 0.9333998468994928, 'learningrate': 0.12463282768061831, 'maxDepth': 15.249268286459106, 'nestimator': 492.0586422726304, 'subsample': 0.5574089242213521}}, {'target': 0.6845164371375717, 'params': {'colSam': 0.7116694393301627, 'learningrate': 0.15283244167404636, 'maxDepth': 50.67375570094574, 'nestimator': 359.6571225043987, 'subsample': 0.7828539974598238}}, {'target': 0.6849902483132564, 'params': {'colSam': 0.41079491830812626, 'learningrate': 0.171475473896941, 'maxDepth': 35.217942258805195, 'nestimator': 431.08600256856636, 'subsample': 0.6708240218857184}}, {'target': 0.6811269400933903, 'params': {'colSam': 0.8088402973372508, 'learningrate': 0.15541842387409352, 'maxDepth': 78.17265243618739, 'nestimator': 397.38921934520454, 'subsample': 0.5196794803979101}}, {'target': 0.6859762844792919, 'params': {'colSam': 0.787972460184637, 'learningrate': 0.11172354122390059, 'maxDepth': 67.2269245665282, 'nestimator': 152.61245105819157, 'subsample': 0.5720743765628223}}, {'target': 0.6849543371519815, 'params': {'colSam': 0.6043847698630777, 'learningrate': 0.17804308060091212, 'maxDepth': 68.15822523541033, 'nestimator': 151.75800466286296, 'subsample': 0.8738531935938788}}, {'target': 0.692722477112637, 'params': {'colSam': 0.4103701413748254, 'learningrate': 0.18372595282799156, 'maxDepth': 65.09488850654324, 'nestimator': 154.61102957217008, 'subsample': 0.9223553672903531}}, {'target': 0.6860554291721992, 'params': {'colSam': 0.8092544101139285, 'learningrate': 0.15277221547421105, 'maxDepth': 63.686391130129, 'nestimator': 155.2756245413334, 'subsample': 0.6312526080114492}}, {'target': 0.681111012329636, 'params': {'colSam': 0.6376755967855197, 'learningrate': 0.08029592327381826, 'maxDepth': 65.61159815354195, 'nestimator': 154.7604932208911, 'subsample': 0.6101907392283312}}, {'target': 0.6826591887192314, 'params': {'colSam': 0.6009460130796753, 'learningrate': 0.04734807471190527, 'maxDepth': 46.32264401676077, 'nestimator': 423.5016290442556, 'subsample': 0.5594229988723505}}, {'target': 0.6848788426418294, 'params': {'colSam': 0.6160773397373543, 'learningrate': 0.05529102414575876, 'maxDepth': 14.483144792045849, 'nestimator': 343.24174645907385, 'subsample': 0.6320284635898471}}, {'target': 0.6804813703181962, 'params': {'colSam': 0.4439819950931185, 'learningrate': 0.17924565392577327, 'maxDepth': 60.43843084842502, 'nestimator': 185.60819271060114, 'subsample': 0.5619196015979608}}, {'target': 0.6849427535195844, 'params': {'colSam': 0.8801880209105233, 'learningrate': 0.1440831300558781, 'maxDepth': 15.932709139372239, 'nestimator': 477.51917983452046, 'subsample': 0.9174576808152164}}, {'target': 0.6883922294094484, 'params': {'colSam': 0.44419126156530836, 'learningrate': 0.17232892842697686, 'maxDepth': 14.267431653312272, 'nestimator': 116.36059330381303, 'subsample': 0.5901204027432505}}, {'target': 0.6833747940233952, 'params': {'colSam': 0.5927075523352123, 'learningrate': 0.044645563958073, 'maxDepth': 14.829388517966017, 'nestimator': 221.57697831021738, 'subsample': 0.8817123237260021}}, {'target': 0.6816457033324425, 'params': {'colSam': 0.5958677796846121, 'learningrate': 0.13554206879346445, 'maxDepth': 83.0544332229847, 'nestimator': 424.6948880294525, 'subsample': 0.5360678727932954}}, {'target': 0.6904190974625276, 'params': {'colSam': 0.44802150530487567, 'learningrate': 0.15382702952654975, 'maxDepth': 82.75312809238001, 'nestimator': 123.26998242180082, 'subsample': 0.40684670345849505}}, {'target': 0.6829311193752952, 'params': {'colSam': 0.9731517118986336, 'learningrate': 0.1545280305351252, 'maxDepth': 31.381459627027542, 'nestimator': 334.83126035000066, 'subsample': 0.8084213420853583}}, {'target': 0.6854841618062734, 'params': {'colSam': 0.4777801901352413, 'learningrate': 0.14911447337105624, 'maxDepth': 39.845757028741595, 'nestimator': 132.78626215393757, 'subsample': 0.5166728079942138}}, {'target': 0.690502102741983, 'params': {'colSam': 0.6427903499341027, 'learningrate': 0.12960152217558615, 'maxDepth': 74.69090694608919, 'nestimator': 127.3998567963445, 'subsample': 0.4290318335222777}}, {'target': 0.6921884517798628, 'params': {'colSam': 0.5708513766719778, 'learningrate': 0.047002887138373695, 'maxDepth': 55.20922295955603, 'nestimator': 357.49586186313405, 'subsample': 0.7163326046379321}}, {'target': 0.6801575986770754, 'params': {'colSam': 0.526077796979678, 'learningrate': 0.07866859325297007, 'maxDepth': 73.49879720383389, 'nestimator': 274.49477786441975, 'subsample': 0.6356930971920239}}, {'target': 0.6880188089342241, 'params': {'colSam': 0.5191832044397469, 'learningrate': 0.11585905734994471, 'maxDepth': 40.11929390181891, 'nestimator': 134.09781972667352, 'subsample': 0.5361006505094602}}, {'target': 0.6821646079643419, 'params': {'colSam': 0.6717118284256165, 'learningrate': 0.16846826306386736, 'maxDepth': 14.54814622001993, 'nestimator': 482.9219576428976, 'subsample': 0.8808034888607329}}, {'target': 0.6769555776860018, 'params': {'colSam': 0.6910468555526968, 'learningrate': 0.17991769543521013, 'maxDepth': 7.816954512814968, 'nestimator': 382.672639557132, 'subsample': 0.6340348652873136}}, {'target': 0.682764377880912, 'params': {'colSam': 0.4413514615159768, 'learningrate': 0.0687917830481622, 'maxDepth': 62.05257837068594, 'nestimator': 317.1339589814453, 'subsample': 0.7955607514057262}}, {'target': 0.6856868144619315, 'params': {'colSam': 0.4273295826219393, 'learningrate': 0.14604414705020016, 'maxDepth': 5.358963911971791, 'nestimator': 458.35292972619135, 'subsample': 0.9834736936183406}}, {'target': 0.6858826455213682, 'params': {'colSam': 0.9760764877975118, 'learningrate': 0.16931486759099787, 'maxDepth': 48.79728375696122, 'nestimator': 175.37958389633292, 'subsample': 0.5680294794736774}}, {'target': 0.6832234247406065, 'params': {'colSam': 0.9613218402163025, 'learningrate': 0.11965134350793272, 'maxDepth': 20.008758337350464, 'nestimator': 492.81583536751305, 'subsample': 0.7714500564261506}}, {'target': 0.6926861053477763, 'params': {'colSam': 0.8070262134442205, 'learningrate': 0.18379495508094829, 'maxDepth': 46.14979417421206, 'nestimator': 303.9075646275045, 'subsample': 0.6646077442915713}}, {'target': 0.682687395000361, 'params': {'colSam': 0.5007982393889944, 'learningrate': 0.1747316599501395, 'maxDepth': 53.32220338028619, 'nestimator': 238.68193419315583, 'subsample': 0.5770259845881263}}, {'target': 0.6878119159913594, 'params': {'colSam': 0.7964714332300211, 'learningrate': 0.06657713941773857, 'maxDepth': 78.01756275726277, 'nestimator': 360.6817169050739, 'subsample': 0.999425912231948}}, {'target': 0.6848897987147162, 'params': {'colSam': 0.42821486344125376, 'learningrate': 0.12743414618080923, 'maxDepth': 10.216237929803288, 'nestimator': 236.39268740260832, 'subsample': 0.9171557739700922}}, {'target': 0.6844121051349117, 'params': {'colSam': 0.5995063543275372, 'learningrate': 0.0953503043852451, 'maxDepth': 66.52278666149576, 'nestimator': 350.94790309757263, 'subsample': 0.7353041491806618}}, {'target': 0.6853513981366677, 'params': {'colSam': 0.9346098593643136, 'learningrate': 0.10057565072533782, 'maxDepth': 54.042101133321005, 'nestimator': 152.60015688771244, 'subsample': 0.864903799650876}}]\n"
     ]
    }
   ],
   "source": [
    "graBO = bayesOpt(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_gra = graBO.max['params']\n",
    " \n",
    "# 모델에 적용\n",
    "model = gra_evaluate(\n",
    "    learningrate=params_gra['learningrate'],\n",
    "    nestimator=params_gra['nestimator'],\n",
    "     maxDepth = params_gra['maxDepth'],\n",
    "     subsample = params_gra['subsample'],\n",
    "     colSam = params_gra['colSam'],\n",
    "     output = 'model'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colSam': 0.4103701413748254,\n",
       " 'learningrate': 0.18372595282799156,\n",
       " 'maxDepth': 65.09488850654324,\n",
       " 'nestimator': 154.61102957217008,\n",
       " 'subsample': 0.9223553672903531}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_gra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▎                                                                          | 1/9 [00:06<00:55,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier                                 0.603701 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▋                                                                 | 2/9 [00:36<01:35, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier                                        0.672537 29.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 3/9 [00:36<00:58,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression                                   0.681552 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|█████████████████████████████████████▎                                              | 4/9 [01:04<01:16, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier                               0.663322 28.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████▋                                     | 5/9 [02:39<02:36, 39.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier                           0.662798 95.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 6/9 [02:40<01:22, 27.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier                               0.627522 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|█████████████████████████████████████████████████████████████████▎                  | 7/9 [03:00<00:50, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier                                 0.671717 20.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|██████████████████████████████████████████████████████████████████████████▋         | 8/9 [03:16<00:22, 22.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier                                        0.677528 15.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [03:30<00:00, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier                                       0.680448 14.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clfs = [\n",
    "    (\n",
    "        KNeighborsClassifier(),              # 사용하려는 모델\n",
    "        {'n_neighbors': [3,5,7,9,11,13,15,17,19],       # 최적화하려는 하이퍼파라미터\n",
    "         'weights': ['uniform','distance']}\n",
    "    ),\n",
    "    (\n",
    "        MLPClassifier(random_state=0),\n",
    "        {'alpha':[0.0001],\n",
    "            'batch_size': ['auto', 32, 64, 128],\n",
    "         'learning_rate' : ['constant', 'adaptive'],\n",
    "         'activation': ['tanh', 'relu'],\n",
    "         'solver': ['sgd', 'adam']}\n",
    "    ),\n",
    "    (\n",
    "        LogisticRegression(random_state=0),  \n",
    "        {'C': [ 0.001, 0.01, 0.1, 1.0, 10.0],      \n",
    "         'penalty': ['l1','l2']}\n",
    "    ),\n",
    "    (\n",
    "        RandomForestClassifier(random_state=0),\n",
    "        {'n_estimators': np.arange(300, 500, 1),\n",
    "         'max_depth': [None,3,4,5,6,7],\n",
    "         #'max_features': (np.arange(0.5, 1.0, 0.1)*X_train.shape[1]).astype(int),\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        GradientBoostingClassifier(random_state=0),\n",
    "        {'n_estimators': np.arange(200, 400, 1),\n",
    "             'learning_rate': [0.01, 0.1,0.03,0.07,0.05],\n",
    "            'max_depth': [None,3,4,5,6,7]}\n",
    "    ),\n",
    "    (\n",
    "        DecisionTreeClassifier(random_state=0),\n",
    "        {'max_depth': [None,3,4,5,6,7],\n",
    "        'max_features': (np.arange(0.5, 1.0, 0.1)*X_train.shape[1]).astype(int)\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        ExtraTreesClassifier(random_state=0),\n",
    "        {'n_estimators': np.arange(300, 500, 1),\n",
    "         'max_depth': [None,5,6,7,8,9,10],\n",
    "        #'max_features': (np.arange(0.5, 1.0, 0.1)*X_train.shape[1]).astype(int),\n",
    "}\n",
    "    ),\n",
    "    (\n",
    "        xgb.XGBClassifier(random_state=0),\n",
    "        {'n_estimators': np.arange(100, 200, 1),\n",
    "         'max_depth': [1,3,5],\n",
    "          \"learning_rate\": [0.05, 0.1,0.16],}\n",
    "    ),\n",
    "    (\n",
    "        lgb.LGBMClassifier(random_state=0),\n",
    "        {'n_estimators':np.arange(300, 400, 1),\n",
    "         'max_depth': [1,2,3,5],\n",
    "          \"learning_rate\": [0.01,0.05, 0.1,0.16],}\n",
    "    ),\n",
    "    #(GaussianNB()),(LGBMClassifier()),\n",
    "    #(\n",
    "    #        XGBClassifier(),\n",
    "    #        {'n_estimators':[100, 200, 300,400, 500], \n",
    "    #         'learning_rate':[1, 0.01, 0.01],\n",
    "    #         'max_depth':[None,3,4,5,6,7,8,9,10]}\n",
    "    #),\n",
    "\n",
    "#        (\n",
    "#        SVC(),\n",
    "#        {'gamma':[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "#         'C':[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "#    ),\n",
    "]\n",
    "\n",
    "clfs_tuned = []  # 튜닝된 모델을 저장\n",
    "for clf, param_grid in tqdm(clfs):\n",
    "    start = time.time()\n",
    "    rand_search = RandomizedSearchCV(clf, param_grid, n_iter=50, scoring='roc_auc', \n",
    "                                     cv=skfold, random_state=0, n_jobs=-1)\n",
    "    rand_search.fit(X_train, y_train)\n",
    "    clf_name = type(clf).__name__\n",
    "    clf_score = rand_search.score(X_dev, y_dev)\n",
    "    print('{:30s} {:30f} {:.1f}'.format(clf_name, clf_score, time.time() - start))\n",
    "    clfs_tuned.append((clf_name, rand_search, clf_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Correlation between models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAHlCAYAAADr6sZuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAADW60lEQVR4nOydd3wVxdeHn3NvQnoBEnrv0puIINIUFAui8KrYUBQLYC8ooKjAT1QQFBsoItjABkpR6TX03nsH6SGN1PP+sZvkJqSA5OZydR4+98PuzOzsd2fv3pw9c2ZGVBWDwWAwGAwGb8LhaQEGg8FgMBgMl4oxYAwGg8FgMHgdxoAxGAwGg8HgdRgDxmAwGAwGg9dhDBiDwWAwGAxehzFgDAaDwWAweB3GgDEYDBeNiFQSkXX/4LhBIlKjgLX0EJGRBVnnvw0RuUNExl9EuX0iEu5+RQZDwWEMGIPBixGRW0RkjogsF5ElIrJSRIKuAF3dROTq9H1VHaSqOzypKR0RqSAifTytw2AwXB7GgDEYvBQReQp4BnhAVa9R1ZZAe+D8ZdYrBSDvFqBsAdTjDqoAN3hahMFguDyMAWMweCEiUhx4Gfg/VT2Snq6q51Q11S5zj4gsEpEFIrJYRFq7HH9WRF6xPTe1RGS+iLwmIvOAB0UkWETGishsEYkSkcdy0OAUkckislBE1orIADt9MHATMFhEfrDT5otIQ3u7hIh8KyLz7Lo/FhF/O2+QiAwXkZ9EZIWIzBSR4DyaIlhEvrI1rBKRdi76OorIXPszTURKi8h1wEjgOltTExHZ53JMHxH5w2V/vt0+ubZHTuex08eLyOsi8ruIrBORb0Qkx99c+7pHi8jPIrJVREaIyK0iMktENonIqy5lq4rIFLv9lonIW+lGp4iEisgE+77/BbTJdp6X7OMWicgnIuLMli8iMti+7uUi0jOPtjcYPIuqmo/5mI+XfYDOwOQ88q8FVgJh9n4lYA8QYe+nAHe5lJ8PfOCy/xnQyd72BVbZdVQC1tnpTqCevV0EOAhE2vvjgTuy1d/Q3v4DuN8lbwQw2N4eBCwHAu39b4CncrnGHsARoLy9XxPYDwQClYE/AX87rxvwpb3dBpjiUs8Cl+uYBqwGAoAQYFM+7ZHXecYDv9rt5LDP0ymXaxkELLLr9gW2AD8AYl/PMaCoXdd6oLV9nA/wI/CovT8GeNHl/kwCxtv79wDDXM75MZb3DmAfEA40BJa7lPHz9HfdfMwnt48PBoPBGwkAEvLIvwP4XFWjAVR1n4gsBppj/ZFOw/rj6sovLtudgVoi8rK974/1x3pvegFVTRWRcBF5C6gOBAFlgBO5iRKRQKCOqn7jkjwamAwMsPd/VdV4e3shlmGSG9NV9aCtZ7uI7AJq2ddZDfjDdk74AKdyqWMqcLOIHMbqfpuNZeT4AjPtMrm1x1X5nGeSZnrElgBV87iWaaqabJddY+8rEC8iu4FyWIZnjKousK85RUQ+BZ4CvsDquutr56WKyI/ArXb9dwJVRWS+vR8MHMqmYTfgLyLDgI9V9UAeeg0Gj2IMGIPBO1kDDBERP1VNzCHfiWWkuKJAqr0dr6rZ82Nctn2AjtnrFpFKLtsPAHdheQ92YXki8oufcdo6ctMFWWN4kuxjciMp234QEGsf84Oq9s9HD8AU4Evgb+B3LE9VN7uO7+0yubVH3XzOcynX4lp3SrZjk8lsu7zuqz9Z29LPZdsJ9FPVWbkJUNUYEWkKdAV+E5FRqvpVHpoNBo9hYmAMBi9ErRE984EvRSQkPV1EIkTEB+sP8eMiEmqnVwCaAksv8hRzsQKE0+ttmkOZq4GZqroOKAk0cMlLAEJz0B0D7BKRe1ySnwJ+vkhd2blZRIrZGltgGTC7gXnAPSJSws4LEZF0T04Wbaq6BwjD+qP9O1YbNcXqTklvr9zaI6/zuINtQIQdy4Mdw/I4me0XBTxs5/ljdbOlMxvoLSK+dn6V9LZLR6yh1E5V/R54EbjdbVdiMFwmxgNjMHgvvbD+yCwUkUSsN/Y4rNiWBXbXwiwRibfz7k/vUroIngY+F5HlWJ6BDVhxH658BkwQke5Yf1jXu+R9B4wVkQ6qen+24+4HPhKR3ljegsXA8IvUlZ1lts5ILK9FN7vLZpOIvAn8KSIxWF6LV+xj1gIOEVkAPGMbYDOAa1T1NICI7AUSXbxUObaHquZ1ngLH7jLqAoyyu+MU+FlVJ9tFegPjROQR4CxWXE0VO28MVnfXShE5i+VxeyjbKSpi3dMzWB6jfu66FoPhchGri9VgMBgMBoPBezBdSAaDwWAwGLwOY8AYDAaDwWDwOkwMjMFgMBgMhkLBjld7FkhT1YEu6cHAWKwZvE8DD6rqubzqMh4Yg8FgMBgMhcVwrEB432zpzwG/q+r1wCzgyfwqMgaMwWAwGAyGQkFVH8SaoDI77bBmlQZrWoBr86vLdCEZ8iWgUZ8rdqjaqmnDPC0hT5yOglgX0T3sPxPnaQl5Uj480NMS8qRKCY8v+p0nC3fmOiGyxykZ7O9pCXlyJT+3AHXLBrtFYEH81p9f9/HjWFM8pDNGVcdcxKF+6TNRY81mXTS/A4wBYzAYDAaDoUCwjZWLMViykyYiDnvupaLksSRJOqYLyWAwGAwGA4jj8j//nOVYa46BtUTJ7PwOMAaMwWAwGAwGELn8zyWfUoaJSBHgf0Ave7HRJkC+a3CZLiSDwWAwGAyX60G5aFR1PtZabqhq+tIbJ4GbL6UeY8AYDAaDwWD4Rx4UT2K6kAwGg8FgMHgdxgNjMBgMBoOh0LqQCgpjwBgMBoPBYPC6LiRjwBgMBoPBYPA6D8wVo1ZEltn/O0XkJxHpaO+riPR0KedvD7PKrZ4AEXk7n3MNEpGbckgfLyK1/vFF5Hyu9iIyV0SWiEiUiHQRkUoi8sNl1vu8iJSxt18RkVUi0jq/azcYDAaD4d/AleiB+Qj4UVX/tPfXAo+JyExVPZLfwaqaAAzMr1xhICItgX7A/6nqSTvNDyh9uXWr6giX3f8DrrZnMFxwkdpEVa/YJQIMBoPBUMh4WRfSFeOBARCRAcAGVZ3kkpwEPA98nEP5YBH5zvZwTBORYnZ6ujenvIj8JSKzRWRoerpNexGZKSJbRaStS/rd9jFr0700IlJLRP4QkXkislBEmtjp4+1JeJaLSJCITBKRxSIy3a7rVeDxdOMFQFUTs11DJxGZY9fxlp12u4gstevqIiIRIjJDRBaJyBcu564lIiOB6sBcEYl0ufZSIvKb3TaTRKSI7fmZKSJTgKcv6eYYDAaD4d+NZ2fivWSuJA9Maazpg5tlz1DVpSKyV0S6A7+4ZPUDJqvqFBHpBPQGXLtQ/ge8qapLRORqrNUuXarVm0WkMZbHZp6dfkZVO4hIceAv4A9gNPCUqu4QkYrAN0Aru/xuVX1FRBoASap6nUjGXSypqnvyue6VqtpeRJzABhEZBDwMPKCqu+26bgNWq+pAl7rTL+JZEWmuqm0AJNOCfg94Q1XXishTwN3AIqAmUFtVz+ejy2AwGAz/JbzMA3MlGTBHgU+BcSLyYA7dG/2BuVh/hNNpDLQWkWexrmVltmOqquoSe3t1trz59v9bybrq5SwAVT0lIoliWQRBqrrDTt8vIq7tttROX297Oz4CpmMZPmdEpISqHs/jum8RkXpYnqZAoAjwLNBHRBKAEcA0oLKIjAK+B5blUpcr9YEPbIPGn8xlytd4yniJKBpMn+5tSdM03vpkev4HuIHvxn3Clg1rSE1N5cnnB1ChclUA9u7aztv9+lK2fEUAej3zKuUrVWHj2pVMGDMKhzi4+Y7/o02HW92q79svP2azra/3CwMz9O3ZuZ23XumToe/x516lQqWqbFi7kq8/G4k4HNzS5W7aulnf9O/GsmvzetLSUrnnyZcoXaFKRt6yOdNZ8tdUHA4nne7tSc36TTPyfhn3ET4+Ptz+4JNu1ffduE/YvH4NaampPPlCtvv7Sl/KpLffsy739/NRiDjo1MW993f0hyNZs3oVqSkpDHzzbapVq54l/9TJk3Tq2J6FS1fg5+fHiuXL+PTjj0hKSqL9DTfyyKO9cqm5YJj27Vh2b1lPamoq9z6Vw739cyricHLLvT2p2SDrvXX6+NDZzff2h68+ZevGtaSlptDruf6Ur2Td2327tjP0tacpU866t48+049yFauwdN5f/DF1MklJiXTqcg/X33iL27R9P+4TtmxYS2pqKk883z/L925wv76ULV8JgMee6Uf5SlVYMu8vZk6ZRFJiIp3uvJc2Hdyn7ZLwsiDeK8mAQVW/FpEKWH+0n8uWlyAiL9t56cbNDuBnVV0EVgBvtirPikgDVV1PVu8LQFp61dnSmwFbbU9LiqqqiCSJSDVV3SUi5YEYl/Ip9rn9gfGq+pXd1bQM+Bz41DbI4uxyQdnO10dVm4pIMPCQnXZcVV8SkXZY3qEBqjrS9tKswFonIj92Ai+q6j7ba+OL5eVKuYhj3cI7z3dh98ETBPoX8cj5t2xYQ/SZUwwe+QX79+5iwucjGfDORxn5117fnseefiXLMRPHfMig9z7Fz9+fl564n9Y33uLq5SpQNm9Yw9kzpxk66kv279nF+M8+4PVhozPyW7RuT69n+mU5ZsLno3hr+Gf4+fvzwuP30caN+nZvWU/M2dM8M2Q0R/bvYerXn/DEwPcBOHpgD7u3rOe5/32Gw5H1R/D0iWNsX7+SOk2udYuudLZsWMPZ06cYMsq6v19/PpKBrve39YX3d8KYDxn0vn1/H3ff/V2zehWnT51i3NffsHPnDj54/10+/mxsljLjvhhDeLj1LqWqjBzxPmO+HE9AQAC9evbgxg43Ub5ChQLXBrBrc9Z7O2X8Jzz5erZ7+07O93bbupXUaeree7t141qiz5zmzRFjOLB3F9+MGcWrQz/MyG/eqj2P9H05Yz825hx//vYjr7/3Kampqbz+bE+atmhNYFBwgWvbsmEtZ8+c5u2RYzmwdxcTPh/FgHcytV17/Q08+nRWbTOnTOaN9z8jLTWF/k/3pFlL92j7t3PFmVuq+jYQIiKv5ZC3CDjskjQUeNU2GH4HqmY7pB8wVkTmAc2Bi/E81BORP4FvsTwhAH2AMXY9nwN9cziuFrBcROYCO1T1rKr+DEwF/hSR+SIyx9bhynIRWQUMBw7YaSNEZCGW8fIz0EZElmN5h6ZdxDUAvIblzZpr11HsIo9zG48OnMji1bs9dv51q5ZxXTtr8FnFytWIiYnOkh8cEnrBMcGhocTHxXI+IQH/gEC3GQcA61ZG0aq9ra9KNWLOncuSH5STvpCwQtO3bd0KGre6EYAyFasQF5upL2r2dIqVKMXo159m3HsDiT13NiNv2jdjuKHLfW7Tlc66Vcsy269yNWLPZb2/QcEXtl9ISOHc36VLFnNTJ+stu3r1GkRHZ9W2dctmEKFc+fIAnDlzhsjISIKDg3E6nVzX6no2b97kFm1g3dsm12fe2/hs97ZoZCk+Gvg0497Nem9//2YMN97p/nu7ftUyWrbrCECFytWIzefZOHb4IJWq1cTH1xc/f3+qX1WPwwf2uUlbFNe5asv2uxIUEnKBtsrVa+Lr64uffwA1atfj0IG9btF2yXhgMcfL4YrxwKhqc5ftR3NKt/efddk+DnTKo64tqtoMQES6ABF2/iCXsueBNvZ2j1y0beRCD06W8qq6jpzjdyYAE3Ko9h47v3cOeTn5Ymfmce7m2bftLq8LNKef979I9NnThIZn9hY6nT6kpaXhcDhwOJ0sXzyPTetWUqX6VTz4+LP4+vpye9f7eenJ+/Fx+nDPw+51kUefPUNYmKs+Z4Y+p9PJ8kXz2LR2FVVq1KLHE8/h6+tL5/+7nxcevw+njw/d3awvJvoMwaHhmfocmfpOHD3IVY2u4enBo1m7dB5/TPqKro89R9TsaZSvWpPwiEiOHsgvHOzyiD6T9f468ri/Dz1h399u9/PiE/fj4+PDvT3c136nT5+maLHMdwjXexsfH8/ID4Yz/IMPeaaPpSE8PJyjR49y4sRxwsOLsnr1Km4uWdJt+mKz3VuHi74TRw5yVeNreGaIdW9n/vAV3Xo9R9Qs+94Wj+SIm+/tubOnCQ3LWZ/D6WTF4nlsXreKytVr8UCvZyhVphw7tmwgPi4Wh8PBzm2buK79BTNnFAjRZ88QFp77c+uq7cHHn6VkmXLs2LyR+LhYxOFg59ZNXH/DJa1h6D68rAvJu9ReOvfYno/5wAPAYA/r8RpEpJdYc8usSjm52dNyCoSgoGDiYjLf3BwiGS7xipWrMfLLyQwe+SVBwSHMnv4LZ8+cZtov3/P599P5/IfpbFy7kn27d7hNX2BQMLEub77icNFXpRoffvUjQz/8kuDgUP6aZun7/efvGDtpBl/8MIMNbtYXEBhMQlxm76k4HBn6nE5nRhdRnSYtOHZwH8cPH2DDsoW0ue3/3KbJlcDs99eR9f6OGjeZIaO+JDgkhFl2+037+XvG/DCdMW6+vyHBwVk8ag6Xtnv/3Xd4pOdjBAcHZ8nvP/AN+r30Ai+98CwRERGUKVPWLdoA/AODiY91ubeSqc/hdFI7h3u7fvlC2hbmvXXR59p+FSpXY/gXk3jzg7HWszvjV4JDw7jrvp4MG/Acn40YTIlSZShRqozbtMXG5Nx2FSpX44MvJ/P2yC8IDg5l9vRfCQkNo+v9PRn62rN8+v5gSpQuS2RJ92i7ZLxsFNK/2oBR1Ymq2sb+3Ok6nNmQN6o6RlWbqmpTn4g6npZTIFxVrxFRC+cAcHDfHopHZr7RpqZaoUEiQlBwCIgQE30Wp9OJn58/TqcPwcEhnDqRVzz25VG7fiOWLpgNwIF9u4lw1ZeSVZ+IcC76TKY+Hx+Cg0M5eeJvt+mrUrs+65Zag/WOHtxLePHIjLxKNeuyeXUUALs2raFMpaqsWjQL1TS+HjGIPyaNZ+PKJaxfdlHTFP0jrPZzub8Rud9fse+vw+X+BoW47/42atKUWX/9AcDuXbsoWbIUAKdOnWLrlk38/NNkXn7xOXbv3sXA/lacU4OGjfhy/ETefGsIJ0+epEHDRm7RBlC1dn3WReV8byvXrMsW+97uTL+3C2ehaWmMHz6ImZPHs2mFe+9trXqNWGY/u4f276FYRImMvAvuLVY3RtMWrXnzg7Hc/+jTiDiyHFOQWL8r1nNr/a7koc3uYbm6ZWsGj/qCB3r1RUSyHONRHHL5n0JEzFxmhvwIaNSnwL4krZpUp0PLqxj44W8FUt+qacMuumxaWhpjR73DgX27CAgI4onn+zNjyiTuffgpVkUt5PefvsXhcFCiVBmefH4AvkWKMHniWNYuXwIiVK5Wg0f7vnJBIGNeOC/hgU5LS+Pzkf/jwN7dBAQG8uQLA5jx6yS6P/IUK5cu4Lcfv8XhtPT1fmEgvkWKMGnCGFYvX4KIULlaTXo9ffH69p+Ju2ht6fp+HDOCowf24B8QyN1PvsTCGT9zy72PkZqSzLcfDSX23Fn8A4O5r8+rBIWGZRy7c9Matq5ZfkmjkMqHB16yvjGj3uHA3l0EBAbx5PP9mfHrJO595ClWLV3Iby7396kX7Ps7YSxrVixBECpVq8Fjl9B+VUpkj8fPW9vQwW+ya+dOgoKCGPjGW3z/3Tf06fsMvkUyg9p79niATz7/Aj8/P95/9x02bliPj48PL7z0CrXr1L2k9li488Ql6ftxzAiO7Lfu7T3p97a7dW+/+WgosdFnCQjK4d5uXMOWtcsvaRRSyWD/S7qWtLQ0vvxwGAf3Wc/GY8++xh9TJ3NPjydZFbWQ6T9/h8PpJLJkaR5/rj++RYowakh/Th4/RkBgED37vkzJMuUu+nyX+tyOHfUOB/ftxj8giCeef42ZUyZzz8OWtmk/fYvD4aREqdI8Yf+ufDD4tQxtjz79CqUuQRtA3bLBbrEUAtq+fdm/9QnzBhaaFWMMGA8jItWBx4EE4HqsuKReqro5W7mH7XKpwOuqOkdE7gBewBp6PUJVJ9lDskdgDcneC/TAChx27T6rD7TFClJ+TVWP5qWxIA2YguZSDBhPcCk/hIXNpRowhc2lGjCFzaUYMJ7gUgyYwuZSDZjC5kp+bsGNBky7IZdvwMztX2iNd8UE8f6H6YcV5HufqrYWkbpYk9BlBCeLSB2sifNa2MsFpA/HfhFoj3UfF4vIVGAP0MEe/v0F0ExVF2MHKotIOSxjZ72IDAXeAh4rnEs1GAwGwxWLl01k96+OgbnSEZFArHlobsCaoA5V3cSFQ557AvuxlguYLCIRWF6VOaqaaM8xsxyopapxtvHib9eTfXjA68AQ+1w7gQpirc9kMBgMhv8yJojXcAnUADYBJQBXf29KtiUDqgMn7eUCJgNv5HDMKewZhUXkO2AfsBHIiOoUkZJAaXtiv3S2YS0vYDAYDAaD12AMGM8SCMQD0WRdziAtvavIJgWYYW9PB2rncExRbINGVbsDZbBm333IpUwP4KtsGuKAK7sz32AwGAzux8smsjMGjGc5hmVoLAK6AohIbeBQtnJRZMbEtAE2YC0pcJOI+NpdUXWBbSISBmAbQIcB1/mpO5NpCKVTBjhSQNdjMBgMBm/Fy7qQTBCvB1HVPSJSCyuQtpOILMJaZ+lxABEZhrWcwCfAVyLSDcvz8oi92OR4YDHWCKY3VDVFRO4WkYewFofciz2rr4gUw1otO2M5Bbubqryq7i+cKzYYDAbDFYuXBfEaA8bzRAGtVPWCSRRUNX3luSSgWw75Y4Gx2dLGAGNyKHsaeySSC/cD4/+JaIPBYDD8yzBLCRgukY+wAnI9QbKqTvTQuQ0Gg8Fg+McYD4yHsWNVfvTQub/3xHkNBoPBcAViupAMBoPBYDB4HV7WhWQMGIPBYDAYDF7ngfEuc8tgMBgMBoMB44ExGAwGg8EApgvJYDAYDAaDF2IMGMO/jVXThnlaQq40vfWV/At5EL/azT0tIVf8A/09LSFPfHyv7J+nm9tU87SEPPlx6jpPS8iVgKAAT0vIk7S0tPwLeZC/v7hgWrCCwctiYK7sXwiDwWAwGAyFg5d5YLxLrcFgMBgMBgPGA2MwGAwGgwFMF5LBYDAYDAYvxMu6kIwBYzAYDAaDwXhgDAaDwWAweB/iZQaMd/mLDAaDwWAwGDAeGIPBYDAYDHifB8YYMAaDwWAwGMC77BdjwBgMBoPBYPA+D4yJgcmGiKiI3JwtLUBE/haRNvb+fBHxz1Zmh52+TETedUmvIiI/2emLRWSwnb7sMnV2FJEb7e0bRGStiDwtIoOzazMYDAaD4d+G8cBcyE6gDzDTJe1h4EQ+x51W1TYAIjJeRFoDG4EfgEdVdYOd51cQIlX1T5fde+1zrL7Y40VEVFULQovBYDAYvB9v88AYA+ZCTgOHRaShqq4TESdwF1kNmvxYAZQFrgY+SzdeAFQ10bWgiFQGPgECgRigC1ARGIt1fxao6gAR+RSoj+U1ux64D/AHzgO3APVEpD/QH7gJSAZGAzUBxTJw9tqen2VAKPDIJVyTwWAwGP7FGAPm38Fw4DXgIaArMBUoczEHikgQcCvwJPAqliGSF6eAzqqaJCLjgGZAU+AbVf1SRBwiUhSoraot0z0n6V80VR1vd229o6rbbCMGLK/RdlV9UkRqAwOAnkAEMEZVt1xUS/wDvhv3CVs2rCE1NZUnnx9AhcpVAdi7aztv9+tL2fIVAej1zKuUr1SFjWtXMmHMKBzi4OY7/o82HW51l7Q8iSgaTJ/ubUnTNN76ZLpHNPTv2oAWtUrgdArPfrGcbYejAQgL9OXDx5oTEeJPzPlkHv9kKdHxSQy6pxFNq0YQ5O/D4B/XMWfD0ULT+nLnOlxbPQKnU3hp4hq2HzkHQGiALyMeakLxYD9iE1Po8+UKouOTC0XTi7deRfPqxXE6hFe+W8eOozEA+DqF9+9vTLniAcSdT6H3uFXEnE/htiZl6dG6Mv6+TsbN28PPKw66TVvnuiWoHhGE0wETVx3hyDnrXebBpmUoEWw5Zv19HZyKS+LTpQcJ8XPyQJOyhPj7cDo+ibHLDrlNG3jPd+/l22vTvEYETof1vUu/x6EBvgx/sDHFQ/yIPZ9C33ErC+1758ornevQvEYkPk7hxQmrsz0XTSke4kfc+WR6F+JzcbF4mwFjYmByQFW3A/4iUg54FPjyIg4rJiLzgV+AD1R1P3AAqJrPcbWAD0TkHaAyEIJl9JQWkRFATVU9AwwXkdFA94u8jMbAfbamT7A8LgBn3Wm8bNmwhugzpxg88gueeL4/Ez4fmSX/2uvb8/YHY3n7g7GUr1QFgIljPmTQe58y5MMvmTp5Ip7q2Xrn+S4kJifj6+P0yPmvrRlJZJg/twyexXNfLuet7o0z8p69rQ4/LdnHLYNnMX3VIXrfXAuAKcv3c+uQWXR9dy4DujUsNK3XVI8gMtSPLu8v4OWJa3i9a72MvL431+SX5Qfo8v4CZq49zOM3VC8UTc2qFicy1I+uHyym33frGNClTkZexwalOXQ6nrtGLGbmuqPc27ISYQG+PHR9Ze4ZtYS7Rizm0XZVCfZ3zztd9YhAQv18eH/+XiauOkLXBqUy8iasOsL78/fy/vy97DoZz8ytJwG4q34ppmz6m2Fz97jdePGW79411YoTGerPne8v5OVv1vJ61/oZeX1uqsmvKw5y5/sL+WPdEXoV0vcui77qEUSG+tPlvfm8NGE1r3fL1Pd0p1r8suIAXd6bz8x1R3j8xhqFri9fpAA+hYgxYHJnJDABWKaqcRdR/rSqtlHVjqo6y077FnhFRCqmF7I9NK4MBAaraj+sLiQAVdXBdt4XIuILzFDVPkBHEalH/uwAPrQ1tcHyJgGkXMSx/5h1q5ZxXbubAKhYuRoxMdFZ8oNDQi84Jjg0lPi4WM4nJOAfEOixt4BHB05k8erdHjk3QLt6Zfg5ah8AWw9FUzS4SEZe7fJFWbjlbwBmrjlIo6rFAVi39zQAMQnJRMcnFZrW1rVLMsX2Vmw7co7woEytV5UNY8l2K2Tsr/VHaVipWKFouv6qEkxdZf2h3340Joum07FJhAX6AlAsuAinYhOpVCKIzYeiSU5VziensmbfaaqXCnGLttqlgllxwHoWjpxLJKjIhUZy8UBfQv182HcmgUBfB0FFnNxSO5KX21amecVwt+hKx1u+e61rl+TXldb3bvuRc4QH+WbkXVUuNON79+f6ozSsVLRQNLnSpnZJfl1xALCei6KBme1Yq2wYS7Ydt/StO+IRff82jAGTC6oahfXH/qNcivxljzqalkcd+4GnsIyQBSIyF3g8W7EfgTki8hOQ/te+u4hEAdOAiUBxYIl9vD9WoHF+jAFutc87A7jmIo65bKLPniY0PPPBdDp9SEtLA8DhdLJ88Tz6P/MIX45+j+Rky316e9f7eenJ+3n2kW60v7lzYci8IokI9efkufMZ+ympmrE0yeaDZ7j96vIAtK5TGh9H5qNbxMfBsAevZsTUTYWnNcSPUzGZ4VyuWrcciqZT47IAXHeV1SVROJqK5Kppxa5TVC8VwpwB7ehydTn+WHeU/SfiaFK5GMH+PgT6OWlUqRhOh3u0hvj5EJOY+e6QmqYXvKzeUKM4s3da3peI4CKUDPHjuzVH+WDhPlpXLUqYm7xD4D3fvYjQrN+71LRMnVsPRdOpkfW9a1Ur0m338lL0pWTRd5Zb7Oei1VUl8HFeeX9+ReSyP4WJiYHJhqo2d9nu4LLdz2W7TV7HZUtfDtyYW3lVnYDl6clO9m6r7AbIeJe6euSi7e6L1ZkdEekF9AJ4450P6Xb/xcX7BgUFExdzLmPfIYLD/sGrWLkaI7+cjKoy6evPmT39F65tfSPTfvmez7+fjo+PDx++8wbVatamUtUr0L3qZs4lJGXxGqgq6b1pI6Zu4t2HrubOayuxeOvfHDgZC0DVUiG83KU+H07bzOaDZwtNa0xCMmEuWtNctI6asY2h3Rtyx9XlWbr9BAdPXowDswA0nU8hLDBnTf061+bz2buYu/lvapcLY1j3hvT5ahWjZm5n/JPNOXb2PAdPxnHoVLxbtCUkp2bxuqj9ScfHIZQPD2DSumOW9jTYezqeuKRUAHadjKdEcBGiz7vHgeot371zCcmEB2Z6XdLSXL932xlybwM6X12OqB0n3HYv89OX23Mxcvo2hnZvxB3NKrB0+/FCey4uBRMDY/hXoKpjVLWpqja9WOMF4Kp6jYhaOAeAg/v2UDyyZEZeaqr14ysiBAWHgAgx0WdxOp34+fnjdPoQHBzCqRPHC/ZivISobcfp3MzqbaxZNozDpzN/gGPPp/DU51F0eWcOoYG+TFq8F39fJ0Pub8KzXy4rVOMFYNnOk9xqv03WKB3C0TMJGXlxiSk889Uq7v5gEaEBvvy07EChaFq+6xS3NLZi7auXCuHY2UxNZYsFctz2MJyKSaRM0QAAZm08RtcPFjN0ymbSFI5Fn7+w4gJg54l4Gpezuk9Lh/pxJlvwZr3SwWw9Hpux/3dsImVC/fHzcSACFYsGcCwmywDGAsVbvnvLd57i1iblAOt7dyTb9+7Z8au5Z+RiQgrxe5dV30luc9F34XOxkv8bsZCQAF9+jNpf6Pryw3hgDP9pmjRvxZrlS+j/zCMEBARZgbxjRnHvw0+xKmohv//0LQ6HgxKlyvDk8wPwLVKEqjVr82qfHiBC5Wo1aNSshacvwyP8ue4wNzYsy4yBHYg9n8xzXy5n0D2NGPLjeq6tGUn/bg0Rgd9XHmTptuM0rlKcBpWK8eNL7TLquH/kAs7GuT8eYfbGo9xQrxRTXm5D3PlkXpq4hgF31WPYlE00qx5Bv851EYEZaw6zzO4WcTdzNh2jXZ2S/Pz8dcSdT+GV79fz2h21ee/3rbz3+1aG3tMAhwN8HA4G/2p1eYx+uAlligYSl5hC/x/Wu03bxqMx1CsdzMttK3M+JY2Jq45wV/2STNl0nNQ0pUZkEOuPxGSUT05Vpm85zvOtK5GmysLdZ4hJTHWbPm/57s3eeJT2dUsx5aXWxJ5P4eVv1tD/zrq8O3UzzapF8ModdRBgxtojhfa9c2XWhqO0r1eaqS+3ITYxhZcmrM54Lq6pHkG/O+oiIkxfc8gj+vLD2zwwYuYy8ywiUh0rLiYBa34XH6CXqm7OVu5hu1wq8DqQCAx2KVIfaGNvvw8EAEeB++0h2lOAkvZxK4BXgHHAa6qa5/jHzYfjrtgvSdNbX/G0hDzxq31RPXYewT/wyp6w2cf3yn6/urlNNU9LyJMfp67ztIRcCQgK8LSEPEmP27tS+fuLbm6xNIo/+P1l/9afmnBvoVlBV/YvxH+DflgxMPepamsRqQu8B3RKLyAidYBWQAtVdX2y2tj55YARqrrBHqF0m6omish7QGesQGGAW1X1lEu9Q4G3gMfcdnUGg8Fg8A68ywFjYmA8iYgEYsXy3QB8D6Cqm4Ds4057AvuBuSIyWUQisuW/Dgyxj9/oMtvvGSA9UiwNOOt6kKruBCoU1PIGBoPBYPBevC0GxhgwnqUGsAkoQda1llJExPXeVAdO2iOMJgNvpGeISEmgtKpm6cAXkZZAHSB9zaRzWMO1Z9nrNKWzDWu5AYPBYDD8h/E2A8Z0IXmWQCAea/4X11mN0rJ1FaUAM+zt6VjLFKTTA/gqfUesb9ArgC/woKqmQuZQaxEpA/yBFTMDlocm++R6BoPBYDAUOCLyNjnEe4pIOPAFEIk1qesD9iz0uWI8MJ7lGNYaS4uw1lzCXrco+7zhUWTGxLQBNrjkdSbTuAF4Ajiqqm+nGy92venG6jmshR7TKQMcuayrMBgMBoPX424PjIi0AkqqamusQSnvuWT3A76z86YAz+Wn13hgPIiq7hGRWliBtJ1EZBGW5fk4gIgMw1pO4BPgKxHphuWtecTOLwYkqarr5BW3AeH2qCWA31R1BPCbHXPjxFqoErubqrw9Y7DBYDAY/su4vweoAy7xnvbfsHTqAcPs7d+Ar/OrzBgwnicKaKWqT2bPUNX0McJJQLcc8k+TOXQ6Pa1T9nJ5pN+Py4y+BoPBYPjvUhAxLK6zuNuMUdUx9naO8Z52yMQG4E6sWejbcxH2iTFgPM9HwF0eOneyqn7voXMbDAaD4QqiIAwY21gZk0t2XvGeQ4GPROQeYD6wL79zmRgYD6Oqaar6Y/4l3XJuY7wYDAaDobDINd5TVWNUtYeq3giEYS1knCfGgDEYDAaDwVAYw6inA0XseM/3gVdEZJiIFBGRdiKyVESigBOqujC/ykwXksFgMBgMBrfP42J3F2WP90yP9ZwLXNJCeMaAMRgMBoPB4HVLCRgDxmAwGAwGg9etRm1iYAwGg8FgMHgdxgNjyBen48q1yv1qN/e0hDxJ3LLM0xJyxVH3krqbC520tLT8C3kQxxX8XAAkxsblX8hDJMbEeFpC3qSl5l/mX4i3eWCMAWMwGAwGg8EYMAaDwWAwGLwQ77JfTAyMwWAwGAwG78N4YAwGg8FgMJguJIPBYDAYDN6HMWAMBoPBYDB4HcaAMRgMBoPB4HV4mwFjgngNBoPBYDB4HcYDYzAYDAaDweuGURsDxmAwGAwGg+lCcjcicllzs4tIQxG5P5c8PxFp7rL/fh71DBKRDSKyQESWiEjjy9F1OYjIYBHx99T5DQaDweD9iMhlfwoTrzNgLhdVXaeq3+SSXRp41qXsi/lU97KqtgYeBQYWjMJLR1UHqOp5T53fYDAYDN6PyOV/ChOvN2BExCkio0VkvogsE5GX7XRfERlve0i+FZHVIuIvIm1E5B27zKe29yRKRPyAH4B2IvKXnb/M/j9ARL4QkXkislREQrPJqAocsstea2tZKCID7LRwEfnVPv5TEVllp/dwqbeliNwuIotsTQ/bZR6zzxklIs1FpJpdfpGIDLbLzLevLbe2aCMi34jILyKyUUSece9dMRgMBoPBvfwbYmAeAY6rahsRcQBTRGQm0BzYqao9RCQM2Op6kIgUBWqraksREVVVEbkHeEdV78l2jpeA1ar6qGT1kb0rIp8AS4HH7Lz3gZtV9ZyI/CAiFYFewE+q+q2IlAcWudQRqKptRSQc+AVoB6QAs0Xke6An0E5V4+3r6wt8o6pf2vsX0xYAFYE2WPd8HTDqItv3kvn2y4/ZvGENqamp9H5hIBUqVwVgz87tvPVKH8qWrwjA48+9SoVKVdmwdiVffzYScTi4pcvdtO1wq7uk0b9rA1rUKoHTKTz7xXK2HY4GICzQlw8fa05EiD8x55N5/JOlRMcnMeieRjStGkGQvw+Df1zHnA1H3aYtLyKKBtOne1vSNI23PpnuEQ0Ar91Vn2trReLjcPDcuBUZ7Rca6MuHPa+heKgfsQkpPPHZUqLjk/HzddCtRSU6NSlP9xELCk3nK3fU5doaEfg4HLwwYRXbj5yzdAb48kGPphQP8SP2fAq9v1hOdHxyoWi6vU4JqkcE4hDhmzVHOHouEYAHmpQhMrgIAAE+Dk7FJ/NZ1EGevLY8of4+JKcp+04n8MvGv92q7/XuTbmuTml8nA56f7yQrQfPABAWVIRP+7QmItSfmIRken4wl7NxSRnHDXvkWpJSUhk4YYX7tN13NdfVKYOPU+g9ekE2bW2ICAsgJiGJniPmZNPWwta23G3aAF6//xpbn4Peo+ex9cDpTH1PtyMiNMBqu+GzOBuXyOT+nShRNJDE5FRW7fib/l8tdau+i8XEwBQ+DYFpAKqaBswDatnpM+z0aGCX60GqegYYLiKjge75nKMZMMk+TlVV7fSXgaZANaAYEAnUAH4Tkfm2jnLZtBwEjrvUnf7NrQFUB2bZ11DS/jwGDBWRfkARYCxQWkRGADUvsi0AlqpqqqomAufyud5/zOYNazh75jRDR33JU88PYPxnH2TJb9G6PUNGfcGQUV9QoZJl2Ez4fBRvDf+Mdz4ax5RJE8hs3oLl2pqRRIb5c8vgWTz35XLe6p4ZtvTsbXX4ack+bhk8i+mrDtH7ZqvZpizfz61DZtH13bkM6NbQLbouhnee70JicjK+Pk6PaWhew2q/24bM4fmvVvDmvY0y8p69tTY/Re3jtiFzmLH6EE/dZLVfn05XIQgRIX6FpvOa6hFEhvpxx7vzeXHiKt7o1iAj7+lOtfhl+QHueHc+M9ce5okbaxSKpmoRgYT6ORm+YB/frjnCXfVKZuRNXH2EEQv2MWLBPnadjGfmthMZeaOXHGDEgn1uN15a1i5FifBAOvT/nT6fLGRoj4xQQF68qyGTFuyiQ//f+X35Pvp2rp+RVz4imHYNyrpZW2lL22tT6fPxQoY+fK2LtkZMWriTDq9N5fdl++jbOfNel48Ipl3Dcm7VBtCyjq3v1V/p8/E8hj7SIlNf1yZMmr+DDq/+yu/L9tD3jkx9d745jY6v/nrFGC9gupA8wWbgJgDb69AK2AActLcRkRJAHdeDRMQXmKGqfYCOIlIPSAVy+qXd4XoOV8+Hqp4GXgOGAyeBbUAHVW0DtFDVJdm01ALKuNSdYv+/19bd1j62maruB3ap6rNYRs9j1il1MFbMzRcX2RYArlaBeywEYN3KKFq1vwmAilWqEXMuq60UFJK99w2CQ8KIj4vlfEIC/gGBbnsLaFevDD9H7QNg66FoitpvvQC1yxdl4Rbrj8TMNQdpVLU4AOv2Wm9SMQnJRMcn4SkeHTiRxat3e+z8AO3qlc7afkGu7RfOovT2W3uIRlWs9hs+dTMTFxSu7jZ1SvHr8gMAbDt8jnAXnVeVC2PxNuv94c91R2hYuVihaKpdMpgVBy1v1ZFziQQVudAQLR7oS6i/D/vPWOFsCsQnpRaKvvYNyzF5kfWOt+XAGYq5GJx1KhZjwcbDAExfsY8m1SIz8t58oBnDf1nvXm2NyjF54U5b22mKhWSOV6hTsTgLNrhoq14iU9uD1zD8l7Vu1Wbpq8DkBTssfftPUyzYRV8lF33L99KkumW4pqlyNi7R7douFRPE635q2zEe8+0YkLFAZRFZhOVxmK6q24FPgZtFZDHwPywPjKuvuDiwRETmAv7ATuAIECEif2Y752Dg/0RkITATCHTNVNW5gBNoC7wLLBSRWcBIu8gQ4EX7+J5YBg3Z6jgBTAGi7BicV+2s721vTnfgD6C7iERheVomZqsmt7YoNKLPniEsrGjGvtPpJC0tLWN7+aJ5vNr3EcZ+9C7Jydbt6Px/9/PC4/fR9+Gu3HBzZ7dpiwj15+S5zFjnlFTNeGPYfPAMt19dHoDWdUrj48h8NIr4OBj24NWMmLrJbdq8gYhQP07FZP7opqSmubTfWW6z2+/62qXwcXrOFR0Z4sep2EydqWmZOrccjOaWxtZbeaurSuDjKBydIX5OYhMzjZE01Qum3GhfvThzdp7K2E9ITuW51pV4plVFqkcE4k4iwwI4GZ2Qse96bzftO03naysD0LZ+WXyc1rPx0A01Wbv7BIdPxRaCNtfn1kXb/lN0blHF0tagbMb37qEba7F21wkOn4xzq7YMfedyaztXfeUy9J2LT2LmkDuY9vbtXFe3zAV1Gi4Or4uBUdULX+Etz0R24lX1ZgARqQB8q6qpwHz7A3BNDse1cjlXc/v/08Ad2coNyqarm8vu79nKHlPV620tTbC6nFDV8dnqGItlhLimZT/vTuDLbGXauOxe0BaqOp/Ma864rrwQkV5YsTu8+e5H/N/9j+R3CACBQcHExmZ6XcQhOGxjoGKVanz41Y+oKj+M/5y/pv1CyzY38vvP3zF20gx8nD6MfOd1qteqQ6WqBe/aP5eQlOVtXFVJ760aMXUT7z50NXdeW4nFW//mwEnrR7lqqRBe7lKfD6dtZvPBswWuyZs4l5BMWGBm+6UpGe33wW+beefBptzZvCKLtx7nwAn3/+HIjbx0jpyxlf91b0SXZuVZsv0EB07FF4qmhOQ0Al28LqpZ3aA+DqF8uD+T1x/LSPt61REAwvx9ePq6irw9232erHPxSRQNzvS6uLbZuz+tZcRjLenWqhoLNx1h//EYqpUJ4/bmlblr8B+0qlvabbpy1pb53L774xpG9LrO0rbxCPv/dtH29kxaFYJxkKe+yasY8fj1dLu+Ogs3Hmb/8RgAeo2cA0DpYkFMffM2mvX9we06LwYvC4HxPgPmErhKRFwDVZ/1lBCgrYi8hvWblQg85UEtF4WqjgHGAGw7Gn/RXU616zdi6YLZ1KnfmAP7dhMRmdnXn5qSgtPHBxEhKDgEEeFc9BmcTid+fpbbNTg4lJMn/naLARO17Tidm1UkavsJapYN4/DpzD9esedTeOrzKADevLcRkxbvxd/XyZD7m/Dwh4tIKCRX/pVM1PYTdG5WgWU7TlCzTChHsrVfnzHWFE2D7mnIpCV7PSWTZTtPcFvTcizfeZIapbPqjDufwtPjVgLwetf6/Gh3ibmbXSfjaFw2lF0n4ykd4seZhKyBw3VLBbP1eFajzyGWIXE+OY1UN8WFpbNkyzG6tKjCki3HqFU+nMMnM70qsQnJ9PpwPgBDHrqG7+bt5O7rq+EQYcKL7YkMC6Bk0UBW7jjOb8v2Fby2zUdtbUepVb5oFq9KbEIyvUbNs7T1aM5383dwd+vqtrYbiAwPpGR4gK3NPd/JJZuP0KVlNZZszkWfbawMebgF3821HOJOh5CappyLTyI5Nc0tuv4JjkLySBYU/1oDRlU3YHXpeBxV/Qv4y9M6CoOmzVuxetliXu37CAGBgTz5wgC+/nwU3R95ipVLF/Dbj9/icDooUaoMvV8YiG+RIlSrWZuXez+EiFC5Wk0aN2vpFm1/rjvMjQ3LMmNgB2LPJ/Pcl8sZdE8jhvy4nmtrRtK/W0NE4PeVB1m67TiNqxSnQaVi/PhSu4w67h+5IMsoh/8Sf607zI0NyjB9wA3Enk/h+XEreOPuhgz9aQPNa0bSv2t9BGHaqoNEbT+Rf4VuYtaGo9xQrzS/vdKW2PMpvDhhFQO71uedXzdxTfUIXu1SFxGYvvowy3acLBRNG4/GUrdUCC+2qcT55DS+XXOEO+uVZOqm46SqUiMyiPVHYrIc81SLChTxceAQmLLJvUG8M1ftp2OT8sweejsxCcn0/XQhgx+8hje/W0mLq0ox6P6rEYSpy/ayZMtRlmzJHI3Xqm5pOjQu7xbjJUNb04rM/t8dxCQk0feTBQx+qDlvfruCFrVLM+i+ZojA1Ki9LNl8lCWbXbWVsbW5z6CeuXKfpW/YnZa+0fMZ3ONa3vxmuaXvgeaICFOX7mbJZsur9tPrtxDo54vTIbwx4bLmZi1QvM0DI+4a8WH493ApHpjCpvmLv3haQp4kbrlyfpyyE1C3Rf6FPIhPkSv7/arLzXXyL+RBJkxc7GkJuaNXjtchR9KubI9rwrQ+bjE16g6Yddm/9ZsG31hoZpA3BvH+qxCR6iLyvoi8LZnLElzwyygiD9uT0y0RkfZ2WlsRWSkiy0XkAZeyV4nITyJyk0taCbEm01tqz08jIvKViLi3A9tgMBgMBjdwZb/i/DfoB0wA7lPV1iJSF3gP6JRewDZoWmENy3Z9dRkG3ADEA6tE5Buggl1n9qEBw4CBqpoxlEZEhgJvkXMQtMFgMBj+Q3hbF5LxwHgQEQnECuy9AfgewDYwsk9O0RPYD8wVkckiEmGnnwbCgGAg1p5jb7+qPgTsczlPUaxh4wPEWoLgAftcO4EKYi2jYDAYDIb/MGYeGMOlUAPYBJQAXKMeU7ItE1AdOGkPl54MvGGnjwBW2XWMy+M8Vexz9QY6AE+4dB1t48IZfQ0Gg8HwH8MYMIZLIRCr+ycaKOqSnpatqygFeykCYDrWZH4lgGew1jiqiLUIZX1yJgVYrqqnVDUBWIw9Fw0QBwQVxMUYDAaDwXsxSwkYLoVjWMsKLAK6AohIbeyVrV2IIjMmpg3W8gARQIqqJqhqCnAGa92lnNgB1BGRYBFxYq3ftMPOK4M1A7HBYDAYDF6DCeL1IKq6R6y1kd4COtlLAMQAjwOIyDCsNY8+Ab4SkW5Y3ppHVPWUiKwSkaVYcTTrsJYayOk8CfayC3OwvDGfq+rfdjdVeXvNJYPBYDD8hynsLqDLxRgwnicKaKWqT2bPUNVX7M0koFsO+W8Db+dUqaoOyrY/BWutJVfuB8Zfol6DwWAw/AvxMvvFdCFdAXyEFcTrCZJVNfuCkAaDwWD4D+JtQbzGA+Nh7GDdHz107u89cV6DwWAwGC4XY8AYDAaDwWDwui4kY8AYDAaDwWAwQbwGg8FgMBi8Dy+zX4wBYzAYDAaDwXhgDP9C9p+J87SEXPEP9Pe0hDxx1G3haQm5krBpqacl5E2JSp5WkCdRG7IvWXaFce64pxXkTnBxTyvIG4fT0woMF4ExYAwGg8FgMJguJIPBYDAYDN6H6UIyGAwGg8HgdXiZ/WJm4jUYDAaDweB9GA+MwWAwGAwG04VkMBgMBoPB+/Ay+8UYMAaDwWAwGIwHxmAwGAwGgxfibQaMCeI1GAwGg8HgdRgPjMFgMBgMBq+LgXGbB0ZEzonIfBFZJiIjC6C+HiLyRAHUs8PWNV9Ehl9ufTnUX1VEyrnsVxGRn+x2WCwig+30ZZd5no4icqO9fYOIrBWRp0VksIhc2fPrGwwGg+GKQ0Qu+1OYuNMDs0VV2wCIyCQRaaCq6914vovldLqui0VERFX1Ios/ACwDDolIMeAH4FFV3WDX5Xcp584NVf3TZfde+xyrL/b4S7wmg8FgMPzL8TYPjNu7kGxvQARw3N4fBdQHQoEnVXWFiMwHZgI3AQHAbap6QkS6Ai8BZ4ETwGK7jtvt9FQgGnhEVU/ZXo2ZwM3ALCAZaA+kATepamIuGh8FetjlDgA9VTVRRFYC24EDIvIhMAYItrU8AFQAxmK14wIgyq7nThGpjeXh+izdeAHIrkFEKgOfAIFADNAFqOhar6oOEJFP7XZzANcD9wH+wHngFqCeiPQH+tvtmAyMBmoCimXg7LXbaJnd/o/k1B4Gg8Fg+O9hgngzqS0iy4FdwCBVPWqnD1bVtsDzwGMu5dfZ6ZOBe0Qk3C7TRlU7Yhkq2OmvAh1tT8o3wGt2HZHARFVtDnQA9qhqa2AL0NYuU8ylC6mXiNQE7rTPcz2wHuhll60BPKeqrwHvAW+oajssY+VuLMPhG1VtBbyuqtOB8cDLqjoCqGbXlxengM62zuNAs+z1ikhRoLaqtgRaqGpy+sGqOh74A3hQVWe51PswsN3W2xcYYKdHAGNU1RgvBoPBYPBa3N2F1FxEegO3A4tEJAB4TUQSgSAgxKX8Qvv/rVh/xGsAK1U1wU5fBfgB1e30eDt9NpbXA+Ckqu6xt/cCS1y2w+3tLF1IItINmK2qKS71PWpv71TVE/Z2feAD20L1B34EPgWeF5ERWB6Trdna4ABQFcira6cW8JCIxACVsdpkrGu9qrpVRIaLyGgsL8+3edSXTmPgahG5w95Pv46zqrrlIo7/x0z/biy7Nq8nLS2Ve558idIVqmTkLZsznSV/TcXhcNLp3p7UrN80I++XcR/h4+PD7Q8+6U55GbzcuQ7XVo/A6RRemriG7UfOARAa4MuIh5pQPNiP2MQU+ny5guj45HxqKxheu6s+19aKxMfh4LlxK9h2ONrSFOjLhz2voXioH7EJKTzx2VKi45Px83XQrUUlOjUpT/cRCwpFY05EFA2mT/e2pGkab30y3WM6Xn+wJdfVK4eP00HvUX+xdf8pAMKC/Pj0uY5EhAUQk5BEz3dncDY2kciwQEY/cyMligZy8HgMD/5vmtu09W5XhSaViuJ0CG9N3cruE3EA+DiFNzvXpmxRf+ISU3nlx43EJqYy8t76FA8uQlKKsulwNB/8tctt2gBef7gN1zWoYLXd8Ols3Wf9ZIQF+fHpS7cRER5ITHwiPYdOpXalSN7o2Sbj2LpVStLxuQls2nPcffrua8Z1dUvj43DQ++P5bD1wxtZXhE/7tiUizJ+YhGR6Dp/D2bhEJve/iRLhgSQmp7Jqx3H6j49yo7arua5OGXycQu/RC9h60EVbnzaZ37sRczgbl5Rx3LBHWpCUksrACcvdpu1S8DIHjPu7kFT1YxGZIyL1sIyS46r6PxG5C+jmWtTlfwEOAU1FxMc2Ltpg/fHeAzQTkQDbuGkHrM1WR/Y682Ir0ENERqlqarb6UlzK7QReVNV9IuIAfAGHqg4WkSDgL6AlVrdWepzLt8AvIrJcVfcDiEiQqsa51DsQ6KWqR0Xkt8xmy6xXRNoAM1T1NxGZICIbyJ8dQJSqTrTPG5jDNRU4u7esJ+bsaZ4ZMpoj+/cw9etPeGLg+wAcPbCH3VvW89z/PsPhyOr8O33iGNvXr6ROk2vdKS+Da6pHEBnqR5f3F1CrTCivd63HfR9a9m7fm2vyy/IDzFh7hO7XVeLxG6rz7m9utfkAaF4jksgwf24bMoeryoXx5r2NuPv9+QA8e2ttforax7RVh3igdVWeuqkW//tlI306XcXxs+eJCCmQ0Kp/zDvPd2H3wRME+hfxmIaWdctSomggHV6aRO2KEQx9tDVdBv4CwIt3N2PSvK1MXbKTHjfVo++dTXl7whIGP3o9b369hC37T7pVW+OK4RQPLsIj41ZTrUQQz3esTu9v1gHQrlYkR6PP0/+XzdzZuAx3NinLhKUHAOjzzXqiE9xvPLesV54SxYLo8OwEaleKZOjj7eny6g8AvNi9JZPmbGLqom306NSQvt2u4e2vFtDxuYkAlI0IYVjvDm41XlrWLk2J8AA6vDqV2hWKMfThFnR50zKUX+zamEkLdjI1ag89OlxF3zvq8/a3KwG4863pnI7JMXKggLUF0uG1dG3X0uWtGZa2uxoxaeFOpkbtpceNV9G3cwPe/s7SVj4imHYNy/HHqv1u1XcpOLzMgimseWCeA0ZhxV50FZE/gQZ5HaCqR4BfgJUiMhO7C0lVTwHDgXkiMhfoDLzzT4Wp6iasuJkldn2VgK9yKPoaMM4u8zNQDOguIlHANGCiXW4u8J6I9LaNlqeAL0RkgX3s49nq/RGYIyI/pV9jDvUWd9Hnj2VM5ccY4Fb7vDOAay7imMtm27oVNG51IwBlKlYhLvZcRl7U7OkUK1GK0a8/zbj3BhJ77mxG3rRvxnBDl/sKQyIArWuXZMqKg5bmI+cID8r8w3tV2TCWbLfePv9af5SGlYoViqZ29Urzc9Q+ALYeiqaoi6ba5cNZtOVvAGauPUSjKsUBGD51MxMX7C4UfXnx6MCJLF7tWR3tG1di8vxtAGzZf5JiIZmD8epUimTBessomB61myY1ShEe7EexEH/6dW/O7OH3cG/72m7Tdm3VYszcaN2/XcfjCAvwzcg7E59MqL/1Lhke5MuZOMtgSVOIOV84nr/2Tasyec4mALbsO0Gx0ICMvDpVSrBg7T4Api/dQZOaZbIc++pD1zPsm8Xu1deoPJMXWj97Ww6cplhwpsFep2JxFmw4bOlbvo8m1UsAkJZGFm+H+7SVy6rN9Xvnqm1FpjaANx+8huG/rOVKQuTyP4WJ2zwwdhxK+vYGLM8GQJMcyrZx2f4DK6YDVR2OZaxkL/8j1h/+vM55j8v2+zmVcUkbjRXwmld9O1yuIZ0v7Y/rMUuwPE3p+8uBG3OrW1UnABOy52evlwsNkPEudfVw2W7jUubu3M7rLmKizxAcGp6x73Q4SUtLw+FwcOLoQa5qdA1PDx7N2qXz+GPSV3R97DmiZk+jfNWahEdEcvTAntwrL0AiQvw45fJmlpKqiIAqbDkUTafGZfl+8T6uu6oETmfhPJURodk1pWVo2nzwLLddXZ5vFuzh+tql8CkkTd5EZHggJ88mZOy7tt+mvSfo3LI6X/+5ibaNKuDjFCqXCqd6uaK0e+574hNTmPFON+at3c+x03F5nOWfUSyoCGdc/pimpGV+39buP8vjrSvzS5/mqMIDY6039LjEFMb2aEJKWhpjFuxl9b6zBa4rnciigZw8G5+xn6Xtdh+n8/W1+HrGOto2royPM/O9t0TRIEoVC2bj7r/dpg0gMjyAk9HnM/W5tN+mfafo3KIKX8/aStsGZfGxvbvnEpKYOfh2klPSeGfyahZvOuIebWHZtLm23f50bdssbfZz+9CNtVi76wSHT8ZRp0LhvCBdKYjI21gDUXyweh822+lFsP7uVcIa0HKvqkbnVg+YmXgNuWAHOK8SkVUzJudkX+VMQGAwCXExmfU4HBndRU6nM6OLqE6TFhw7uI/jhw+wYdlC2tz2fwV7AfkQk5BMmIuHI02V9EHlo2Zso3n1CCY914qKEUEcPFnwf9By4lxCMmGBrprI0PTBb5tpXrMEv7zSlkolgjlwonA0eRPn4hIp6tKV5npP3/1hGS3rlmPa/7pSqXQY+/8+R0paGiu3HeN0zHnOJ6WwdPNhqpYJd4u22MQUQl28Luqi7ekbqjJ+yX7uHL2M137exBu3XwXAwF+30POr1Qz4ZTOvdqrpFl3pWG2X6TlIS3Npu28X07JeBaa9dx+VShdl/7GzGeUe6NiAiX+4f3aMc3FJFHXxumTR9+NqWtYpzbS3bqNSqTD2H7d+f3qNnEvH16by2Mg5jOjVyn3a4rNpc/3e/biGlrVLM+2tW6lUMpT9f8dQrUwYtzevzEe/XUwkQOHi7nlgRKQVUNIetPI41uCYdO4A9tuDV34hMxY1V4wBY8gRVR2jqk1VtWmn/3vwoo+rUrs+65bOA+Dowb2EF4/MyKtUsy6bV1uBdLs2raFMpaqsWjQL1TS+HjGIPyaNZ+PKJaxf5v5g1GU7T3Jr47IA1CgdwtEzmW/ucYkpPPPVKu7+YBGhAb78tOyA2/UARG0/QedmFQCoWSaUI6cz34hjz6fQZ8wy7hw2j9BAXyYt2VsomryJJZsO0eU6y/lZq0JxDp+MzciLTUim1/A/uPXVnwgL9OO72VvYeegMV1UsTpC/Lw6H0Lh6SXYeOuMWbWv2n+XG2lb3QZXIIP4+l+lpKx0ewKlYyztzOi6JkmGWIeF0WH8MYhNTSUlz75RNSzYcoEtry3CqVTGCwyczX0JiE5LoNew3bn3pW8KC/fhu1saMvFtb1uCPZRfTo32Z+jYfoUvLqpa+8kU5fCrbvR05l1tf/52wwCJ8N287kNl+5+KTSE5NdaO2o3RpUSVTm8sLT2xCMr1GzePW16cRFlSE7+bv4O7W1XGIMOHFG3jtnqbc0qwStzev7DZ9l4JDLv+TDx2A7yEjfMPV/XQCKGpvR5A58CRXzFIChgKlTpMWbFm9jJGvPYV/QCB3P/kSUyd8wi33Pkarm7rw7UdDWbd0Hv6BwdzX51WCQsMyjt25aQ1b1yynQfPWbtc5e+NRbqhXiikvtyHufDIvTVzDgLvqMWzKJppVj6Bf57qIwIw1h1m2070Bnun8te4wNzYow/QBNxB7PoXnx63gjbsbMvSnDTSvGUn/rvURhGmrDhK1Pd9n+z/HzBV76NisCrOH30NMfBJ9P5zF4J7X8+bXi2lRpyyDelyHIExdspMlmw4BMOy7Zcwc9n+kpKbxxYz1HHfpRilIFu44SavqEYzv2YS4xFTe+m0rz95YjdFzd/PxnN30v60WIuDjcDDiL8sg+LB7A/x9nTgd8OFs945AmrlsJx2vqcbsUQ8RE59I3xEzGNyrPW+Om0eLehUY9EgbRISpi7axZINl0BcN8ScpJZXEZPcZBxn6Vu2nY9OKzH7nDmISkun78QIGP9ScN79dQYvapRl0/zWIwNSle1iy2Zqx46eBnQj088HpEN5w4yifDG3/u4OYhCT6fpJN233NLG1Re1my+WiGPoBWdcvQoXF5flt2ZbyQFMQ8MCLSi8ypSMCatmOMvV2CrIZJiog4VDUNa563gSKyGWtOthb5nstMxupZRKQ6listgRz6BV3KPWyXS8Wac2aOiJQAPgdKAgdU9R57tNcIrInx9gI9VDVFRN4FmmIN034FmAeMA15zmaMnR/7ccuKK/ZI89IHnhg5fDEnn3R9E+E9J2LTU0xLypkQlTyvIk+rXNPS0hDzZuch9w4Yvm+DinlaQN1f4aJyE3550i8BbPl9x2b/10x9vlqs2++/Q76q6yN5faM+/hoi8B8xT1Rki0hB4RVXvzetcpgvJ8/QDfif3fkFEpA7QCmsSu5aqOsfOGgYMVNUWLkHLe4AO9qR357Hm1AF4257UrgvQz15GYCjwlhuvzWAwGAyGdBYBXQHs2eoPueRVBI7Z28eB8vlVZrqQPIg9N4sCN+DSL2ivoeRKT2A/MFdEjmMNzU7FGl49QETKYrnpJqbPMWMv4VAMy6BBVdM7tWsAG+y0nSJSQUT8cltmwWAwGAz/DQS3e56mA51EZBHWSKPHRWQY1nxoA4FPXOZZeym/yowB41lqAJuAq8i9XxCs2Yf/UNU29vpQb2ANo66BNXlePDBbRGbbE+J9hzXk+3PgbwCxVq4ehjUD8i0u59qGtV7SlRcSbzAYDIZC4yKCcC8L+29a9qnWX7H/3461duFFY7qQPEsglvERTWb0NUCai/EC1uy5M+zt6UBtO225qp6yZyRejLX2EqraHSiDZcU+ZKfNUtXGWFHgrksRxGEZNQaDwWD4D+PuYdQFjTFgPMsxLEMjr35BsJZQ6GRvt8HyluwA6ohIsIg4sQJ0d4hIGGRYuoeBYBHxcVlK4CTgdKm7DOCeGZ4MBoPB4DWYmXgNF42q7hGRWliBtFn6BQFc+gY/Ab6yF56MBh5R1QQRGQzMwfLGfK6qf9sT0D0EJGGNQnoSa22m3+2+RcVazRt7v3z6Ok0Gg8FgMHgLxoDxPFFAK1W9YAlmVU3vG0wi68KX6flTgCnZ0sZgrYPkSiIXLoMAcD8uSxIYDAaD4b+LWczRcKl8hDW5jydITl+t2mAwGAz/bUwXkuGSsGNVLliYspDO/b0nzmswGAyGK4/CDsK9XIwHxmAwGAwGg9dhPDAGg8FgMBiu9BUULsAYMAaDwWAwGLwuiNcYMAaDwWAwGNy/kEABYwwYQ76UDw/Mv5CH8PG9sr/CaWlp+RfyECGNryfm0AFPy8id4/s8rSBP/PyaelpCnviUqOBpCbmSkpTsaQl5kxTvaQUewQTxGgwGr+CKNl4MBoMhH67s11eDwWAwGAyFgrsXcyxojAFjMBgMBoPB67qQjAFjMBgMBoPBDKM2GAwGg8HgfXibB8YE8RoMBoPBYPA6jAfGYDAYDAaDCeI1GAwGg8HgfXhbF5IxYAwGg8FgMHjdTLwmBsZgMBgMBoPXka8BIyLFROQLEVkqIovsT+l/cjIRmS8i/iLSUETu/wfHh4lIQ5f9HXadK0XkrX+iKZfzVBWRcvb2P9JqH+sjIoNEZLmILLTb0N9Ou+ky9AWIyNv2dpCIzBaRP0Wko4jc+E/rNRgMBsN/F4fIZX8Kkzy7kETEF/gNGKCq8+00vxzKiarqxZ5UVdcB6y5FqE0j4CaXY0+rahtbwyIRKaaqp/9Bvdl5AFgGHLoMrQAfAbuA5qqqdnumXK44VU0ABtq7jYGtqtr3cus1GAwGw38XLwuByTcG5g5gdrrxAqCqiQAiUgn4FEgE5onIEuB/QCCwXVUfEREf4HOgGnAUCLWPbQPcpKr9RORa+zgH8JeqDhaRHkAzoDxQFXgdiAJGAsVEpIyqPpiuSUTCgGTgnL0/EOgAOIEVqvpsbukiUg0Ya7fFAvs8PYA7RaQ2sMZF63xgJpYRFQDcpqonRORu4AXgFHDcruMXoJaqPunSdsm2jowGFpFRQH27bZ5U1RUi8qmd5gCuB24G+gFpwHBV/VVEltn35yO7TZKAjYC/qn4mIrcDL9l1fKGqX4nIIKA40BC4X1X3YzAYDAYD/74g3qrABrC6krD+KIcDzwD7gZpAbVU9LyLFgY6AArNFpCzWH949qtrTNjK2ulYuVmu9D9ysqudE5AcRqWhnh6vqbSJSAvhdVa8RkWexjQm7TDHbqKiBZYSk2l0olYDrba/HxyJyG3A+l/QqwDeq+qWIOFQ1TUSuBpap6h+2seXKOlUdJiLPA/eIyETgWaC1qiaIyMd2uSrApnzaF2CwbQS1Bh4TkZ12m7ZM92yJyMPAA6q6W0Qyuv1U9Zhrm9iGHyISbmtqh+XxmS0i39uHxahqq4vQZTAYDIb/EF5mv+RrwOzD8p5gd820sd/iA+z8Nap63t6+BstgiQWKASFY3Rtj7eOj7T/OrkRiGR+/2ZZfOFDOzltkH3c8D6vwtKq2sQ2hwcC9QFlgukuX1myglr2dU/rHwPMiMsLWmsXIyoGF9v9bsbxE1bG8OQl2+mqgCHAAywDMFREJAF4TkUQgCAhR1TMiMlxERmN5cr7FMkb6iEgCMAI4m4/GGrauWfZ+BFDS3l6az7GXzXfjPmHz+jWkpaby5AsDqFDZaoa9u7bz9it9KVPeslEff/ZVyleqwsa1K5nw+ShEHHTq8n+06XCr27S9eOtVNK9eHKdDeOW7dew4GgOAr1N4//7GlCseQNz5FHqPW0XM+RRua1KWHq0r4+/rZNy8Pfy84qDbtGXnlTvqcm2NCHwcDl6YsIrtR84BEBrgywc9mlI8xI/Y8yn0/mI50fHJhaLp9Qdbcl29cvg4HfQe9Rdb958CICzIj0+f60hEWAAxCUn0fHcGZ2MTiQwLZPQzN1KiaCAHj8fw4P+mFYrO7EQUDaZP97akaRpvfTLdIxqeaF2JRuXDcTqEoTO2s+dkPAA+DmHgrTUpHeZPfFIq/adsIS4xNeO4Z2+oSkqqMnreHrfqG/B/DWl5VUl8nA76joli26GzAIQF+jL68RZEhPoTm5DMYx8v5mxcEm/f14RGVYoTHODL69+uZuHmY27T9vq9TbiuTil8HA56f7qIrQfTtRXh096tiAjzJyYhmZ4j53M2LinjuGEPX0NSShoDJ650mzaA1+9vznV1y+LjFHp/NJetB6xIhrCgInz69A2Zz8Xwvzgbm8jkAbdQIjyQxORUVu34m/5fLXGrvn8r+QXxTgO6ikh9lzSny7ZrPMcbwHNYsRnpRsJ+4DoAEYkE6mar/ySwDehgx7K0UNX0O+kaU5O+nQpcEINjGyWnsIyAzVhdPOm0A9bmka6qOtjW/UVe58mmRbFGnR0GrrbjWwDa2pqOACkicm/6gXbwrWubdwKO2x6l+XYZX2CGqvYBOopIPbvMS3aZgeTPXizPWVu7XZu5dBdddgxOXmzZsIazp08xZNQXPPFCf77+fGSW/Gtbt2fwyLEMHjmW8pWqADBhzIcMev9Thn70JVMnTeQSwqkuiWZVixMZ6kfXDxbT77t1DOhSJyOvY4PSHDodz10jFjNz3VHubVmJsABfHrq+MveMWsJdIxbzaLuqBPsXzswD11SPIDLUjzvenc+LE1fxRrcGGXlPd6rFL8sPcMe785m59jBP3FijUDS1rFuWEkUD6fDSJPqMmsXQR1tn5L14dzMmzdtKh5cm8fvSXfS9sykAgx+9nje/XkLb5773mPEC8M7zXUhMTsbXx5l/YTfQsHwYxYKK8Pg36/jfzB083T7z3aZNzQiORifSa+I65m0/yR0NM8dIlAz145rKRd2ur0WtEpQIC+DmN//k6bFRDL6/SUbe853r8eOSvdz85p9MW3WQ3p1qAzDs5/Xc+vZfdH9/Hs93ruc2bS2vKkmJ8AA6DJhOn88WM/ShazLyXryrAZMW7abDgOn8vnw/fW/P/BNTPiKIdg3Kuk1Xhr46Zaznot/P9Bk9l6GPXJepr1tTJi3YTod+P/N71B763tEwI+/ON3+n46u/XFHGi7cF8eZpwKhqLHA38IY9imYWUBvYkkPxX7HiRcZj/VEH+Ay4WUQWA+9lP05V04B3gfS6R+ajdyPQXkTG2fvF7FFIC7BiRr5W1RnACRGJsruX/lbV2bmlA91FJArLWJto1zsXeE9EeuejJ91Q+RlYISIzgASs7iqwgoHb2AHG84DJZPV6LcMyEP8E0v9CFQeWiMhcwB/YCYwQkYVYxsvPF6HpBDAFiBKRv4BX8zumoFi3ahmt2lt2YsXK1Yg9F50lPyg49IJjQkJCiY+L5XxCAv4BgW7rh73+qhJMXXUIgO1HYwgPKpKRdzo2ibBAywYtFlyEU7GJVCoRxOZD0SSnKueTU1mz7zTVS4W4RVt22tQpxa/LDwCw7fC5LFqvKhfG4m3HAfhz3REaVi5WKJraN67E5PnbANiy/yTFQvwz8upUimTBekvv9KjdNKlRivBgP4qF+NOve3NmD7+He9vXLhSdOfHowIksXr3bY+dvXqUof2627tnuE3GEBvhm5J2JTybUNozDA3w54+JN692mChOi3O/1a1e/DD8u3QvA1oNnKRac+f5Wp0LRDO/K9FUHaVy1OACx5613oWqlQ9l84IzbtLVvWI7Ji6x7t+XAmQu0Ldh4xNK2cj9NqkVm5L15/9UM/3WD23Rl6GtUgckLdlj69p/O9lwUZ8EG6zdn+vI9NKluOcLTVDkbl+h2bZeKyOV/CpN8XydVdS9wVy7Z97iUewd4J4cynXJIm29/UNXfgd+znXN8tv3m9v9nsQyV9PQcXz1Vtf/Fpqvql8CX2dKWYHXDuOolfcSTvf0H8Ie9+6GqDre9Kz9hj1pS1Wjg8RykDHLZbpJD/jXZ9p/MXsClTea76Bvvkj8Wu/vOJc31vG4h+sxpQsMz3xgdTh/S0tJwOBw4nE6WL57HpnUrqVL9Kh564ll8fX25vdv9vPjE/fj4+HBvjwsutcCICCnCqZjMH42UVEUEVGHFrlM8c3NN5gxoh6rS+f1F+DqFJpWLEezvQ5oqjSoV49cVh9ymz5XIED9OxWZqTU1Ly9C65WA0tzQux3eL99LqqhL4FNL835HhgZw8m5Cxn5KaqWnT3hN0blmdr//cRNtGFfBxCpVLhVO9XFHaPfc98YkpzHinG/PW7ufY6bhC0XslUTSwCGddDJPUNEWw3LjrDkbT87qKTOp1NWmq9Px6LQC3NyjF1mMx/H0ukaqRQW7VFxnmz8lz5zP2s9zbA2e4vVkFJszbRZu6pfFxWu+9beuV5q37mhDk50PXd+YUnjaXZ2HT/tN0bl6Jr+fsoG29Mvg4LG0Pta/B2t0nOXwyjjoV3OvBigwP4GR0fKa+LM/FKTq3qMrXf22hbcPyGW13Lj6JmUO6kJyaxjs/rGTxpsO5VV+oeFsQr5nIrmD42vawLAaW2kOvvRoR6SUiq0Rk1eRvxuV/gE1gUDBxMecy9h0OwWH/qFSsXI1R4yYzZNSXBIeEMGvaL5w9c5ppP3/PmB+mM+aH6Wxcu5J9u3cU+PUAxJxPISww05ORpkp6b1W/zrX5fPYu2g+ey9Nfr2FY94acjU9m1MztjH+yOe92b8TBk3EcOhWfS+0Fy7mE5GxaydA6csZWmteI4Mfnr6diZDAHCktTXCJFQzLffl3b790fltGybjmm/a8rlUqHsf/vc6SkpbFy2zFOx5znfFIKSzcfpmqZ8ELReqURm5hCiEv3Y5pqRl907zaV+WbZQe4es5I3ftvGa51qUKFYAG1qRvJ9IRnM5+KTKRqU8/ft/V830KJWSab2v5FKJYM5cCIWgHkbj9Kq3zQ6D5nFF33dNy7gAm1pLt+7n9bTsnYppr1xM5VKhbL/RAzVyoRye/NKfPT7xYyhKAB9cUkUDc70umR5LiavpGWdMkwbfIel72/rt7HXB7Pp+OovPDZiFiOeaJ1TtR7BUQCfwtZruExUtbuqtlXVFqr6vqf1FASqOkZVm6pq0/+7/5GLPq52/UYsXWC9jR3ct4fiESUz8lJTLZeziBAUHIKIEBN9FofTiZ+fP06nD0EhIZw6cbxgL8Zm+a5T3NK4DADVS4VwzMWbULZYIMftt7xTMYmUKWrFqc/aeIyuHyxm6JTNpCkciz5/YcVuYNnOE9zW1Ipnr1E6lCOnM42UuPMpPD1uJd1GLCQ0wJcfo/YViqYlmw7R5TrLMVmrQnEOn4zNyItNSKbX8D+49dWfCAv047vZW9h56AxXVSxOkL8vDofQuHpJdh5yX1fDlcy6g9G0r2V1b1SOCOT4uUzvWqkwf07Zgaen45IoGepPxzolcQgMuaM2j7aqSKvqxWlTM8Jt+pZu/ZvO11jB9TXLhnH4VKaXLPZ8Ck98uoTOQ2YRFliEHxbtwekQAopY8USnYhJxutELuGTLMbq0qAxArXLh2bQl0+ujhdz65kzCAovw3fxd3N2qGg4RJjzfltfubsQtV1fg9msq5lb95evbfIQuLatZ+soXu/C5+GA2tw6YYj0Xc60u2PT2OhefRHJqmtu0/dsxayEZCpQmzVuxevkSXnv6EQICg3jy+f5M+HwU9z7yFKuWLuS3n77F4XBQolQZnnphAL5FilCtZm369emBIFSqVoNGzVq4RducTcdoV6ckPz9/HXHnU3jl+/W8dkdt3vt9K+/9vpWh9zTA4QAfh4PBv1pvb6MfbkKZooHEJabQ/4f1btGVE7M2HOWGeqX57ZW2xJ5P4cUJqxjYtT7v/LqJa6pH8GqXuojA9NWHWbbjZKFomrliDx2bVWH28HuIiU+i74ezGNzzet78ejEt6pRlUI/rEISpS3ayZJPlORj23TJmDvs/UlLT+GLGeo6fLRxv0ZXG4p2naFG1GGMeaEh8Uir/m7GDPm2r8NmCvXy+YC+v3FQDEfBxOvhwzm42Hs70YjauEE6LqsWYv9199/mPtYfo0Kgcfw66iZjzyTwzNoq3ujfm7UnruLZWCV6/uxEi8NuKAyzZ+jeBfj5MfrkdDhEUZdD3a9ymbebqA3RsUp7ZQ24lJiGZvp8uZvADV/Pm96tpcVVJBnVvighMXbaPJVuOsWRL5mioVnVK06FxOX5b7r4pr2au3EvHphWZPewuS9/ouQx+uAVvTlxGi9plGPTgtQgwdelulmy24nV+ev02Av18cDqEN752+8DQi8bbupDEXSM+DBeHiFTHipNJwJq0zgfopaqbs5V72C6XCryuqnPsOXI+xxoifUBV77FHjL2PNdT9KNaEdUki0hYrYDoNGA18A4wDXlPVo3lp3HIk7or9knQYPCv/Qh4kKTEp/0IeIubQAU9LyJvj+zytIE/qdu3qaQl5sm3DlTtPZUpS4Qz7/8ckXdmGdsL0p91iaTw7ddtl/9aP7Fyr0Kwg04XkefphBTGXVNXWWEbKe64FRKQO0AprmHlLVU2PmBsGDLS7rtIDqhVrhuBWWMPYO7uUvQFrWPuLdtpQoMDWkDIYDAaD9+KQy/8Uqt7CPZ3BFREJxDI4bgC+B1DVTVgTAbrSE8sYmSsik0UkQkSKYg25HmAP037APn5j+nIPwBkgvcP4NBAGBAOxarETqJDT+lYGg8FgMFzJGAPGs9TAWm6gBHDCJT0l24R31YGT9jDuyViTBlaxj++Ntb7TE+KySriItATqAH/aSSOAVfb5XIcVbcNaEsJgMBgM/2FE5LI/hYkxYDxLIBAPRAOukxWk2ZP8pZMCzLC3p2NNJpgCLFfVU/YyBouBamLRD2um4QdVNdWOlXkGqGh/2rnMrhyHNYOxwWAwGP7DmC4kw6VwDCiDte5TVwCxVsDOPvlDFJkTArbBWiZgB1BHRIJFxAk0tdOeAI6q6tuqmr6gSgSQoqoJqpqC1bWUvuZUGeCIG67NYDAYDF7Ev24mXoP7UNU9IlILK5C2k4gsAmKwZ+8VkWFYywd8AnwlIt2wvDWP2CtfDwbmYHljPlfVv+0VtsPtUUsAv6nqCHtSuqXYk38Cf9jdVOVd1kkyGAwGw3+Uwl7L6HIxBozniQJaqWpOywW8Ym8mAd1yyJ+CteaRa1pOSzegqm8Db7umiciDWGtXGQwGg8HgVZguJM/zEVYQrydIVtWJ+RczGAwGw78db1tKwHhgPIwdrPujh879vSfOazAYDIYrDy/rQTIGjMFgMBgMBhMDYzAYDAaDwQvxMvvFxMAYDAaDwWDwPowHxmAwGAwGQ6FPRHe5GAPGYDAYDAaDiYEx/PuoUuLKXWng5jbVPC0hTxxX8CtN1Ibsa4ZeWfj5NfW0hDzZ9NNPnpaQJ+2feMjTEnIlPjHF0xLyxHkFP7fuxMvsFxMDYzAYDAaDwfswHhiDwWAwGAwmBsZgMBgMBoP3IXiXBWMMGIPBYDAYDMYDYzAYDAaDwfvwNgPGBPEaDAaDwWDwOowHxmAwGAwGA+Jl46iNAWMwGAwGg8HrupCMAWMwGAwGg6FQJrITkbeB67Hsj16qutlO/wJIn5k0FNinqnfmVZcxYAwGg8FgMLh9KQERaQWUVNXWIlIXeA/oBKCqj7qU+xCYmF99HgviFZFzIjLf/swWkVv+QR2DRcQ/l7z3/0F91Ww9y0TkuL09/FLrcanPR0QGichyEVkoIktFxN9Ou+ky6g2wrVhEJMhuvz9FpKOI3PhP6zUYDAaDwY10AL4HUNVNwAXrmYhIJSwjZ2V+lXnSA7NFVdsAiEhJ4AcROauqSy62AlUdkEfei5cqSFV3AW3sBnxHVe9xzRcRUVW9hCo/AnYBzVVVRcQXuOxFQFQ1ARho7zYGtqpq38ut12AwGAz/XQohBqYEcMJlP0VEHKqa5pL2HDDyYiq7IoZRq+rfwIvAQwAicruILBKRJSLysJ1WXEQmi8g8EZljp823PRrNRWSxfUxvO2+Z/X+IiHxjH7dcRB6w03uIyCci8ruIbBGRrjlpE5FKIjJTRKYAT4tITRH5y67vE7uMU0Q+FZG5IjJHRCqLSAmglqoOTzd6VDU5uwEkIqPsulaLSDM77VP72qNExNduj6X2NXZJvz4RKYVlJHUWkeH2NT2RRxsOEpGP7PSKBXT7DAaDwfAvQKQgPtJLRFa5fHq5nCIaKOqyn+ZqvNg9Kg1VNepi9F5JMTD7gAoiEg48C7TD8lbMFpHvsfrKvlLVmSKS3fC6G3hDVefkkNcP+EtVJ4iIHzBfRGbaeeGqepttbPwO5La8bE2gtqqeF5E/gEdU9ZCIvGv36dUEtqvqkyJSGxgAjAU2XcR1D1bVEyLSGnhMRHba52qZ7vGxDZAHVHW36/Wp6jEReRa4SVX7iUgPgDzaECBGVVtdhK5/zOgPR7Jm9SpSU1IY+ObbVKtWPUv+qZMn6dSxPQuXrsDPz48Vy5fx6ccfkZSURPsbbuSRR3vlUvPl07luCapHBOF0wMRVRzhyLhGAB5uWoUSwHwD+vg5OxSXx6dKDhPg5eaBJWUL8fTgdn8TYZYfcpg3g9jolqB4RiEOEb9Yc4ait74EmZYgMLgJAgI+DU/HJfBZ1kCevLU+ovw/Jacq+0wn8svFvt+rr3a4KTSoVxekQ3pq6ld0n4gDwcQpvdq5N2aL+xCWm8sqPG4lNTGXkvfUpHlyEpBRl0+FoPvhrl9u0PdG6Eo3Kh+N0CENnbGfPyXhLm0MYeGtNSof5E5+USv8pW4hLTM047tkbqpKSqoyet8dt2vIjomgwfbq3JU3TeOuT6R7Tkc79TctSp3QwTocweuE+Dpw5D1ht+XTrSpQM8SMhOZV35+whPik1n9oKhoebl6d+2VCcAiPm7mHf6YQMTS/dUDVD0+A/dhKXlIqvU7ihZiTXVS1K/9+3u1XbQ9eUo36ZUJwO4YN5e9jvou2FdlUoGepHQlIqQ/7aRbytrX2NCFpUKcbr092r7VJwFMBSAqo6BhiTS/YioCuwyP5bmf0H9WZg9sWe60oyYOphdbfUAKoDs+z0CKAkcJWqzgTI5m4CGAw8LyIdgA+Bwy55DYHh9nGJIrICqGznLbLTj0vewUtrVPW8vd0I+MYuHwysxurGuVpE7rDLnAAOAFXzqlREAoDXRCQRCAJCVPWM7U0ZDUQB32IZI31EJAEYAZzNq15yb0OApfkce1msWb2K06dOMe7rb9i5cwcfvP8uH382NkuZcV+MITzcMsJVlZEj3mfMl+MJCAigV88e3NjhJspXqFDg2qpHBBLq58P78/dSJtSPrg1K8eGi/QBMWHUko9w9jUqzbN9ZAO6qX4opm/7OMHTcSbWIQEL9nAxfsI8yoX7cVa8ko5ccAGDi6kx9dzcoxbIDZzP2Ry85QFwh/BFpXDGc4sFFeGTcaqqVCOL5jtXp/c06ANrViuRo9Hn6/7KZOxuX4c4mZZmw1NLe55v1RCcku1Vbw/JhFAsqwuPfrKNqZBBPt6/Ks5M2AtCmZgRHoxN547dtdG5Ymjsalubb5dbvZslQP66pXJQlu067VV9+vPN8F3YfPEGgfxGP6gCoUyqY8EAfXv19OxWLBvBI8/IMmrkTgOaVwjkem8SIeXvpUCuCjrUi+HWDe41mgHplQiga6MtzP2+mUrEAHr+uIq/+tg2AllWL8fe5RP731y461SlBpzol+HHtUe5uXIbT8cmEBfi6VVvd0pa2F37dQqViAfRqUYH+0yyjpEWVovwdk8iw2bu5uXYknWqX4Kd1R+nWqAxn4pMID7iS/gQXCtOBTiKyCIgBHheRYcBAVU0C2gBTL7ayK6ILSUSqAm8DHwB7gQ1AWztGppmq7geOikgLu3z2b2S8qvYHPscyYFzZDNxkH1cEaADstPNcu3Pyim1xjVvZCNxha2uJ5bXZAXyoqm3s9IdU9QhW/969LtcZkM1D1Ak4rqr9gPku1zZDVfsAHUWknl3mJbvMQPIntzbMfi0FztIli7mpkxWPXb16DaKjo7Pkb92yGUQoV748AGfOnCEyMpLg4GCcTifXtbqezZsvxnF16dQuFcyKA5aeI+cSCSrivKBM8UBfQv182HcmgUBfB0FFnNxSO5KX21amecVwt+jK0FcymBUHL0Kfvw/77TdihUJ7A762ajFm2h6eXcfjsvxhOBOfTKi/9WMcHuTLmTjLYElTiDnvXuMFoHmVovy5+TgAu0/EEZqbtgBfzsRn6undpgoTog66XV9+PDpwIotX7/a0DAAalQtjgW3Q7T+TQLBf5h/Z6PMpBPtZ38tQfx+iE9z6c5JB0wrhzN1xEoB9pxMI8XfRlJBMsL0f5u/DWdtY/mblYWbY3wl30qRCGPN2nMpFWwohdvuF+vtmaPtu1WFmbjlxYWUepiC6kPJCVdNU9UlVbaWqnVT1oKq+YhsvqOozqjr3YvV60oCpbcd+zMYyXnqo6m5VPQFMAaJE5C/gVbv888AgEVkA/JCtrhdFZDEwjguHXg0FutjH/QW8r6pnL0P3AGCaHYfzNVAEy112q4gsEJEZwDV22QewgoIXicg8YDJZvV7LgK4i8ieWYQVQHFgiInMBfyxja4SILMQyXn7OT2Aebeh2Tp8+TdFimYHlTqeTtDTLYRYfH8/ID4bzZO/MeOPw8HCOHj3KiRPHSU5OZvXqVaSmuudHMcTPh5jEzLpT0/QCh+kNNYoze6f1QxkRXISSIX58t+YoHyzcR+uqRQnzd98bU4ifk1iXro00vVBf++rFmbPzVMZ+QnIqz7WuxDOtKlI9ItBt2gCKBRXhTFxSxn5Kmmb8YK3df5YqkUH80qc5t9QvzZyt1h+OuMQUxvZowucPNaJJpXC3aSsaWISzLoaJ671ddzCaShGBTOp1NTfVLcH87db9vb1BKbYei+HvQvCueRNhAT6cS8j5OdlyLJby4QF83K0ubaoVJ2rfmULRFB7gm+v93XgkhopFAxh3XwPa14xk8e7C9aaFB/hm8TC6att0NIbyxQIYe2992teMYMkez3r68sMhl/8pTDzmv1LV0DzyxmLFkLim7cMaguWa1sbefNv+uOY1t/8/C3TL4Rzjcyrvcq57sm/b+8uA63KQfXcO54gGHs+h7CCX7SY55F+Tbf/JHOpOv7752N4b12vKpQ1dz5snduBVL4DRn3xOz8cuLi4lJDiYmHPnMvYdDgcOh2Unv//uOzzS8zGCg4Oz5Pcf+Ab9XnqBkNBQIiIiKFOm7MXKvCQSklOzeDWUrG43H4dQPjyASeuOAZCWBntPx2d0z+w6GU+J4CJEn3ePgZWQnEagqz7NSZ8/k9cfy0j72u76CvP34enrKvL2bPe9xccmpmTxbKgq6SHpT99QlfFL9rN45ylqlgrmjduv4pWfNjHw1y0ARIYU4dMHGtH1k+Vu0+b65pummtF2vdtU5ptlB1m6+zQ1SgbzWqcajFm4jzY1I3l+8kYaVwh3iyZvJT4pNcPLAlmfkwebleXX9cdYdTCaysUD6HN9Jd6b4/7YobikrPfX9dl49NoKTF5zhOX7z1I1IpAX2lVl8J87c67ILdpSs3ip0ly0PdK8PD+tPcoKW9tzbasw1I1xYJeLu+eBKWiuiC4kw5WHqo5R1aaq2vRijReARk2aMuuvPwDYvWsXJUuWAuDUqVNs3bKJn3+azMsvPsfu3bsY2L8fAA0aNuLL8RN5860hnDx5kgYNGxX8BQE7T8TTuJxlN5cO9cvSlQBQr3QwW4/HZuz/HZtImVB//HwciEDFogEci3Hf2/quk3E0LmvrC/HjTLa4kbqlgtl6PC5LWvobz/nkNFIvaYT/pbNm/1lurF0CgCqRQVk8F6XDAzgVa3lnTsclUTLMmp7JaQuMTUwlJc19+tYdjKZ9rUgAKkcEctxFW6kwf07FuWgL9adjnZI4BIbcUZtHW1WkVfXitKkZ4TZ93sTmYzG0rGJ5UcuH+3MyNtPrViI483sZnZBCRFDhxOxsPBLD9dWKA1CxWAAnXDSVDC3CaftZPpuQTGRI4cYRbTpyjuurWe1VoWgAJ128lCVD/Dgdn5SpLdjzMU554e4upILmPxdBZHAv17duw+JFC+jxQHeCgoIY+MZbfDD8Pfr0fYbvJ/+SUa5njwd4e8g7gOWZ2bhhPT4+Przw0isZHpuCZuPRGOqVDubltpU5n5LGxFVHuKt+SaZsOk5qmlIjMoj1R2IyyienKtO3HOf51pVIU2Xh7jPEJLov3mTj0VjqlgrhxTaVOJ+cxrdrjnBnvZJM3XScVL1QH8BTLSpQxMeBQ2DKJvcGUy7ccZJW1SMY37MJcYmpvPXbVp69sRqj5+7m4zm76X9bLUTAx+FgxF/WG/CH3Rvg7+vE6YAPZ7vvzXPxzlO0qFqMMQ80JD4plf/N2EGftlX4bMFePl+wl1duqmFpczr4cM5uNh7O9BI2rhBOi6rFMrqW/uus3B9N0/LhDLu9FgnJqYxeuJ8e15Tjm5WH+WblYZ5qVRHBMk6/Wl448UPL9p7hmorhjLyrDgnJqYyYu4fHWlTgq2UH+SrqIM+0rWJ/94TPF+/Pv8ICZPm+szSrWJQRd9YmISmVkfP38ui1FRi//CDjlx/k6daVM7SNsQPbDQWDXNq8bIaCRkSqY3UzJZDD+hAu5R62y6UCr9tDxodhdTcFAwNU9Q/JZT0Jex6bkkAisAJ4BStm6DVVPZqXxvMpeQY4e5S+v7gn4LegcFzBq6NFbcjztnscP78r+/1q00+5zbpwZdD+iYc8LSFX4hMLJ/j3n+K8gp9bgFl9mrtF4JcrDlz2b33PZhUKrfGu7F+I/wb9gAnAfTmtDwEgInWAVkCLbEPIf1TVV0QkEpgJ/JHPehK3quopl/yhwFvAY264LoPBYDB4EV4WAmNiYDyJiARixXvdQN7rQ/QE9gNzxZqNOMIuu8rOP0e2uWHkwvUk0rKXUdWdWJMH+hXMFRkMBoPBW3EUwKew9Ro8Rw2s2XpzXB/CZb86cNIedTUZeCM9wzY+PsQaLu5K9vUkzgFzRGSWPetvOtuwZhI2GAwGg8FrMF1IniUQiCef9SGwJp+bYW9Pxx5WLSI1gNeBd1V1Q3phl/UknklPU9Uedl4Z4A+gvp0VhzULsMFgMBj+w+QzI/0Vh/HAeJZjQBky14cgl/UhosiMiWkDbLCXIRiBFfC7IVv5C9aTEJF0Y/Uc4Do+twxwBIPBYDD8p5EC+BQmxgPjQVR1j4jUwgqkzbI+BED6GhHAJ8BXItINy1vzCNbaUY2BGS5W852qepqc15P4zY65cQKv2fU7gPIuywwYDAaD4T+Kt01kZwwYzxMFtFLVnGbbfcXeTOLC2YRPYXlPLsC168glrVMORe8Hxl+KWIPBYDD8O/Eu88V0IV0JfIQVxOsJklU1+9pRBoPBYDBc8RgPjIexg3V/9NC5v/fEeQ0Gg8Fw5eFlPUjGgDEYDAaDweB9o5CMAWMwGAwGg8HrYkqMAWMwGAwGg8HrPDDeZnAZDAaDwWAwGA+MwWAwGAwG7xtGbQwYQ74s3Hki/0Ie4sep6zwtIU8SY+M8LSF3zh33tII88SlRwdMS8qT9Ew95WkKezPnsa09LyJ3ydTytIG8cTk8ryJs+zd1Srbd1IRkDxmAwGAwGg9fFlHibXoPBYDAYDAbjgTEYDAaDwWC6kAwGg8FgMHgh3mW+GAPGYDAYDAYDZikBg8FgMBgMXojDy3wwJojXYDAYDAaD12E8MAaDwWAwGEwXksFgMBgMBu9DvKwLyRgwBoPBYDAYvM4D4zUxMCJyTkTm25+X8ijX5hLq7GPXt09ENtjbNxaEXrt+HxEZJCLLRWShiCwVEX877abLqDdARN62t4NEZLaI/CkiHQtSv8FgMBj+OziQy/4UJt7kgdmiqm0uotw7QJaFIkREVFWzF1TV0cBoERkELFPVPwpCqAsfAbuA5qqqIuILpFxupaqaAAy0dxsDW1W17+XWazAYDAaDt+A1HpjsiMg1IjLB3n5cRPqKyI9AbduTUsz+fxAw3S73g4jME5FlIlIll3oHichHIrJIRCqKSC97e4mI3GyXqSkif9l1fWKnNReRxXbZ3iJSAqilqsPTjSdVTc5uSInIKLue1SLSzE771D5flIj4isjttvdmsYh0scssE5FSWEZSZxEZLiI9ROQJO/92F90P53RtBXtHDAaDweDNiFz+pzDxJg9MbRGZb2+PUNXfRKSbiHQGOgBdVfUjEVmW7qmxp0VeqqqD7OP6quoJEXkIuBcYksu5YlS1lYjUtOu+HvAF/gJmAqOAR1T1kIi8KyKtgDuBN1R1jog4gGbApou4rsG2ptbAYyKyE6itqi3TPUe2AfKAqu626wZAVY+JyLPATaraT0R62NcdDjwLtMPy+MwWke9dr+0idP1jpn07lt1b1pOamsq9T71E6QqZtuKyOdNZ8udUxOHklnt7UrNB04y8X8Z9hNPHh84PPuk2bf27NqBFrRI4ncKzXyxn2+FoAMICffnwseZEhPgTcz6Zxz9ZSnR8EoPuaUTTqhEE+fsw+Md1zNlw1G3aAF7v3pTr6pTGx+mg98cL2XrwjKUvqAif9mlNRKg/MQnJ9PxgLmfjkjKOG/bItSSlpDJwwgr36nu4Ddc1qGDpGz6drftO2Pr8+PSl24gIDyQmPpGeQ6dSu1Ikb/Rsk3Fs3Sol6fjcBDbtcd8q2AP+ryEtryqJj9NB3zFRbDt01tIX6Mvox1sQEepPbEIyj328mLNxSbx9XxMaVSlOcIAvr3+7moWbj7lNmyv3Ny1LndLBOB3C6IX7OHDmPAA+DuHp1pUoGeJHQnIq787ZQ3xSaqFoyo2IosH06d6WNE3jrU+me0TD6/ddzXV1yuDjFHqPXpDtuWhDRFgAMQlJ9BwxJ9tz0cJ+Lpa7V1/3plxXu5T1XHyyKKu+3tdnPrcj52XV93BzklLSGDjRvc/txWJiYNzHFlVtY39+s9PeBr4D3s2pi8hmKYDtEXlDRN4B2gMheZxrqf1/A/szD8t4KSkiPkAj4BvboGoHlAEGA+1EZBhQGjgAVM3rgkQkAHjN1tQVCFHVM8BwERkNdLeLPgs8ISJvAaF51WlTA6gOzLK1l7Q/rtfmFnZtXk/M2dM8M2Q09zz5ElPGf5KRd/TAHnZvWc9z73zG8+98msV4OX3iGNvWrXSnNK6tGUlkmD+3DJ7Fc18u563ujTPynr2tDj8t2cctg2cxfdUhet9cC4Apy/dz65BZdH13LgO6NXSrvpa1S1EiPJAO/X+nzycLGdojsyf0xbsaMmnBLjr0/53fl++jb+f6GXnlI4Jp16CsW7UBtKxXnhLFgujw7AT6DJ/O0MfbZ+rr3pJJczbR4dkJ/L54O327XcPSTQfp+NxEOj43kUeGTGHemr1uNV5a1CpBibAAbn7zT54eG8Xg+5tk5D3fuR4/LtnLzW/+ybRVB+ndqTYAw35ez61v/0X39+fxfOd6btPmSp1SwYQH+vDq79v5eOF+HmlePiOveaVwjscm8cpv21i69wwda0UUiqa8eOf5LiQmJ+Pr4/TI+VvWLm09F69Npc/HCxn68LUZeS/e1YhJC3fS4bWp/L5sH307N8jIKx8RTLuG5QpBXylKhAfQYcA0+ny6iKE9rsnUd2dDJi3cRYcB06zn9vbM71j5iKBC0XcpSAH8K0y8yYDJiX5AH+B5lzTfbGXSY04eAJaoaj9gfT71ph+zA1iQbjgBTVQ1BdgI3GGntQR+AuJVtT/wOfChqh4BUkTk3vRK7eBb1zbvBBy3Nc23y/gCM1S1D9BRROrZZV6yywwkf/YCG4C2tsZmqro/27W5hW3rVtDkeiuOuEzFKsTHnsvIi5o9naKRpfho4NOMe3cgsefOZuT9/s0YbrzzPndKo129MvwctQ+ArYeiKRpcJCOvdvmiLNzyNwAz1xykUdXiAKzbexqAmIRkouOTcCftG5Zj8qJdAGw5cIZiIX4ZeXUqFmPBxsMATF+xjybVIjPy3nygGcN/ye8rXQD6mlZl8hzLqbhl3wmKhQZk6qtSggVr91n6lu6gSc0yWY599aHrGfbNYrfqa1e/DD8u3QvA1oNnKRbs0n4VimZ4V6avOkhj+/7Gnrceh2qlQ9l84Ixb9aXTqFwYC3ZZ36v9ZxII9st0hEefTyHYzzIUQv19iE5w6+N6UTw6cCKLV+/22PnbNyrH5IU7Adhy4DTFQvwz8upULM6CDS7PRfUSGXlvPngNw39Z6359DcsxeaHLcxuc/bk9YulbuT/rc3t/M4b/ss7t+v7NeJMBkx7bMl9EPhGRdkC4qn4FbBCRnna5PXaMR9Fsx8/G8nZMw/KQ5IuqrgMO2LEofwLp5xgATBOROcDXQBHgRRFZDIwDJtrlHgDa2HrmAZPJ2m23DOhq153+6lAcWCIicwF/YCcwQkQWYhkvP1+E7hPAFCBKRP4CXr2Y6y0IYqPPEBwanrHvcDpJS0sD4MSRgwSHhvHMkNE0uq4dM3/4CoCoWdMoX7Um4cUjc6qywIgI9efkufMZ+ympmuEy3XzwDLdfbb0Jt65TGh9H5qNRxMfBsAevZsTUi+kR/OdEhgVwMjrBRV9ahr5N+07T+drKALStXxYfp6XvoRtqsnb3CQ6finWrNoDIooGcPBufs77dx+l8veW1atu4coY+gBJFgyhVLJiNu/92r76w7PfXRd+BM9zerAIAbeqWztDXtl5pFr1zKyMfbc6Xs7a7VV86YQE+nHMxTFLTNOO9dcuxWMqHB/Bxt7q0qVacqH2FY1RdyVjPRS73df8pOrewuqjbNiiLj9PKeOjGWqzddYLDJ+MKR18uvyub9p3K47k9yeFT7td3KTjk8j+FidfEwKhqTl0nc+28IS7lurnkt3FJXw/k6CN2iZHJsm3vvwW8lS1tGXBdtmretj+u5aKBx/+/vfMMk6LM2vD9kHOSoCgCiopgTiCICiq66hrXsOpnFnWVXXMWUTEr6hrYNafVFXVdIwaQJCLKGgEzggoYEJE0wDBzvh9vzUzT9CTp6uoZz83V13RXvVX1UN1dfeq8J2Q4ZOoxts+wvlfa6zWCQsysd/R3HJH3xsweSll/L3Bv2japx60QSYOAQQB/G3oz+x5+bJW2a9SkGcuWLE7ZTx3qRMZAnbp16bF9cP/23L4Pb476Lz/O+YYPp0zg1Etv4Mtp8d4tLSpYSaumZV4XM6Nk4nH4c9O48bgdOWTnLrz5yQ98Mz8YBBuv25wLDt6Kv784nenfLoxX37KVtE65eys2SvXd+PT7DD+lL4f168aEaXOZ/eNiunVsyQG9u3LosFfot0WVbPK107d0Ba1T7n6Li8vO343/epPhf92Hw/r3ZMIHs5n9/cLScf+399Y8+kr8HqJFywppnfL+pp6/m5/9iJtP6MWhfboyccb3fPNTeH/HfjyPfhe9SKe2TXn4rN0YcNnLsetctrKo1MsCYNED4Nid1ufZD79n6re/0nWdxpy5axduGjMzdk35zJrfi5TP3VPvMXzQLuF78fFcZv+Q8r24ehT9tuhYzl5zpO/pDxg+qA+H7bIxE6bNK/ve9urCode8mpPvbXWoaYXsapIHxskhZnaPme1gZjtU1XgB2LjHVnwweSwA8779ejWvStfNtmDG/yYD8MW09+jYZWOmTngdKy7moVuGMmrkQ0x7ZxIfvj0+u/+ZiMmf/siBO4Xkq83Wb8mcBWXehCXLV/GXf07m4OvH0KJJfZ5882sa1a/LNcdsz1n3vx278QIwacb3HBzdTXbv1Io588u8KksKChn093Hsf8VLtGzSgMfHfsERu3ajjsQj5+3BJUdsz347deGA3l3i0/fRNxy82+ZBX+e2zJlfZqguKVjJoBueZ//z/0XLZg15/PWPS9ft33dTXnn7i9h0lfDWJz9wYK+U9zfl7nbJ8lWcNmISB17zOi2bNODfE2dSt45o3CAYEj8vXkHdHN0+Tv9+MX03agNAp1aNmL+kbGqyfbOG/FJQCMCvBatom2KQ/V6ZNH1eyvei9WpelSUFhQy6fSz7D3mRlk0b8Pi4zzlit02i78WeXHLkDtH3omt8+mbM4+DIy9J9g1Zpn7tCBv19PPsPfTnSF31v64hHzt2DSw7fjv126swBvbrEpq86eBaS87um5w59mPHe29x68V9o1LgJR55+Ps89fDf7HXUK/f5wMI/dcS3vTxpL46bNOPrMi2naomXptl98/B4z3p/C1r13i0Xbqx/MYa9t1uflyweyZHkhZ98/haFHbss1T33Izpu149LDtkGCF979lrc+/ZHtNlqHrbu04anzB5Tu45jbxq+WRZBNRk2dzd7bd2L0tQewuKCQwSMmMOzYXlz5+Lv02Xxdhh6zI0I89/bXTJoxj0kzyjKi+m2xHgO368Tzb8+KRRvAqLe/YO9e3Rh9+3EsXraCwcNfZtigPbjygbH02XJDhp64O5J4buKnTProGwBaN2/EylVFrCiMP5Pmlfe/Y+C2G/Dq0H1YvLyQv907mauO2o6rn/yAnbu3Z8gR2yLB8+98w6RPfqBJw3qMvGAAdSQMY+gT78WuEeDd2b+yQ6dW3HBAdwoKi7hzwmyO77UBj707h8fencNf+nVGQN064sEp3+ZEUz4zaups9t6hM6OvO4jFBSsZfPd4hh3Xmyv/9Q59eqzH0KN3QoLnJn/NpOnzmDQ99XvRMfpefB2jvm/Ye7sNGX3tH6Pv7USGHbsTVz4+NXxvj94h5Xv7PZNmlGW69dtiPQZu24nnp8yKTV91qGkeGJWfvOM4gdc++SlvPySHD3s1aQkVsmJJfs1xr8ai+DKCskG99hsmLaFCdhvQI2kJFTLmHw8nLaF8OvVMWkHF1Ekm46qqFPx3UCyWxrjPFqz1tX73zdrkzAryKaSEkbSJpJslXS1pfFR4bo1vt6QTouJ1kyTtIWmXlKDmcZIWSNoqGru5pKcVtSsoZ+zWkh6UlF+TsI7jOE4ieBCvU10uAh4Bjjaz3SRtAdxESLEGIDJo+gF9zKw4Zdvdo/UbEIr7fRRV2L0IKA2gMLM3M4z9UNK1hADlU+L77zmO4zg1gZo2heQemASR1ISQgLAn8ASAmU0D2qQNPQmYDbwhaaSk9OpWQ4iqCpvZbDM7DphVzmFTx34BbCipYTljHcdxnN8JNS2I1w2YZNmU0G6gPfBTyvJVaQXvNgHmR0XpRgJXlKyQ1AFYL0oTr5Byxn4KbPab/weO4zhOrUBZeOQSN2CSpQmwDPgVSC28V5w2VbQKKClQ8RKQGj14PPBgFY+XaexSoGkVt3ccx3GcvMANmGT5ntBHaSKhFxKSegDfpY2bTFlMzO6ENgElHEiZcVMZmcZ2BOZWWbHjOI5TK6kjrfUjp3pzejRnNcxsJtCd4FVpIGkicDNwIYCkGyQ1AO4mtCQYB5xGaByJpDbASjNbnmH3q5FpbDRN1SmlT5LjOI7zO6WmTSF5FlLyTAb6mVmmdgEXRk9XAodlWL+AlHYJaeuGVmHsMcBD1dTrOI7j1EZqVhKSe2DygDsIQbxJUGhmj1Y+zHEcx3HyC/fAJEwUrPtUQsd+IonjOo7jOPlHTasD4waM4ziO4zg5r+OytrgB4ziO4zhODfO/uAHjOI7jOA7UOAvGg3gdx3Ecx6lxuAfGqZQOzRolLaFcGjdtnLSEClmxeHHSEsqn2TpJK6iQVSsLk5ZQIctWrEpaQsV0WqOpff7w7fSkFVRM/fy95sWJB/E6juM4jlPjqGlBvD6F5DiO4zhOTirxSrpa0nhJkyT1TFt3gqS3o3V7VLYv98A4juM4jhN7EK+kfkAHM9tN0hbATUR9/iJjph/QJ62Zcbm4B8ZxHMdxnFwwEHgCwMymAW1S1p0EzAbekDRSUtvKduYGjOM4juM4KBv/pEGSpqY8BqUcoj3wU8rrVVFTYYBNgPlmtjswEriiMr0+heQ4juM4TlaCeM3sHuCeclb/CrROeV2cMl20Cng5ev4SsEaD43TcA+M4juM4Ti6CeCcCfwKQ1AP4LmXdZKJ4GGB34KPKduYGjOM4juM4ueAloIGkicDNwIWSbpDUALgb2F3SOOA0YFhlO/MpJMdxHMdxYs9CiqaL0qeGLoz+rgQOq87+3IBxHMdxHKfGVeL1KaQ0JB0l6Z8pr0+XNDR63lnSv6MiO29KGiupnqQukn6MivNMlXRQyvbbSXpZ0mRJb0n6S7T87bXUeaykraLnx0h6T9Lhkm5em/06juM4v0+ktX/kEvfApGFmj0s6WtKOhACjo4ABktoATwKnmtmHAJKaA0XRpm+Y2ZGSmgFjgP9K6gbcCRxlZrOibRpmSecjKS9PAPYys58J6WeVIklmZtnQ4jiO49R8apb/xQ2Y8jgDeBCYC5xtZoWSTgL+UWK8AJjZYgCtbnZuBHwRPT8LuKzEeIm2WZE6WNIOwHVAE+AzMztRUm9CgJMB/wbuBx4G1gd+NbP9Iq/Q28A2wPbAs5LOAO41s96RIXUPsC6wDDjWzBZIehf4DPgGuGQtzpHjOI7jJIYbMBkws1mSvgY6mtnUaPHGBM9KSfrX3UBb4ECCF2aApDejcadG23QDPqRivgb2JhgroyWtDxwBXGFmY6IiP1sCK81sl5SiPyVar5e0D7CPmS1PMaYuAkaa2X8l7Uswyq4GNgX2NbPUYkJZ5d8PjuCTj9+nuGgVg86+lE5dNgZg1pefce0lf6XjBp0BOPlvF7FB5414a+xrvPLcSFauXMG+Bx/JrnvtF5e01bjggB703rQtdeuI8x99j8/nhc7RLRrX55Zjt2Od5g1ZsnwVgx94l1+X5aYz8pCjd2SXnh2pV1ecced4Pvn2FwBaNm3AiDN3p23LxiwuWMlJw8ewcOnK0u1uOLEPK1cVcfkjU2LWtxO7bLEe9erU4Yy7xvHJNyn6BvenbctGLC4o5KRbxrBw6QpGXroP7Vs1YUVhEVM//5FLH5ocn7Y/b88uPdcN2kZM5JNvFwZtTRow4ox+ZdpuG7f6uTuhFytXFXP5o+/Gpg3ghN6d2Gr9FtQVDH9jJrMWFABQr444f8+N6dC8IQWFRQx75QuWriyifl2x52bt2GXj1lz6wmexaoP8/+yVR9vWzTjzqP4UWzFX3f1SIhqGnLo3u2y7EfXq1uGM657mk5k/ANCyWSNGXHo4bVs3ZfGyFZx0xRMsXFzAn/bcmtMO70ujhvW5698TeWLUe4noXoMa5oLxGJgMSNoSaAkslNQ3WjyLYJBgZjOiaoFTgfrR+jfMbBegK3CGpM4EL8fGlRyuF3A7cC2hrHJzQvrYAEk3AOtFXp83JN1BKMVcFbYDzo1S0i6hrGTzF3EaL598/D6//rKAK4ffwylnXcJj99y+2vre/fZg6PB7GDr8HjbovBFLFi/i1eefYshNI7hy+L289MzjLFu6JC55pfTqtg7tWjTikJsncMFj7zPkT1uVrjtzn8149p1vOeTmCbzywVwG7blJ7HoA+vZYj/atmjDwkuc4864JXHvCzqXrzjt0W56c8AUDL3mOF96exeADty5d16ltMwZss0GO9DVm4MXPceZd47n2hD5l+v60HU+O/4KBFz/HC29/zeCDys7nIVe9xN6XPBer8dJ38w5B22UvceY/3uTa43qVaTt0a56c+BUDL3uJF6bMZvABW5Su69S2KQO2Xj82XSVs2bE5rZvU5+xnpjP8jZmcukvnMu0bt+GHRSs465npTPxqAfv2bA/AEdt1RIKWjeuXt9uske+fvYq4/pyDWVFYSP16dRM5ft9tutK+TXMGnjaCM697hmsH71+67rzjBvDkq+8x8LQRvDB+GoP/vCutmjfm1MP68oe//JO9Bt3N4D/vSvOmWYksWGuyUYk3l7gBk4ak+gTvytnAOcDwKG7lUYJB0CVl+BrfGDNbDiwHGgL3ATel9nSQ1DRtkyuiY11O8MIALDOzS4F/An+X1Ah4yMwGE/LmW1Xhv/I5cImZ7R4ZViXTRauqsO1v5sOpb9N3wN4AbNi1G0sWLVptfdPmLVZ7/f2cb+nSbTPq1a9Pw0aN2GTzLZnzzaw4JQKwW48OPPvutwB8NncRrZqW/UhsvkELJn0WbLxXP5zHNl1aZ9xHttlj2w0YOSHMPs74ZgFtmjcqXdez8zqM/2gOAC+9M4vtN2lfuu7KY3txy3/ez4G+Tqvra1Z20V1N35QyfcXFrHa3Hpu2bTZg5MSvIm2/rK5tw9aM/3hu0PbubLbv1q503ZXH7Mgtz1ZaL2ut2WHDVrzx+XwAZi0ooHmjMuf3rwWFNItet2xUj4UFwdv32LtzeHn6j7Frg/z/7FXEyZc/ypv/+yqx4+/Ra1NGvhbOwYyZ39OmRZPSdT03Xo/xkbaXJsxg+x6d2HiDtnz42RwKVxVRsKKQd6Z9Q/cuHRLRnk5NC+J1A2ZNrgCeMrNvzGwuwXAZYmZzCFNDd0fZRqOj8fOivwMkjZP0FjDBzD43s3eA64Fnom3eAA5KO96zwHvAQ8CcaNl50XTUA9HxuwNTou0/N7OFVfh/XAtcHGVKvUDlnqCssGjhAlq0bFX6uk7duhQXF5c+f+fNsQw562QevOtmVhUWsm7HDfh8xkcsW7qE5QXL+OLTaRQVxWpjAdC2RUN+XlwWjlRUbKVfvk+++5V9tw135f26t6Nundx8K9u1bMz8X5eXvl5VVFyqadrsnzmwz0YA9N96ferVDSuO26s773/5E3PmL41fX6s0fSnnbNqsNH11wqVlUcFKRg07gBev+iO7bNExPm0tGzF/Uaq21HO3gAN7dwnatuxYqu24PTbl/a/m5+TctWpcn4Up05BFxVZ6r/rx3MV0bt2YB47emj02a8ebXy2IXU86+f7Zy2fatW7G/F/KzkE4d+EcTftyLgf23xKA/jt2o17dOsycM59eW3amedOGNG3cgB17bki9uvnxU5yDSrxZxWNg0jCzy9Je35ny/APKSh2n8iuhSVWm/Y0CRmVY3jv6ez3ByEnl6uiRyk5p2w9Neb57hv3+mElryfq4aNK0GUuXLC59XadOHepEPxgbdu3GLfc9iZnx1CP3MPrlZ9nnwMM59OiTuOGys2ndth3t1+1I+3Xj+6ErYVFBIa2alHldiouNkpys21/+jGv+vDUH7rgBkz//ie9+Xha7HoBFy1bSOsVzUGxlmm586j2GD9qFw/p1Y8LHc5n9w2K6dWzJAb27cujVo+gXo3FQqm9pmr7iVH3/Y/ip/YK+aXOZ/WP4DAy67Q0A1mvThOeG/pGd/vpkPNqWFdK6aYPM2p7+kOGn7Mxhu2zMhOnzmP3TYrp1bMEBvbtw6DWv0a/nerFoSmXpylWreV3MytytJ++8ISPfm8uU2QvZuG0Tzh2wMcNe/SLzjmIi3z97+cyipctp3aJx6etw7sLJu/GhNxh+3kEcttc2THjvK2bPW8Aviwq4/oHR/Gf4Scz98Vdmz13A7Hm5N1prA/lh9jl5R2pH0af/9WCVt+u+5ba8PWEMAN/NnkmbtmV2XYlnRRJNmzUvnS/doc9uXHnrvRxz8l+R6qy2TVxM+eJn9t8+zN1vul5z5v5SULpu6YpVnPXQ/zjytjdp3rg+T7/9Tex6ACZNn8fB0Z1u906tV7uzXVJQyKDbx7L/kBdp2bQBj4/7nCN224Q6Eo+ctyeXHLkD++3UhQN6d41R31wO7rtxmb6fy2KVlhQUMui2N9h/yAu0bNKAx8eGoNMS79WiZSspLCpac6fZ0jbjew7uE/7v3TdoxZyfU87d8kIG3TGB/a8cFbSN+5Ij+nUL5+6c/lxyxLbst+OGHNCrc3m7X2s+nruYXbutA0DnNo35aUnZtFqHFg1YEHlnFhYU0q55g4z7iJN8/+zlM5Pe/5qDB4SYr+5dOzDnx4Wl65YsW8Ggq55k/8H30LJZIx6PgnVfmjiDvU69m8vufIliM+b+tCjTrnNPDXPBuAfGyUhqR9EPv11c5Xox2/XahfenTGLIWSfTuEmTEMh779858vjTmTp5Ai898zh16talXYf1OPXsSwG4/ZpLmf/j9zRu0pSTBl8Qz38ojdEfz2OPLdblv+fvxpLlq7jgsfe49JAtuPG56ezUrS0XHtQTAS+/P5e3v5ifE02jps5m7x06M/q6g1hcsJLBd49n2HG9ufJf79Cnx3oMPXonJHhu8tdMmj6PSdPnlW7bb4uODNyuE8+//XX8+q4/iMUFhQy+K03fMb2Cvrdmlmp7+vJ9adKwHnXriCtizFIZ9b9v2Hv7Toy+Zv+gbcSbDPu/Hbnyif/RZ/MODD1qh6Dt7VlMmvE9k2Z8X7ptv57rMXC7DXh+yuzY9L399S/06tyK2w7tSUFhEcPfmMkpfTbkwbe/5cHJ3/K3/hshhYykf74Zn47yyPfPXj4zatIn7N23O6Pv+QuLl65g8HVPM+zM/bjyH6/QZ5uuDD1tn3Duxk5j0vszAXjo6qPo1KE1i5et4Kwb/5Pw/6CMmlaJV17LzKmM6hgwuWafq19LWkKFLPw+N0GYv4l8/+7Xy70nojrs3L9n0hIqZPLoD5KWUD7fTk9aQcXUb1T5mAQpeOfmWCyNz75fttYXhc3WbZIzK8g9MAkjaRNCcHABsCvhPRlkZtPTxp0QjSsChgArWL1b51aEFuR/JUr3BloAs8zsEEn/BTpE271DaKD1ACFTaR6O4ziOU4NwAyZ5LgIeAY42s90kbQHcREoArqSeQD+gT9TNs4Tdo/UbAMPN7CPg5JTt/k7IYiph/6jdQMn6a4GrgFOy/Z9yHMdxahY1awLJg3gTRVITQjLCnsATAGY2jbKicyWcBMwmFLMbmVpXJmIIcE3avrsAHcyspLxoMbAwdYyZfQFsmK3+TI7jOE4NpoYF8boBkyybAtMIKdip1XFXpbUM2ASYH6VLjyTUqgFAUgfKqvWmcjZwW8rrRcAYSa9L2i1l+afAZmv5/3Acx3FqODWtEq9PISVLE0KjxV+B1HKvxWlTRauAl6PnLwGnp6w7ntB4spSocu82Zva3kmVmdny0riPwCiFmBmApkF4d2HEcx/mdketKumuLe2CS5XugIzAR+BOUNor8Lm3cZMpiYnYHUmufH0iZcVPCH4DRqQsklRiri4DUzoQdCV23HcdxHKfG4B6YBDGzmZK6EwJp95U0EVhM1M06auZ4OaE304OSDiN4a06M1rchdKlenrbr3YHn0pY9H8Xc1CXqixRNU3Uys9wXnnAcx3HyihrmgHEDJg+YDPQzs9PTV5jZhdHTlcBhGdYvIMpESlv+twzLMrVAOIbQg8lxHMf5vVPDLBifQkqeOyinj1IOKDSzRysf5jiO49R2PIjXqRZRsO5TCR37iSSO6ziO4zhrixswjuM4juPUuCwkN2Acx3Ecx6lpITBuwDiO4ziOQ42zYNyAcRzHcRwn50G4a4sbME6l1K2Tvx/q4uLiygclSXFR0goqpk7dpBWUz8plSSuokHz+XgD5/d7Wb5S0goopTC+t5eQjbsA4zu+VfP6Bcxwn53gQr+M4juM4NY4aZr+4AeM4juM4jntgHMdxHMepkdQsC8ZbCTiO4ziOU+NwD4zjOI7jOD6F5DiO4zhOzaOG2S9uwDiO4ziOU/M8MB4D4ziO4zhOjcM9MI7jOI7j1LhWAr9LD4yktzMsO0TSOEkTJU2WdFG0fKikjyRNkDRaUvto+UOSnsywnzskPZTyeg9Jb0iaFO33YEldJP17Lf8P50jqGD2/UNJUSbtJunpt9us4juP8TlEWHjnEPTCApMOBQ4D9zWxJtKxFypALzOwVSScBxwDDo+WbSupiZrOibdoCvYAZ0eu+wEXA4WY2P1rWEFhvbTWb2fCUl4cDO5pZMTC+KttLkpnZ2upwHMdxagc1y//yO/XAZOBc4OQS4wXAzBZlGLcZMD3l9Z3AWSmvBwMPp7y+GDi1xHiJ9rsidYeS9pU0RtIUSVdFyw6Q9JakNyOPTVtJL0feofuiMQ9J6i7pNmAT4A1J7Uq8S5LWlfR85P15UlKDyPMzStJ/gb9W8xw5juM4tRhp7R+5xA2YQJ0Uz8s50VTSsynrb5T0EdAP+DBl+SSgu6RWkpoAOwNjUtZ3MLOZlRz7XTPbA+gDHCqpDnAC8H9mtgvwHNAX+J+Z9QMGpW5sZmcBM8xsdzP7KWXVTcAVZjaA4JU5Ilq+GXCkmd1eiS7HcRzHyVt8CilQJKm+mRVGUzPD0+JkSqaQegAPAPumrBsBnAoUROtS+UVSezP7sYJj7ydpS2Al0ARoQPDqnCmpgDBd9SLQVdLtwBPAGjE8GdgKuFXBJG4EPBUtf8/MYu0V/8QDdzPjo/cpKiritHMuZcOuGwPw9ZefMeyiwazfqQsAp/ztIjp12YhJY19j1H+fZOWKFex7yJ/ZfeB+ccor5cIDe9J703bUqyvOe+R/fDY3ON1aNK7P8ON2YJ3mDVm6vJAz7n+HX5cV5kTTkGN6sUvPjtSrW4cz7hzLJ98sAKBl0waM+OsA2rZozOKCQk665XUWLl3ByEv3pX3rJqwoLGLq5z9w6YNvxavv6B0jfeKMO8fzybe/lOk7c3fatmzM4oKVnDR8DAuXrizd7oYT+7ByVRGXPzIlXn3H9GaXLdYP+u54I+387Vmm75bXWLhkBSMv24/2rVLP36TYtB3XawO26tiCunXErWNnMntBAQD16ohzB2xEhxYNKVhZxDWvfcmylUXUryv22LQtfTZqw5CXPotNVwlDjtqBXXqsGz57d09c/b09Y1fatmgUPnu3jV39vT2hNytXFXP5o+/Eq+/Uvdll242Cvuue5pOZPwR9zRox4tLDadu6KYuXreCkK55g4eIC/rTn1px2eF8aNazPXf+eyBOj3otVX3m0bd2MM4/qT7EVc9XdLyWioap4EG/N5FGC0VIfQFLdcsYtABqnLXse2AP4I2VGQgn/BEZIalqyIPV5xJlmdi5wDdAwWvajmZ0PjAMuBxqY2W3AOcBdVfw/fQEcb2a7E7w7d0bLV1Vx+9/EjI/eZ+EvC7j6tns57ZxLeOSfqzt6dt51T6669R6uuvUeOnXZiCWLFzHqvyO54uZ/cPVt9/Li0/9i2dIl5ew9e/TapC3tWjTi4JvGcf4j/2PIYVuVrvvrvt35zzvfcPBN4xj1wVxO3WvT2PUA9O25Hu1bNWHgxc9y5l1jufbEPqXrzvvT9jw57nMGXvwsL7w9k8EHbV267pArX2Tvi5+N3Xjp2yPSd8lznHnXBK49YecyfYduy5MTvmDgJc/xwtuzGHxgmb5ObZsxYJsNYtUG0LdnR9q3bsLAi57hzDvf4NoTdynTd9gOPDn+MwZe9AwvTJ7J4IO2KV13yJUvsPfF/4nVeNlivea0blKfc5+dwW1jZzKoz4al6/ps1JofFq/gnP/M4M2ZC9i3R3sADtu2IxK0ahz/fWbfHuvSvlVjBl72ImeOmMi1x/cqXXfeIdvw5IQvGXjZi7wwZRaDD9iydF2ntk1z895u05X2bZoz8LQRnHndM1w7eP8yfccN4MlX32PgaSN4Yfw0Bv95V1o1b8yph/XlD3/5J3sNupvBf96V5k0bVnCE+Lj+nINZUVhI/Xrl/azkETUsiPf3asD0iKaJxkkaBtwNfAKMlTQWGM3qsSw3ShpH8H6ck7qjKBD2SeAFMytKW/cMYQro1ehYY4DeaVqmSJoK3AJ8Ey0bLmkCwXh5Bthd0hTgdYI3pipcAjwg6Y1oH22quN1a8eHUyewyYG8ANuzajSWLf11tfdPmzVd7/f2cb+m6yWbUr1+fho0as2mPLfnum69j17l7jw48+0443Z/OXUTrJg1K13VfvyWTPg1Os1c/mMs2XVrHrgdgj203ZOT4zwGYMXsBbZo1Kl3Xs8s6jP9oDgAvTfma7TfpAECxGQuXrlhzZ7Ho24CRE74I+r5ZQJvmKfo6p+h7Zxbbb9K+dN2Vx/bilv+8nwN9aeevefr5+y7omzIz5+dv+w1bMvbznwGYtaCA5o3KjJJfC1bRvGF43aJRfRYWBG/f41PnMGrGT2vuLAb22GYDRk74EoAZ3/xCm2ZlP/Y9O7dh/MdzAXjp3dls361d6borj9mJW/7zQfz6em3KyNfCZ2jGzO9p06JJmb6N12P8/74K+ibMYPsendh4g7Z8+NkcClcVUbCikHemfUP3Lh1i15mJky9/lDcjfflODbNffp9TSGbWIsPiu6NH+tihwNAMy49PeX5/yvNPgdR1jwCPZDjekdH6MzKsOz3DslEVHL93+nMz+xwYUN5x4+LXhb/QslXZD37dunUpLi6mTp061K1bl3feHMv0D6bSdZPuHHvqWXTouAGfT/+YZUuXoDp1+OKTaey65x/ilAhA2xYN+Xlx2Q/XqmJDAjP45LuF7Lfd+jz+5iz6bd6eenVzY+e3a9mY+YsKyjQVFZdqmjbrZw7ssxEPv/4J/bfegHp1w6Vi0bKVjLrmIApXFXH9k1N5c9rcePX9Wjb7uJq+2SX6PqX/1uuX6jtur+68/+VPzJm/lJ4bxmtDt2vVmPm/Lsus7+ufObDPxjz82gz6b9Op9D0N5+9gCouKuf7f7/LmtDmxaGvVuD6/FpRNQxYVGwIMmDZvMUfvuD73/nkrDPjb09Ni0VAR4bOX+t7a6p+9nbvy8OjP6L/V+qXn7rg9N+P9r+Yz5+ccvLetmzH/l6Up+oqRhJkx7cu5HNh/Sx5+/h3679iNenXrMHPOfHpt2ZnmTRtSXGzs2HNDnnwlmSmkmoRX4nVqBZIGRbVlpj71WHpoT/k0adqMJYsXp+ynDnXqhI/Zhl27cev9I7n6tvto1qwFo196luYtWvKnY07i2kvOYsTNw2i/3vq069Ax6/+fdBYVFNKyaZnXpdiMkqTy2176lF6btGPkObvSuV1Tvp2/tJy9ZFnTspW0TrnzTdV048ip9O3ZkRevPoAu67Zg9o/hHA+6bQx7X/wsp9w6huGn7pqcvqfeo2+P9Xjxqv3p0qEFs39YTLeOLTmgd1fueP6jWHWV6lu6ktYpXqvVz9+74fwNOyicvx9CvNOgW0ez98X/4ZThrzP8tN1i07Z0ZRHNGpbdLxZbMF4ATuzdiaffn8cpT3zEDa9/ydn9N4pNR3lU+N4+/QF9e6zLi0P3De/tj9F726sLd7zwcW70LV1O6xZls/dBXxB440Nv0Hebrrx4xyC6rL8Os+ct4JdFBVz/wGj+M/wk7r7kMGbPXcDseQtyotXJHW7AOBkxs3vMbAcz2+GwY06s8nabb7ktkyeMBuDbWTNZp13ZVEJRUQi/kUTTZs1Lrf0d++7GsNvv4/8GDUbSatvExZQv5vPH7cPc/abrNWfeL2Wej6UrVvG3B9/l8OETaN64Pk9Nnh27HoBJ0+dycN9uAHTv1Jo5KYbTkoJCBt02hv0vf56WTRvy+BshqLNunTJPTGFRccz65nFwn43K13f7WPYf8iItmzbg8XGfc8Rum1BH4pHz9uSSI3dgv526cEDvrjHqSz1/bZgzvyyWaklBIYNuHc3+l/2Xlk0a8vgbnwK5O3/T5i5i127BS7Fh68bMTwmC7dC8IQuWhdcLCwpp16xBxn3EyaQZ8zh45/DedN+gFXN+Tnlvlxcy6O/j2X/oy9F7+wVH7NqNOnXEI+fuwSWHb8d+O3XmgF5d4tP3/tccPCDEqXXv2oE5Py4s07dsBYOuepL9B99Dy2aNeDwK1n1p4gz2OvVuLrvzJYrNmPtTpsoYTirKwr9c8rucQnLiY/veu/DelDe57G8n0ahxU0475xIevefvHHnC6UydPIEXn/4XderUpf2663HaOZcBcOuwS5j/4/c0btKUk/96YU50vv7RPPbYcj2eu2B3lqxYxfmP/I/LDt2SG/47jV6btOWig7ZAEi+99x1vfzG/8h1mgVHvzmLvHToz+oZDWFywksF3jmPY8Ttz5WNT6NNjPYb+X28k8dxbXzFpepgqenrIfjRpWJ+6dcQVj1QlOW0t9E2dHfRdd1DQd/d4hh3Xmyv/9U7Qd/ROSPDc5K+ZNH0ek6bPK9223xYdGbhdJ55/O774plHvfh2dv0NZXFDI4DvfYNgJfbjy0bfp06MjQ4/dGUHa+fsjTRrWC+fv4fiCoKfMWshOnVsz/JAeFKws4rZxX3Pyzhvy0JRveWjKt/x1t65IISPpnre+qXyHWWbU1G/Ye7sNGX3tH8O5GzGRYcfuxJWPT6XP5usy9OgdEOK5t79m0ozvmTTj+9Jt+22xHgO37cTzU2bFp2/SJ+zdtzuj7/kLi5euYPB1TzPszP248h+v0Gebrgw9bZ/w2Rs7jUnvh8oVD119FJ06tGbxshWcdeN/YtNWm6hpU0jyYqzJImkTytKwdyUYlYPMbHrauBOicUXAEDMbI6k/cCNQDNxpZo9KagbcC6xPyJo6NrUon6ThwEozu0jSLcCDZlbhpPu0OUvy9kOyxxWjKh+UIIu+/yFpCeVTJ8+zIopyk7r+W9nlDzslLaFC3hydm6m738Tcz5NWUDGFsVaaWGsK3r8zFlPjl2VFa32tb92kbs7MIJ9CSp6LgBcIRe92IxgpN6UOkNSTUESvj5n1NbOSYnk3AHsCuwDnKRR9OZuQEbUrIWvp9JT9bAjslbLrq4FhsfyvHMdxHCdG3IBJkKh6rxGMkCcAIm9Iekj/ScBsQruAkVHPJQgelpZAM2BJlNI9gLJ6NM8QqgOXcC3B6CE61kJgkaROWfxvOY7jODUQbyXgVIdNgWlAeyC14MOqqKVACZsA86OidCOBK6Llw4Gp0T5KUoUamlmJ7/1noDVA1Ijyf8B3aRreB7bNxn/GcRzHqbnUtCBeN2CSpQmwDPiVyNCIKI46S5ewCng5ev4SoRBfe+BvQOfoMUDSVkBxivHTGvhJ0qbAwcBtGTQsBdKrAzuO4zi/M9wD41SH74GOwETgTwBRv6V0L8lkyvov7Q58BLQFVplZgZmtAn4BNgCmAAdGYw8lVBU+ivBePwEMAQ6QdHA0piMQX/Uzx3Ecp0bglXidKmNmMyV1B64C9pU0EVhMCORF0g2EdgJ3Aw9KOozgrTnRzH6OCs29RYij+QB4BXgHeFTS34AvgTPMrLTkrKTdgX3MrKTbdi/g+rj/r47jOI6TTdyASZ7JQD8zW6N9gJmVFEVZCRyWYf3VhEyiVOYD5dbiN7NxhCaRSNoVeCvu7tSO4zhODaCG1YHxKaTkuYMQxJsE6xIykxzHcZzfOR7E61QLMys2s6cqHxnLsUemd9B2HMdxfp/kIohX0tWSxkuaFNU4K1m+jaR5ksZFjx6V7cunkBzHcRzHid1/IqkfUdFWSVsQirbumzLkaTMbXNX9uQfGcRzHcZxcMJCKi7b+Up2duQHjOI7jOE5W8qglDYoyZEseg1KOUFHR1lXAwZImSrpdUqVt2X0KyXEcx3GcrAThmtk9wD3lrC63aGvkkdky6ul3BXAKcFdFx3IPjOM4juM4uQjiLbdoq6R6AFFPv4WE+mYV6w1jHSd3SBoUWel5Rz5rA9e3tuSzvnzWBq5vbchnbbkkmi66C9iCsqKtZxIKtv4ROBsoAmYBg1KLsGbcnxswTq6RNNXMdkhaRybyWRu4vrUln/XlszZwfWtDPmuryfgUkuM4juM4NQ43YBzHcRzHqXG4AeMkQT7PBeezNnB9a0s+68tnbeD61oZ81lZj8RgYx3Ecx3FqHO6BcRzHcRynxuEGjOM4juM4NQ43YBzHcRzHqXG4AeM4juM4To3DDRjHcRzHcWocbsA4WUXS4KQ1OL9PJHVKWkN55LM2yH99+Y5f95LBDRgn2/SXVD9pEeUh6b6kNdRUasC5eyxpARWQz9ogz/VJGpa0hkrI6+tebaVe0gKcWkcj4BNJ7xGacpmZHZWwplQWS9rMzD5LWkg60V3c6YSW8xDOXZ8EJaWTt+cu4sPoh+4tYBWAmb2WrKRS8lkb5L++DSW1MbMFSQsph3y/7tVK3IBxss3pSQuohN7A/pJ+oexCky9GwsnANma2Mmkh5ZDP5w7g5+jvjtFfA/LlRziftUH+69sc+ErSF+TnZy/fr3u1Eq/E62QVSfWAI4D2wJ1AGzP7IVlVNQNJz5jZoUnrqMlIagB0MLNvk9aSTj5rg/zXl8/4dS8ZPAbGyTaPAi2Awwiu6LuTlbM6kjpLuk/SvyU1krRb0ppSWCZpvKTrJF0r6dqkBaWS5+cOSccBLwMvRvquTFpTCfmsDWqEvlaSLpV0s6SGknokrSmNvL7u1VbcgHGyTTszGwEst+Dea5WwnnTuA24B2pvZcuD8hPWkch8wBHgFeDV65BP5fO4ATjazPYEFkb5eSQtKIZ+1Qf7rewR4D9jJzFYA1yWsJ518v+7VStyAcbLNUklbA0jaMGkxGZCZfZLyulliStIws/HAfKAtMDd6nU/k7bmLMEl1CfEbAC2TFJNGPmuD/NfXxMxGEQUYA82TFJOBfL/u1UrcgHGyzSDgXKANcDNwWrJy1uBzSX8Fmko6Gvg+aUElSDoPuAboBFwv6YSEJaWTt+cu4iZC4Gk3SS8A9yesJ5V81gb5r+8HSQcAdSX1BQqSFpRGvl/3aiUexOv8rpBUBzgB2A74DLjXzPLiYijpLaCvmVmkc4yZ9U9aVwn5fO5KkNQS2BT42szmJ60nlXzWBvmtT1JT4CLKPnvXmdlPyapyksYNGCcrSLrSzK6QNJkyNzQA+ZDuKKmBma2MMi1WI1/SliWNTTVYJE0ws12T1BTpyOtzJ2kPMxsj6VTW/Ozdk5AsIL+1Qf7ry3fy/bpX2/E6ME62GB39/WO+3b1FXEYIkH2VsguNoucDkhKVxjRJlwEvAn8APk1YTwn5fu5KpsKXJ6oiM/msDfJcn6QbzeyCNANBVFAHJqqIuxnQlBBLFmdaeL5f92o1bsA42eIWYCdgJPnxo5bOj9Hfa8xsdIUjI3J8IQT4G3AioaDddOAvMR+vqlT73OWYc4DXgS3MLN8yo/JZG+S/vneiv6eY2bSKBkrqAFxNiCH7FFgGdJS0AfCQmf0rBn35ft2r1bgB42SLZyRNBTaJYjkULc+XipknSpoEDJM0mzJ9mNnnqQNzfSEsmaIhfB8fiR6QP0H2VT53CVFP0u3AgZIKU1eY2SUJaSohn7VB/uu7SNIY4E5Je7H6Zy99+vI64Foz+zJ1oSQBx0g6wsyezLK+fL/u1Wo8BsbJKpJuNbOzk9aRjqQ9gD8D+wGjWP1Cc2La2Aeo4EIIrMzmhVDSVWY2RNJY1nSTJ35XV51zlwSSmgDbA38Hzkpdl3Qqej5rgxqh7xjgeILG91n9s5f4d6OEfL3u1XbcgHGygqR1zex7SZumr8uTu3QgVBw1s4eT1lETyfdzJ6m9mf1Y+cjck8/aoEbou9DMbqhkzPVmdlH0fFfgDmAlcImZvR6Trmpf9yStD2xLNDUNTMmHYPiaiBswTlaQdJaZ3SbpwbRV+XKXXuVsiyQuhNGxSjwx3YF7gUfM7N64jlcNXXmdqVJOJkiFgZ65Ip+1QY3Qt4WZTZO0N2t+9l5LG/tGiVdG0qsEz81i4CUzi6XtRXWue5J6AsMI3eY/AJYCHQlVjycRvL7+g1wNPAbGyQpmdlv0N9+Kr5VQN/pblWyLnVKeXwrsQ3QhJAQ8xkXJRfZkYG/gBYIhkzTVOXdJcB2Ame2ctJAM5LM2yH992wLTCJ3QU8nULbuRpFbAIqCBmc0DkFQUl7hqXvdOAI43s1/TV0jqBxwKPJ1VgbUcN2CcrCLpHjMbJKkXcBfwvJldlbSulLu1x8ysCErviL7IMDznF8KIoqj67i9mtkxS45iPVyWqee5yjoXePUg60Myek9QCuBx42symuLbyqQH6Ho3+ljaXlNTCzBZlGP4D8ADBuJkVja1LDqr2VuW6Z2bnZdjuQDN7zswmxq2xNuIGjJNtNov+HknwZKTfJSXNBKCvpKMIXo6GBK2pJHUhPIUQKHuLpEaE5on5RFXOXZKcCzxHSA1+GbgW2CNRRWXkszbIc32SXjCzP0ZTSRdK+tTMViszYGYHp28XGdz75UBipdc9rdldXsAfJfXKk4yvGke+pGk6tYclkq4klCMvJg8b/kV/e5vZcUC7NQaYHWxmh5jZoSWuYTMrMrO4L4TrEOJtDDgJSDwLJI1Kz13C1JXUldD4byz5dYOWz9og//WVNJfcN4pzWSNoVtLTkrbLraxSqnLdawTsT5gSe5XQdf6H6K/zG3ADxsk2xwL/I9RtaAgMTVbOGnwcpSu/FnlVmqYPkFRP0qGS9olSp0uWnxWztlujIL6/EWrPjIj5eNWl0nOXMDcQGundEXmwpiesJ5V81gb5r2+upIeB96LXmbpRdwWOk/RENJWTSyq97pnZOQRv0B+AbaI09R/MbEIuhdYmPAvJySopc+ktCSXonzGzt5PWlYqkVma2MPoRbmtmP6St/zfwDfAL0AM41swsNcshJl2TCG7768zsbKX1RsoHKjt3SSKpbnqMTr6kp+azNqgR+hoCm5nZRwo9uTY3sw/TxrxhZgMkdQbOBrYmlPqfZGbjYtZXreuepBOBgwm/wfvHqa024x4YJ9ucG/09mzCXfk2CWtYgSlVeGKUqjwcOyDBsPTO7wMyuI3hBSuanlWFsNnkIeAO4L7oLXhjz8apFFc9dkkwAiGJ0LqCsonE+kM/aIP/1nRgZLx2Bx4HO5Q00s9lmdhYhe3A6cGAO9FXrumdmDxDijd6NWVetxg0YJ9vk+1x6aqryQDIHoS5X6IOEmb0FrJL0f0D9OIVFNV/6A4vMbHmmoMRUJNWXtIWkXpI6xaktoirnLknyOUYnn7VB/usr+awNBs4nrWpwxFepL8xshZn913JTIbfS656kZpIukPRsNBV7DTCv5FrjVB83YJxscwOhwVm+zqWvlqoMZEpVPo+UIEELFUCbEgpQxYak4wi1Zl6S1CgKCsw0roOke4DnCcG+BwBXSXpd0tExSqzKuUuSfI7RyWdtUE19CRjPdST1B4rM7Gsy30zcngMd5VGV694jhHpSpwF7AWcQfoPvypXI2obHwDixEM1TAxmbriWGpI0JgXQlFWSPity5qWO2sEo638akbaKZ9SuJfZH0ipntk2FcTns1pey/0nOXNHkeo5O32qBq+lROo1Mgzo7PREG5R0THLgDOM7NhaWN+JhSavMbMPo5DR2VUdN2TNN4yVASOO7auNpNv7n2nhiNpKKGiZBNC2uAsoG+CktKZRZh33jV6/V2GMeMlJXEhtOjHo+SuomXGQSklyqMflG7A52b2E/BojPpmUfm5SwxJOwCnSErNUDkqKT2p5LM2qJa+JDo+Y2ZTJH1D2dTWyAzDPiLEogyRtC7wIPByLm6gqnjdmyPpSOCplIDpg8jfCtd5jxswTrbZmxD9P4wwx3tLsnLW4FngJ6ALsIQQKJtedCqpC+FNkZZukl4A7s80SNLjZnaUQqfe04A3gR0kPWRmj8WoryrnLklGEN63PwHjgK0SVbM6+awNqq7v1nTjBULjH2I0niXdRwjcbRMt+o41g3PNzOYAp0pqT+iFdL6kFTnwcFTluncKIcj39SirqgiYAvxfzNpqLR4D42SbpVEhp/pmthSosLBUAnPpzc3sJOAdMzuQzHEcZmZzzOxUwkVnU2CspDdi1jYfOIRwJ3eCmZVXiXfD6O8pwJ4WGk/uDZwas76qnLskWRzV1FhiZv8hNMnLF/JZG1Rd3zhJ/5a0ZQ61QUih3otQAG4nQpuPdEqzBM3sRzO70cz6Er5PcVPpdc/MlprZMDMbEOk6AxhjZj/nQF+txD0wTra5RVJbYJqkdwl3GGtQ3ly6pFjn0oECSfWA5pGGnpnklTwxsx+BG4EbJbWOSVMJw8xsDypPrfxRUg9gLsFdvZxQ1j/ubIaqnLsk+UjSOoReVheSX5k0+awNqq4vKe9kSRuPpoQp1kweossybWhmv8QlKoVKr3uRx/Q8QiDvA4SaT79I2s/MBudAY63Dg3idREgwELUL8DPQndC07imLGsaljOlrZpOyfewqaLuX4NV4C1gFYGb3ZBjXjpD1sA6wCeFi2ZNgAD0fo74uVHLu8oEoC2Rf4G0zm5u0nlSqqi1Krd2M8IM918y+zQd9qQGnKdM0BwKxTtNI2h74muAZugJ4NsoOTB3T38zGSmpDqIS7OcHgGpYjI6ZCJE0G+hGqCH8EdDaz4pLg/WTV1UzcgHGygqQnKAs+XQ0zWyMYUNKWSWUKVEZSF8IojXo1zOzhCsa3AjYiGDufW9RZ+PeGpIHlrbOyTtqJUF1tuc7y+Q36xlqG6tCSWidtJKRk8f0beIpQkqA/MKiymkprccwqX/ckvQMMAFoDU4FOZrZS0qRoSsmpJj6F5GSLi6o5flwuM32iu5/yLjR90hZdRbhTuptwIbyAcCF8gFD+OxYqMlbKGb+Qst4wsVHNc5cEO5ez3Eg+yLi62nKd5VNdfTmdpqnmZ6/k96yDmT0TPR8l6YI4tEVU57p3ITCG4MU8BviPpEJgVBzCfg+4B8bJCpIOJMyFF6YsawL0slCZMn38WMKXeAiQ05THypA02cx2Tr/bLO/uM4vHfZcwLfQj4a77W+B74Fwzm5UyLm89DkkgqUGGmhsC6prZqoRklejIW22RlrzWVx0kHQ/sAswmBMS/TKhbtLuZHR7TMat13Uvbth2h3s4ncWj7PeBZSE62uCD1SwxgoVrrJeWMz2mmj6SrlFayW1ITZe4w/c8obfMNSadL6izpL4QU4jh5F9jVzHoTSvVPIqRk3p027hRCafWd0x694xBVzXOXOiZXGWZvKNTPSaUh8EymwTmmWtokXZ/yfFdJH0p6V9JeeaJvYHmPOMRJOq2cz96f08ea2UPAcKAVoePzcEJdlhPi0BZR5eueQiVhJLWR9HdCT6eTc5AcUGvxKSQnW5Tnyku/OJaQ60yf3c1sSOoCM1smaX/gtrTlD0Xz1ScBOwJ7ApOJ90IIIVX0u0jDp5J2MrMLosDKVC4HLjKzjK0GYqDK5w4SyTArsqgwWIq+5Vq9KFtSVFfbTinPLyU0JFxMiOd4PQ/0nRLpmZ22PK7pumPM7B9p+pZJOgl4In2wmc2grLEiAAqZc3FRneteIlPTtRk3YJxssSI9kC9ypZaX2pvrlMfyPusZDawELoQAv0Z3li8Tqt2WGHmrdcGOjJsh6RvHSLXOHbmP42hYTX25pLraGkXB2YuABmY2D0BSUTnj15bq6hsCXJhD47m8DvDVeW+HUf0YvapSneteEjE6tRqfQnKyxbXAvyV1BlCoifAw8M9yxk+W1DtKxUTSsZL+ku4uziJzJK1Wt0TShkBhOeMzMazyIWvFCYR06H8RXOBHR0bTtekDzeybkufRNM0aPZOySLXOnZmdmG68RMvNzB6NIT1+lKTVOg5LOgLIh9iC6mr7gXBH/hShHD3RFE9BOeNzqi+K18il8bwwffpRoV5NeYbNGlgo9BgX1bnuJTU1XWvxIF4na0jqA1wMtAd+Ae6xUNUz09hHgBWElMKPgQbAHGA7Mzs5Bm1dgX8TSqZ/SOgfdAHwFzOrrHBczogMg/XNbHIFYzIWxAKIoyBWdc+dpN0Jn4MPgX8Q5vrrABeb2ZgY9NUF7iDUTZkW6SsE/s/MFmf7eLVFG1Rfn3Lc6FTSdpG+Syn77N0IXG9mr6aN3Ry4mXBNWQUUE1oOXGihxUBcGvsSPDwdgAVUfN3rQZia3oRwnicDIyxU73WqiRswTmxIamFmmUp+p9ZsaATMNLOO0fIxFqrRxqGnNXAi4SI4G3g81ZORMi6pC+ElwJaEH5M+wG1mdlqGcTkviFXVcxeNnUJoibAZcBchIHkB8Hxc72103HaEujjflEy95AtV1SbpacL0W+zp8WnHraq+nHd8ltQN+Btln737yzGcJwKnmdn0lGU9gBvNbP9caP0tSKpX0zK+8gWPgXGyiqQXzOyPkvYGLpT0mZmdnmFoAZQGDKamG5Y3J58NtiB4eUZaxZVN7yHzhfCfQJwXwoFmtrtCuvZySRuVM64uoYVAM4Lnqh6wkhinhM3sF0lFqe+lpNPNbESG4UsiQ2+OpGUl5zqKgYmTkkDIraNDLQc+MLOPYj5uVWhCCIBtppDu28vMxmcY1xU4TtL5BAM2YyuOGPiTmY2Q1FHSU8Cjlrmqc85bCUTTkYOh1EPZoJyhRanf2WjbGZJaxKVNoaJ4Riyla3wlxBmjU6txA8bJNi2jv/ua2QBJo8sZd46kxmZWYGZHQ/DYEOaPs45Cemp7QqryCEnDzay8lO2cXwhLDiOpWfS3HsHDkomcFsSS1JHgGTpe0oxocSPCXXEmA2aqpKaRW/zCaB+NKT9jI1v0IXTJ/h8hu2MZcKBCpdPhqQOV+1L99wF/Be6KjNPzgUwGzK9m9rcopuLs6HM7GphkZuNi1Hck4b0cTJgevB/IZMCY5bDjs0KdlYuBz4GRwJmEnlwTzOzWtOETJP2DkJ30E8GDehhhaiwulhIyxx4ifCerbaTHHKNTq3EDxsk2cyU9DJQYBxl/hM1smqQGkrYiXGh+Aj41s3tj0rWrRZU7o/ibp1M0ppPEhRDChfoVQk2cMZQTNGyhQFZpt2BJHxBvQaxGhBozLaO/AooIU0qZ9F2Y8rzEgF0B/DEmfSW0M7Pjo+cPSnoxOuZEQk2QJFK8S5CZfZLihGpW0WAzmw2cJakhIaD7QGBcTNoA6ijUKSkys68rCKbPdfmDSwnG6MYEA72rhfL7bwLpBkxjQgD8XoRmlL8Cr5vZS5L6Ae1Tsn+ygpkNjoKKBwN/JwrAtgyxGUlNTddm3IBxss2JQDcz+yi6+A7KNEjS4QS36duE+IjWQE9JQ8xsQgy6SvsEmdnSSFt55PxCGOl6G9glikeYD+yeaZzK6dUkKZZeTWY2E7hS0rtm9nJl4yXVIdyVzjSzHyUdS/jBjss4LaGtosqykQdrPTMzSanTG7lO8S7hc0l/BZpKOppQYTkTX6W+MLMVwH+jR5ycBxwODIvi0l4tZ1yuyx8sjTx5H0n6KmWqKtOU1T8J1xQj3GwsA3aIzvdk4M44BJrZz8DQyMt4MvBKNJWefrykpqZrLR7E62QVRWX4qzIO2MNC1cqSZU2AF2NyRX9GmHKBcBfZhmA4maX1VImCBtMvhB0JUw6TgTsz3WGthbZtCKmp3xLc920IHoM6ZnZEhvE5b1oXHfcqMxsiqTthSuThTB4z5TjDLOW4RxCmtaYQDKinCRksD5dMU2bYZgtgAzN7JS5d0XHqENLktwM+A+41syqnRktqZaH3VWxI2gVYj3DeGkTGU/qYnDY6lfQDZVMzA1Ke9zezdcvZpjHBi9kE+N7Mvs62rnKO2wI4jZAV+G8zezBt/Tgz2z3DdhPMbNdcaKxtuAHjZJVozv5L4C2CmxQz+zzDuAnAgNToe4WUzkkWSuknTq4uhFH2xCkEN/kRhGyLS62cXipKrlfTeDPbTdLNBIPrBcuQVaQEMsxSjt2SkKI6xzJk00R34+eToxT0tGOXGAjPAPXLMRAGEtpH/ELwFI2Llr8Rh2Gfctw7CfEc/Qn9hB6yzF3kc2o8R7FAGYmm2RInCiw+m3CDM8LMXihn3FWEOLz0qekGZvaXHMmtVfgUkpNtOkSPkvbwRuZYieGE3kejCV/mNoSy6XFPM6yGpOfN7IBM66I75A9zIKPIzD4FPpV0O7BDJXfbqxXEoqxpXdwFsYoknQD8YqGce+NyxiWRYVZS4OxIwmdJkjCzq9KGnQnsQIYU9Ji1pRoI/yVk76xhIBDinvYhBCPfLumnaMoh7gyuzc1sj8gIXhkF6GYi19VkvzWzYiitR1QSm5MXafKRIbcJYXrqH4QA/E0h441bIlPTtRk3YJysYmZV6hdkZv+V9BohKLQdMJNw9/JzxVtmnXzol9M6uvMWUVZDSbCnZegubcn1ajqFYCjdEnlX7itnXE4zzFJ4gZCp8i4V96jJaQp6RKqBUFiBgbC05DsQxczcJ2kQ8WdwrVLINrPovSrP2My18fy6pAOiOJjngKmE98yA42I6ZnUoIBjCuxJqM5UYmplu3BKJ0anNuAHjZBVJ2wK3E34oFgODzeyLDONK5tI/BK4AegAfxhWIKilT7QgR/51tVfgPoZt0+vNyG+RZMr2aZhPihk4nXGxfKkdbabaWQtZPN+DzTPEyWWa5md1WyZgLyGEKegpVNRCmSNrOzN6LPCFXE6ZqNo1Z32BC6nQPQgzMeZkGJWA8N7CyKrU/W1RbJbr5SZyq3rBFY78kdJ9OnZoenasYndqIx8A4WUXSOOBYM/tGoYfJCMtQBTNtLn0k4U4uzrn0sQSDYA2DJc64keogqZmZLYmeC2icGuRche2vtxhrSkh6ApgA/B9hivBpMzs0w7jHzewohZYHpwFvEqZtHrT40pSJpjHejzQagFVSYE0h4yvOFPSS42xKMOy3JdyxX25VLFIXebu2tBy0vJBU19K6U1dxu1iqySqlurSkzUvep7jjvaqKQu+jY4DphOnmBwkevrMtPwoo1mq8maOTbYotKjFvoThYeXESqXPp/zGz5WY2CmgVhygz629mA6K/qz3iON5vJD0Tplrz4XEaLxHtLFTeXW7hzqdVOeM2jP6eAuwZ6dqbYMzEyR+ASwjn8VXWPJ9IqifpUEn7SJKZ/WShPstZMWvb28z+YGbrmtnA8owXhVosSGoj6e+SXicE9a7RHDObSNo7MvI/lNRI0hnV3EVcjU6/izLFSDFeOhOmX/KBxwmdw/cEniV4ro5mzRo1Tgz4FJKTbVZI2tjMvpK0cQXjcjqXLqncNEWLp+7Mb6HUW2BmppBWvgZKriDWUklbRxo2rGDcjwr1LeYS7kaXE6ZM4uo0DlTZk/YY8A0hy+doScdGxtgBwG0xyusv6R9mVln386sIsRR3E6aOLiB4Jh+grFVCHFxGSFN+LQq+3p/Qx6pKxGg8X0To9jyC4LnaBDgHODWm41WXhmb2AICkD1OMrHyYmq71uAHjZJuzgH9IakqoBZIxNTWBufSRwI+EWIciVg+2yxcD5itJpwJPErwJC8oZl1RBrEHATYQsn5sp36NyKnADYY7/LYXmjj2J6S5d0lFm9rik60gLdjWzS9KGr2dmR0bb9SF4bK4h/lioRsAnkt4jfP4sU5oyuc/yKcGi4OKS89cy06BcG89mNlvSvoTrxKnA18ChZjY328f6jbRKCcAn5XmbRFX9TvAYGCeviHEuvREhK+AQQhrr/VaNQmK5INJ4PqEI22eEjr9rBDQroYJYUYB1xkqs5YxvRehwXAh8YWbLK97iN+va2sw+lLRb+jpLa5go6VVg/xJPiKQLCZ6iU81slxi03WRm5ytDPRPLUMdEodHjLoSA6fmUeSZ3N7PDs60v5binELqGb01oWfCtmV2dYVxOOz5LGkIoklecsqw+MMTMLs/28aqLpCvKW2dmV+ZSy+8RN2CcrBLdgVxLmDZYBZxlZh9UY/u4A1HrAH8ilPx+i1BVd35cx4sDJVQQS6HC7llmVp5nqGRcTqu1phz3rNQsJGXoli1pS0KcVuoP8GnAH81svxg0VbsAXWQQnESYLikkeCZHpGTjZJ0o4L4xwYD53Mwy1j/KtfEcvTd/Jnzu3o+8ZsOBR8zs7mwfz6lZuAHjZBVJ/wP2MrMF0V3no3F6BX4rktYHHgEKzWyfhLXcaGYXKLRXKPlCigxtDqLxNxE6BacWxJpoMRfEiqb8NiV0Bi6ZBsmkL9cZZiXdsm8gxIxAmLK50cy6V7Bdaop3XLFXJaXw16CcKaTy9hOLZzJl/+PNbA0PVoZxOTeeJa1LmLpcB1gInGsZqiwnQTS1d7eZLZH0DKHSMoRKxvckKO13gcfAONlmfskdejR/nTFbIKlA1CgI9WxCUOmlFhooJoqZXRD9rbSHVERSTet2quLQ1TLMoudxxnFUuVt2OSne20uKqxP1TEKX8bVlGOE9j4sPJQ1j9RYgmWqtJFFNdv3o8TXhPc6n7NkDzezG6HkbM+uj0BLlNUKsmhMjbsA4WUFR+WxgkqQzgdcJsRzl1ULIaSCqpL0JZeTnEGJL1iiulzSSXkn1BkkaZWZ/SB9nCRXEimIPBgHdCfVWHrTMLtycZphZ9bplp6d4L49+cMYRfpizzfJMsS7VJa5pVUl7mFlJYT8IAfVQfhHFnBrPkv5BMF5OiG6ItgCekDTS1uz2nASpXrHnAcysyJOQcoMbME62SL3L7ApsHz0vb46yKNV4gVBdVqFKaRyMAr4A2gIPRxeYcqdpcomkXoTsrW0kPR4tbgQ0rWg7y12vphLuj453PyHl9jZC9+d0XUm1OugNvKyKu2XnOsW7Wt23E/BMXgqMqWrAaQLG83gzeyLl+NMk7UFoJpoPFEtqYmbLzOxWKK2Inanyt5NlPAbGSYSkAlHzEYU2Bx0J5+LIaHERMDc1+yJp0gM4JY02sz2rsX1O4jhUQbdshcq7NxDiKTYBSlO8zez5GLUdQojPKbnglhs/RG6zfD4kZL6tQTlTSE4Kkg4mXLdOMrOCyJs3HPg0PYDcyT7ugXGySpTK+leCQQJAOVkY3pk1wkK5+1mSdoueI6knoW5NhaXwc0xdSTIzi7K5KvQQZSDuOI5Ku2VHwbon5irFO4WrgP5VCBbOtWeyBWVxQ6sdlnL6cDllmNmz0dTqWAW3bhEhccGNlxzgHhgnq0iaTugN8gll/WhWZBjXjTXn0jsCmxHNpZcTX1FrkTTJzPpKOopQer+hRUXX8gFJJxGqwY4G9gBeMbMqV2uNG4XKz/tRFjx5lEVVUlPGJJXi/byZHVCFcTn1TCpPegrVNiRdZWb5Ms1Va3EPjJNtZpvZ+5UNSioQNc8pMdh6m9lxkkYnqiYNM7s/muLYCrgo3VNQQlIZZhbaV8wEzgDeTzdeIlJL9Y8kd6X6v5X0GDCRMsM+U5ZKrj2TT2dxX04ZWS+K6KyJGzBOVlAoYAcwTdL1hKyOYqh4Lj2BQNR85mOFhnq3RHPpzZIWBGXVZKOXu5rZfZVskkirA0nDCcG4Y4CDJPU2s2vThuU6xbuEd6o4LqdZPiUeNEldCAXjmqesS2/D4Dh5hU8hOVlB5ZfUNjO7KqdiajCSWpnZwsiAaWtmP+SBptJqsqpCZdn0YN+U5XG3OnjTUtoBZNKqhEr1R8duQ8jQ+8LMFlUyNtUz+X0OUuTfAv5BmBr8EFjXovpETvlo9eKTpYuBzc2sVe4V/b5wD4yTFaqahumsidKaEabVkKiJd8ETovod6XEc02I+bnrGVqP0AUmleEcelL8A7wJbRV6tUeWNT8AzWWBmj0jqbmbDJcWWkVWbsKoXn3RiwA0YJ6tkuCNZDnxACJKssIfO75iSqZZXElVRPutHd+gC2qQ8L6+GTlIZZq9Juhd4idDN+41Mg8xsBnBu6rKodkecnAnsZmYro7T5Vwi1ifKFHyWtAzSXdATQJWE9jlMpPoXkZBVJ1wDPAv8juKN7EX6gjzGzPyWpLd+JfthSKayJmVhJZphJ2pPQkHBGRR6ODNvF3UR0tems8qbZkiaqk/N/hID68qpoO05e4AaMk1UkvWZmA1NejzGzPTxds3IkTQXWBb4CegBfEurAnFWVzK64iepd9AdalSwzs5EVjM9pHEd0zP0IqdHvmVlGD0wSSHoUeBV4keAdOjjumJvqIOnFOArlOU6c5FNTLKd2YJJ6A0jaijzJpKkhfAr0sNAVuCeR54qQkpwPvAIcAHRKeZSLmRWY2YdmNjlHxstwYB+C4XeQpDXihyRtLuklSW9JmiBpnKTHFLqTx8nphB5SjxE8RKfEfLzq8q6kPSU1kdQggzfQcfIO98A4WUXSBsB1wMbAL4QeSTOAI83ssSS15TvpXqqSrJ2qZP7kgnyd9iihillIOS3VX1OI0vchTPuVxDcl/plznIrwIF4nq5jZd4Q59HTceKmcWZIuJqT27gosTlhPOmOiKsGTKCvG9k2yklaj0iwkclyqX9KNZnZBWnB7XjQRTeOQ1ErEUasFx8lr3APjZAVJV5rZFZnqIuTZhTpviTJhjge2Ab4h1OVYRqgp8XFyygJRmfuBwEzKfoSPSlZVGZIuAzpTloX0k5ldljbGm4hmIEOQ8fhoKtNx8hY3YJysIKmRxd8Qr9aj0MRxc+BDM/siaT2pSJqc73UvoiykbYBpZrZGWrqkm4DnWT3Fe2LcKd6STjezEZI6ArcDj5jZC9k+zm/QtRtwPSFofDrBMK0PzMynIGPHyYQbME5WiVzPZxDubC8FNo7qbjiVIOl8oC+hDUM/4EUzezBRUSlIGgI8bGazk9aSTvS5W2RmxZL+TMh8etjMVqWNSyTFu8SjERUrvAe4P59iTCSNdIPFqWl4DIyTbR4BRgAXm9mK6IJ9YMKaagoHA33NzCT9ndDTJ28MGMK0zLGSfope50Uch6ShwABgZRSkWx/4mWAonJg61pJrIlpHUn9CDM7XUUp6PjEh9YWkE/LJeHacTLgB42SbJmY2KvImQEpzOKdSVpTc/UeehLpJC0olj6eP/mBmvSS1BKab2QYQsqbK2yCBUv3nAUcAV0tqRKgJk0+slPQUcCOhSrE3WHXyHjdgnGzzg6QDgLqS+gIFSQuqQUyLAlFLip19mrCe1ZDUmtCbqTvwPnC9mS1LVhUASwHM7FdJn6csT89KyjmSGpjZSsL5Si1GeGNCkjJiZvdI+h4YC5xhZg8nrclxKsNjYJysIqkpIcZgO+Az4Doz+6nirRwASXUIUx7bEOIz7jWzokRFpSDpWUI6/BjClM0BZnZ8oqIASZ8RpowEtEl9bmabJaztKjMbEtVZSU+jzqcYmIeBH4BhhO9vSzM7I1lVjlMxbsA4Tp5S8uOXtI4SMqTajjazPZPU5GQHSTuZ2Tspr/ub2diKtnGcpPFWAk5WkDRW0htpjzGSxiStrQazS+VDcko9SQ0hpM0DTRPWsxqSHkp7fV9CUtZA0uspz+tF8SaJI+lcADN7R1JqJeJDE5LkOFXGY2CcbLFP2ut2wHBgTgJanHi4GRgr6R1gJ+CWhPUAIGlr4Ehgd0nXRosbATsmp2oNSgOyzWxV1PU5H9iPsvfxHEL8FYS6MI6T17gB42QFM1tR8jyqw3EmcIGZTUpOVc0gU/ViQpzE5gnIKRcze17SeGAT4CozW5C0poivCY0m96Esu6cIuDIxRWvyk6S9zexVSTsDKyrdwnGcCvEYGCdrSFoXuJtQav4yr8xbO5A0qLx1ZnZPLrVUhKSOZjY3aR2ZkNQGuIlglM4Fzs2HgoCSfqWsAm9qNd7NzaxVgtIcp1LcA+NkBUknAKcA55jZ20nrcbJKibdgT0Lp/anA7sDChPSUR29JF1DmzcqLQnsAZrZA0unAuvnUANPMWiatwXF+K+6BcbKCpGJCnYuV5HfXXec3ImmUmf0h5fVLZrZfkppSkTQN6J+PafuSjiN0aW8H9CJUqr4iWVWOU7NxD4yTFczMM9pqP61LCrNFNWvWS1pQGjPz0XiJONnM+kkaa2bLJfVKWpDj1HTcgHGygqS9zOz1DMsvMrPrk9DkZJ3ULKQdCUXt8olvJT0GTCTyAuZRjI5FrSFKvJM+deM4a4kbME62GCSplZmV1reQNBxolqAmJ4uY2dNRPZNNgRvNbF7SmtJ4p/IhiXET8BrQTdILwP0J63GcGo/HwDhZIZpSuIPQBO5+Qhflz81sWKLCnKwhaR1CvZU2hPgmzOyqREWlIakTsIGZTU5aSzpRs8lNga/NbH7SehynpuNxC05WMLPiqHdKO8Kd8OtuvNQ6XgDqA+8CU6JH3iDpEkKTxLskNZL0j6Q1AUjaWdI/gScIgbzeod1xsoBPITlZIaUYm4B1gL9I+guehVSbWG5mtyUtogIGmtnuKYGyGyUtSNK+wHnRYxawFfCQpOPN7OsktTlOTccNGCcrmNnOSWtwYucVSXsBEygLkl2ZrKTVMEnNor/1yA9Px1nAkWb2Y/R6nKQTgauBYxJT5Ti1ADdgHMepKn+IHpdErw0YUP7wnHMxoaXApsAY4Jpk5QBQP8V4AcDMvpLUISlBjlNbcAPGcZwqYWb9k9ZQEVEF6F2iRonzLT8yFMrT4PGHjrOWeBaS4zhVQtIOhHYRpVMzZnZUcooCko4ys8clXUeawWBml5SzWU5I6TW02mK815DjrDXugXEcp6qMAM4F/gSMIwSk5gMlBsIriarIgPcacpz4cAPGcZyqstjMJkjax8z+I+mUpAVFfCKpAZB3tV8cx4kPN2Acx6kqH0XF7BpJupBQ8ycfeJUwddQCWBf4AtgSmEbomu04Ti3EY2Acx6kWkhoB+wKT86mdgKQngFPNbFEUyHujmZ2QtC7HceLBI+Edx6kUSVuWpP6a2XLgc+DRZFWtwbpmtggg6kq9ccJ6HMeJEZ9CchynQqKmnB2BdSQNBQ4EtgXOTlJXBr6SdDHwMtAPWJywHsdxYsSnkBzHqRBJb5lZn2jq6HPgOjMbkbSudCTVBY4HtiOU7f9niUfGcZzah3tgHMepjOUQpo4kzclH4wXAzIokvQxMjBatC7gB4zi1FPfAOI5TISnF2AT0SHmeV406Jd0HdAFaR4u+M7MDk1PkOE6cuAfGcZwKqUHF2DYzs36SrgUuBx5KWI/jODHiWUiO49QWCqK/TQl1YfKlUrDjODHgBozjOLWFiyW1JrQUeAv4V8J6HMeJEY+BcRynViBpsJndkbQOx3Fyg3tgHMepLfSXVD9pEY7j5AYP4nUcp7bQiNDY8T2giJAldVTCmhzHiQmfQnIcp1YgqXP6MjObnYQWx3Hix6eQHMep0UjqIKl+ZKxsCGwWPYqSVeY4Tpy4B8ZxnBqNpPHAnmZWGE0f/ZcwPb65mR2WqDjHcWLDY2Acx6npyMwKo+e/mtlVAJJeS1CT4zgx41NIjuPUdFKvY4ekPG+QayGO4+QON2Acx6npfCKpH4CZ/QIgaQtgfqKqHMeJFY+BcRynRhNV330eeB34CNgEOBQ4wrOQHKf24gaM4zg1Hkn1gIOAjYFZwItmtjRJTY7jxIsbMI7jOI7j1Dg8BsZxHMdxnBqHGzCO4ziO49Q43IBxHMdxHKfG4QaM4ziO4zg1DjdgHMdxHMepcfw/1vocgt5VbMsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_results = []\n",
    "for name, clf, clf_score in clfs_tuned:\n",
    "    pred = clf.predict_proba(X_dev)[:,1]\n",
    "    name = f'{name} \\n({clf_score:.4f})'\n",
    "    pred_results.append(pd.Series(pred, name=name))\n",
    "ensemble_results = pd.concat(pred_results, axis=1)\n",
    "\n",
    "# 모형의 예측값 간의 상관관계를 보기 위해 hitmap을 도식한다.\n",
    "plt.figure(figsize = (8,6))\n",
    "g = sns.heatmap(ensemble_results.corr(), annot=True, cmap='Blues')\n",
    "g.set_title(\"Correlation between models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mean agreement vs. Performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier \\n(0.6037)          0.588212\n",
       "MLPClassifier \\n(0.6725)                 0.845502\n",
       "LogisticRegression \\n(0.6816)            0.862316\n",
       "RandomForestClassifier \\n(0.6633)        0.890140\n",
       "GradientBoostingClassifier \\n(0.6628)    0.872722\n",
       "DecisionTreeClassifier \\n(0.6275)        0.763654\n",
       "ExtraTreesClassifier \\n(0.6717)          0.884346\n",
       "XGBClassifier \\n(0.6775)                 0.882638\n",
       "LGBMClassifier \\n(0.6804)                0.882976\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean agreement\n",
    "(ensemble_results.corr().sum()-1)/(ensemble_results.corr().shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = (ensemble_results.corr().sum()-1)/(ensemble_results.corr().shape[0]-1)\n",
    "names = corr.index\n",
    "aucs = np.array(corr.index.str[-7:-1]).astype(float)\n",
    "df = pd.DataFrame({'model': names, 'auc': aucs, 'cor': corr})        \n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "g = sns.scatterplot(x=\"cor\", y=\"auc\", data=df, s=40, color='red')\n",
    "for line in range(0, df.shape[0]):\n",
    "     g.text(df.cor[line]+0.003, df.auc[line]-0.003, \n",
    "            df.model[line], horizontalalignment='left', \n",
    "            size='medium', color='black', weight='semibold')\n",
    "        \n",
    "plt.xlim((df.cor.min()-0.01,df.cor.max()+0.01))\n",
    "plt.ylim((df.auc.min()-0.01,df.auc.max()+0.01))\n",
    "plt.xlabel('Mean Agreement')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Averaging Ensemble*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging 앙상블에 사용하지 않을 모델은 주석 처리하시오.\n",
    "selected = [\n",
    "    'KNeighborsClassifier', \n",
    "    'MLPClassifier',\n",
    "    'LogisticRegression', \n",
    "    'RandomForestClassifier', \n",
    "    'GradientBoostingClassifier', \n",
    "    'DecisionTreeClassifier',\n",
    "    'ExtraTreesClassifier',\n",
    "    'XGBClassifier',\n",
    "    'LGBMClassifier'\n",
    "    #'SVC'\n",
    "]\n",
    "models_for_ensemble = [clf for clf in clfs_tuned if clf[0] in selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:25<00:00, 48.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=0\n",
      "LogisticRegression●LGBMClassifier\n",
      "0.6832510637631577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "for p in tqdm([0, 1, 2.56]):  # p==1:산술평균, p=0:기하평균, 그 외:멱평균(주의:멱평균은 과적합 가능성이 높음)    \n",
    "    for i in range(2, len(models_for_ensemble)+1):\n",
    "        for models in combinations(models_for_ensemble, i):\n",
    "            if p == 0:\n",
    "                pred_mean = gmean([clf.predict_proba(X_dev)[:,1] for name, clf, _ in models], axis=0)\n",
    "            else:\n",
    "                preds = [clf.predict_proba(X_dev)[:,1] for name, clf, _ in models]\n",
    "                pred_mean = (np.sum(np.array(preds)**p, axis=0) / len(models))**(1/p)\n",
    "            score = roc_auc_score(y_dev, pred_mean)\n",
    "            if max_score < score:\n",
    "                best_avg_ensemble = (p, models, score)\n",
    "                max_score = score\n",
    "\n",
    "p, models, score = best_avg_ensemble\n",
    "print('p={}\\n{}\\n{}'.format(p, '●'.join([clf_name for clf_name, _, _ in models]), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn의 다른 classifier와 호환성을 갖기위해 Custom Classifier인 \"AveragingClassifier\" 생성\n",
    "\n",
    "class AveragingClassifier(ClassifierMixin):\n",
    "    def __init__(self, estimators, p):\n",
    "        self.estimators = estimators\n",
    "        self.p = p\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return None\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.p == 0:\n",
    "            pred = gmean([clf.predict(X) for name, clf in estimators], axis=0)\n",
    "        else:\n",
    "            preds = [clf.predict(X) for name, clf in estimators]\n",
    "            pred = (np.sum(np.array(preds)**self.p, axis=0) / len(estimators))**(1/self.p)\n",
    "        return pred\n",
    "         \n",
    "    def predict_proba(self, X):\n",
    "        if self.p == 0:\n",
    "            prob = gmean([clf.predict_proba(X) for name, clf in estimators], axis=0)\n",
    "        else:\n",
    "            probs = [clf.predict_proba(X) for name, clf in estimators]\n",
    "            prob = (np.sum(np.array(probs)**self.p, axis=0) / len(estimators))**(1/self.p)\n",
    "        return prob\n",
    "    \n",
    "estimators = [(name, clf) for name, clf, _ in models]\n",
    "avg_clf = AveragingClassifier(estimators, p)\n",
    "avg_clf.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Stacking*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-layer stacking\n",
    "\n",
    "# Initialize 1st level estimators\n",
    "# 사용하지 않을 모델은 주석 처리하세요.\n",
    "selected = [\n",
    "    #'KNeighborsClassifier', \n",
    "    'MLPClassifier',\n",
    "    'LogisticRegression', \n",
    "    'RandomForestClassifier', \n",
    "    'GradientBoostingClassifier',\n",
    "    'ExtraTreesClassifier',\n",
    "    'DecisionTreeClassifier',\n",
    "    #'XGBClassifier',\n",
    "    'LGBMClassifier'\n",
    "]\n",
    "\n",
    "estimators = [(name, clf) for name, clf, _ in clfs_tuned if name in selected]\n",
    "stk_clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(random_state=0), cv=5)\n",
    "\n",
    "stk_clf.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_dev, stk_clf.predict_proba(X_dev)[:,1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:55:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:55:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# 보팅 앙상블\n",
    "# 각 모델의 최적 파라미터를 기준으로 모델을 설정\n",
    "# MLPClassifier\n",
    "model = MLPClassifier(alpha=0.0001, batch_size = 'auto', learning_rate = 'adaptive',\n",
    "              activation = 'relu', solver = 'sgd',random_state=0)\n",
    "mlp_model  = model.fit(X_train, y_train)\n",
    "mlp_model.score(X_dev,y_dev)\n",
    "\n",
    "# LogisticRegression\n",
    "model = LogisticRegression(C= 0.1,penalty = 'l2',random_state=0)\n",
    "lr_model  = model.fit(X_train, y_train)\n",
    "\n",
    "# RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 286,max_depth = 6,min_samples_split=6,min_samples_leaf=1,max_features=23,\n",
    "                               criterion='entropy',\n",
    "                               random_state=0)\n",
    "rfm_model  = model.fit(X_train, y_train)\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(n_estimators=473,learning_rate=0.01,\n",
    "                           max_depth=3,random_state=0)\n",
    "gbm_model  = model.fit(X_train, y_train)\n",
    "gbm_model.score(X_dev,y_dev)\n",
    "\n",
    "# XGBClassifier\n",
    "model = xgb.XGBClassifier(n_estimators=100,learning_rate=0.05,min_child_weight=3,\n",
    "                           max_depth=1,random_state=0)\n",
    "xgb_model  = model.fit(X_train, y_train)\n",
    "\n",
    "# ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier(n_estimators=138,max_depth=4, min_samples_split=6,\n",
    "                             min_samples_leaf=6,max_features=27,random_state=0)\n",
    "ett_model  = model.fit(X_train, y_train)\n",
    "\n",
    "# LGBMClassifier\n",
    "model = lgb.LGBMClassifier(n_estimators=355,learning_rate=0.01,\n",
    "                           max_depth=2,min_child_weight=6,random_state=0)\n",
    "lgb_model  = model.fit(X_train, y_train)\n",
    "\n",
    "# 각 모델의 정확도를 계산 \n",
    "lgb_pred = lgb_model.fit(X_train, y_train).predict(X_dev)\n",
    "rfm_pred = rfm_model.fit(X_train, y_train).predict(X_dev)\n",
    "xgb_pred = xgb_model.fit(X_train, y_train).predict(X_dev)\n",
    "ett_pred = ett_model.fit(X_train, y_train).predict(X_dev)\n",
    "gbm_pred = gbm_model.fit(X_train, y_train).predict(X_dev)\n",
    "mlp_pred = mlp_model.fit(X_train, y_train).predict(X_dev)\n",
    "lr_pred = lr_model.fit(X_train, y_train).predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb_pred 0.35333333333333333\n",
      "rfm_pred 0.3495238095238095\n",
      "xgb_pred 0.34\n",
      "ett_pred 0.34476190476190477\n",
      "gbm_pred 0.3495238095238095\n",
      "mlp_pred 0.3647619047619048\n",
      "lr_pred 0.34\n"
     ]
    }
   ],
   "source": [
    "# 정확도를 가지고 평균 절대 오차를 구한 뒤 가장 작은 값을 가지는 것들을 파악한다.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"lgb_pred\",mean_absolute_error(y_dev,lgb_pred))\n",
    "print(\"rfm_pred\",mean_absolute_error(y_dev,rfm_pred))\n",
    "print(\"xgb_pred\",mean_absolute_error(y_dev,xgb_pred))\n",
    "print(\"ett_pred\",mean_absolute_error(y_dev,ett_pred))\n",
    "print(\"gbm_pred\",mean_absolute_error(y_dev,gbm_pred))\n",
    "print(\"mlp_pred\",mean_absolute_error(y_dev,mlp_pred))\n",
    "print(\"lr_pred\",mean_absolute_error(y_dev,lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.6798493703539875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.4437231 , 0.1680172 , 0.21101994, ..., 0.50672024, 0.43777121,\n",
       "       0.51647264])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파악 후 낮은 것 중 3개를 가져오고 낮을수록 가중치를 많이 주어 보팅앙상블을 실시했다.\n",
    "voting = VotingClassifier(estimators=[('xgb', xgb_model),('ETT', ett_model),\n",
    "                                      ('LR', lr_model)],voting='soft',weights=[4,3,4])\n",
    "voting.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_dev, voting.predict_proba(X_dev)[:,1])) \n",
    "voting.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging ensemble로 예측한 submission: (결과) 0.71959\n",
    "pd.DataFrame({'cust_id': test_id, 'gender': avg_clf.predict_proba(X_test)[:,1]}).to_csv('submission_avg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking ensemble로 예측한 submission: (결과) 0.71928\n",
    "pd.DataFrame({'cust_id': test_id, 'gender': stk_clf.predict_proba(X_test)[:,1]}).to_csv('submission_stk.csv', index=False)\n",
    "\n",
    "# 단일 모델로 성능이 가장 높은 Logistic Regression으로 예측한 submission: (결과) 0.71403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight_voting (soft)을 적용한 submission\n",
    "pd.DataFrame({'cust_id': test_id, 'gender': voting.predict_proba(X_test)[:,1]}).to_csv('submission_voting.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db6a418af5947fb6d1546dc8949ac55663504f18"
   },
   "source": [
    "<font color=\"#CC3D3D\"><p>\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
