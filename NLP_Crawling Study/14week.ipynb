{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "res=requests.get('https://github.com/e9t/nsmc/raw/master/ratings_train.txt')\n",
    "\n",
    "with open('ratings_train.txt','wb') as f:\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc=pd.read_csv('ratings_train.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hangul(text):\n",
    "    return re.findall(r'[ㄱ-ㅎ가-힣]+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nsmc[nsmc['document'].notnull()]['document'].map(find_hangul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아', '더빙', '진짜', '짜증나네요', '목소리']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_hangul(text):\n",
    "    return ' '.join(find_hangul(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = nsmc[nsmc['document'].notnull()]['document'].map(only_hangul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아 더빙 진짜 짜증나네요 목소리'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nsmc.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastText 모형 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(sentences=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    sentences=data,\n",
    "    epochs=5,\n",
    "    total_examples=model.corpus_count,\n",
    "    total_words=model.corpus_total_words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nsmc.fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load('nsmc.fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "model = FastText.load('nsmc.fasttext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 임베딩\n",
    "'히어로'는 단어 임베딩이 학습되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'히어로' in model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04594129,  0.45343852,  0.44429657,  0.5475346 , -0.6134086 ,\n",
       "       -0.23622645, -0.78780735,  0.3909033 ,  0.22873542,  0.21316187,\n",
       "       -0.71568775,  0.08368004, -0.2830746 , -0.1506468 ,  0.56481427,\n",
       "       -0.7089242 ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['히어로']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'슈퍼히어로'는 단어 임베딩이 없지만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'슈퍼히어로' in model.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "준단어 토큰의 임베딩을 더해서 임베딩을 계산해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04049635,  0.26484385,  0.24594593,  0.20961554, -0.268292  ,\n",
       "       -0.08478185, -0.29447132,  0.12084288,  0.11553464,  0.03385194,\n",
       "       -0.3028485 ,  0.03501648, -0.10842834, -0.0880933 ,  0.23624958,\n",
       "       -0.2664656 ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['슈퍼히어로']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사도\n",
    "'히어로'와 '슈퍼히어로'의 유사도는 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847185"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('슈퍼히어로', '히어로')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'히어로'와 '평론가'의 유사도는 상대적으로 낮다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6637813"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('히어로', '평론가')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'평론가'와 비슷한 단어들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('전문가', 0.9911670088768005),\n",
       " ('평론가들', 0.9909869432449341),\n",
       " ('높은거야', 0.9896015524864197),\n",
       " ('점이나', 0.9895164966583252),\n",
       " ('점대가', 0.9892258644104004),\n",
       " ('평론', 0.9883065223693848),\n",
       " ('점대는', 0.9882416129112244),\n",
       " ('점대라', 0.9879096746444702),\n",
       " ('높은거지', 0.9871199131011963),\n",
       " ('점이라', 0.9865758419036865)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('평론가')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "준비\n",
    "학습된 FastText 모형을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "ft = FastText.load('nsmc.fasttext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nsmc = pd.read_csv('ratings_train.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리\n",
    "리뷰가 있는 데이터만 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nsmc[nsmc['document'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련용 데이터와 테스트용 데이터를 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "doc_train, doc_test, y_train, y_test = train_test_split(df['document'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 단어만 추출하는 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_hangul(text):\n",
    "    return re.findall(r'[ㄱ-ㅎ가-힣]+', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000, 16 크기의 행렬을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.zeros((1000, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문서에서 한글 단어를 찾아 단어 임베딩을 구하고, 이를 문서마다 평균을 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(doc_train.iloc[:1000]):\n",
    "    vs = [ft.wv[word] for word in find_hangul(doc)]\n",
    "    if vs:\n",
    "        x_train[i,] = np.mean(vs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train은 각 문서의 단어 임베딩 평균이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85029197,  1.39048409,  1.75145721,  0.75306934, -0.89818573,\n",
       "       -0.17689162, -0.6556133 , -0.66011852,  1.11917162, -0.8815093 ,\n",
       "       -0.95759803, -0.59692693,  0.25644588, -1.11521089, -0.30577666,\n",
       "       -0.56151581])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모형 학습\n",
    "각 문서의 단어 임베딩 평균을 이용하여 감성을 예측하는 모형을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 656us/step - loss: 0.6874 - accuracy: 0.5300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ca893e99a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train.values[:1000], epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('imdb.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "tk = joblib.load('tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_train, review_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = tk.texts_to_sequences(review_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9, 6, 33, 1258, 214], 'It is an insane game.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[0], review_train.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순방향 순환신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패딩을 한다. 길이가 짧으면 앞쪽에 0을 채운다(padding='pre'). maxlen은 최대 길이를 지정할 수 있다. 지정하지 않으면 가장 긴 문자열의 길이로 지정된다. truncating='pre'는 maxlen보다 긴 문자열일 경우 앞쪽을 자른다. 뒤쪽을 자르게 하려면 'post'로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pads = tf.keras.preprocessing.sequence.pad_sequences(seqs, maxlen=None, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS= tk.num_words + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding에서 mask_zero=True로 설정하면 0으로 패딩된 부분의 예측은 손실에 반영하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(NUM_WORDS, 8, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(8),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 8)           16008     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 16,561\n",
      "Trainable params: 16,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모형을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6930 - accuracy: 0.5200\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.6425\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6859 - accuracy: 0.7675\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6684 - accuracy: 0.8175\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6014 - accuracy: 0.8325\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.4919 - accuracy: 0.8363\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.3968 - accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.3273 - accuracy: 0.9225\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.2771 - accuracy: 0.9388\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.2338 - accuracy: 0.9613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x253bd473730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pads, y_train.values, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역방향 순환신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패딩을 한다. 길이가 짧으면 뒤쪽에 0을 채운다(padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pads = tf.keras.preprocessing.sequence.pad_sequences(seqs, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(NUM_WORDS, 8, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(8, go_backwards=True),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.6928 - accuracy: 0.5088\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.6650\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6777 - accuracy: 0.7663\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.6331 - accuracy: 0.8025\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.5461 - accuracy: 0.8612\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.4421 - accuracy: 0.9025\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.3816 - accuracy: 0.9112\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.3153 - accuracy: 0.9362\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.2833 - accuracy: 0.9450\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.2560 - accuracy: 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x253d434aee0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pads, y_train.values, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "양방향 순환신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM을 Bidirectional로 감싸주면 자동으로 순방향과 역방향 레이어를 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(NUM_WORDS, 8, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 8)           16008     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 16)                1088      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 17,113\n",
      "Trainable params: 17,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.6921 - accuracy: 0.5362\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.6849 - accuracy: 0.7013\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.6648 - accuracy: 0.8037\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.5980 - accuracy: 0.8388\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.4443 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.2928 - accuracy: 0.9150\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.2127 - accuracy: 0.9513\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.1689 - accuracy: 0.9613\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.1410 - accuracy: 0.9663\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.1157 - accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x253dd041bb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pads, y_train.values, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
